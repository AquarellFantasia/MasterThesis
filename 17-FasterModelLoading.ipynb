{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad176564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-27 22:00:41.774006: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-27 22:00:43.907300: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /appl/cudnn/v8.3.2.44-prod-cuda-11.5/lib:/appl/cuda/11.6.0/lib64:/appl/python/3.10.7/lib:/appl/gcc/11.3.0-binutils-2.38/lib64:/appl/gcc/11.3.0-binutils-2.38/lib:/lsf/10.1/linux3.10-glibc2.17-x86_64/lib\n",
      "2023-01-27 22:00:43.907981: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /appl/cudnn/v8.3.2.44-prod-cuda-11.5/lib:/appl/cuda/11.6.0/lib64:/appl/python/3.10.7/lib:/appl/gcc/11.3.0-binutils-2.38/lib64:/appl/gcc/11.3.0-binutils-2.38/lib:/lsf/10.1/linux3.10-glibc2.17-x86_64/lib\n",
      "2023-01-27 22:00:43.907992: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Model\n",
    "from keras.utils import Sequence\n",
    "from keras.utils import load_img\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9886ffe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('black_background_500x500.csv')\n",
    "train_df = df[df['ImagePath'].str.contains(\"train\")]\n",
    "test_df = df[df['ImagePath'].str.contains(\"test\")]\n",
    "valid_df = df[df['ImagePath'].str.contains(\"valid\")]\n",
    "\n",
    "input_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c46f0bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df_to_list(the_df, i_s):\n",
    "    the_df = the_df.reset_index()\n",
    "    x_list = np.zeros((len(the_df), i_s, i_s, 1))\n",
    "    y_list = np.zeros((len(the_df), 3))\n",
    "    for i, row in the_df.iterrows():\n",
    "        data = load_img(path = row['ImagePath'], color_mode = \"grayscale\")\n",
    "        data = tf.keras.utils.img_to_array(data, data_format=\"channels_last\", dtype=\"float32\")\n",
    "        data /= 255\n",
    "        x_list[i] = np.asarray(data)\n",
    "        y_list[i] = row[['phi1','PHI', 'phi2']].values\n",
    "    \n",
    "    return x_list, y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e34a4252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImagePath,image_name,phi1,PHI,phi2\n",
    "train_x_list,train_y_list = load_df_to_list(train_df, input_size)\n",
    "test_x_list,test_y_list   = load_df_to_list(test_df, input_size)\n",
    "valid_x_list,valid_y_list = load_df_to_list(valid_df, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "821ed390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8750, 500, 500, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5d80d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_x_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0550d470",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-27 22:02:06.369275: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-27 22:02:07.106934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 84 MB memory:  -> device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:af:00.0, compute capability: 7.0\n",
      "2023-01-27 22:02:07.136231: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:735] failed to allocate 84.88M (88997888 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    }
   ],
   "source": [
    "# inputs = keras.Input(shape=(input_size, input_size, 1))\n",
    "# x = layers.Conv2D(filters=4, kernel_size=5, activation=\"relu\")(inputs)\n",
    "# x = layers.MaxPooling2D(pool_size=4)(x)\n",
    "# x = layers.Conv2D(filters=4, kernel_size=5, activation=\"relu\")(x)\n",
    "# x = layers.MaxPooling2D(pool_size=4)(x)\n",
    "# x = layers.Conv2D(filters=4, kernel_size=5, activation=\"relu\")(x)\n",
    "# x = tf.keras.layers.Dropout(0.5)(x)\n",
    "# x = layers.Flatten()(x)\n",
    "# outputs = layers.Dense(3)(x)\n",
    "\n",
    "# model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "# model.summary()\n",
    "\n",
    "inputs = keras.Input(shape=(input_size, input_size, 1))\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=4)(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=4)(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=4)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(3)(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfb817a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "  \n",
    "def abs_loss_function(y_true, y_pred):   \n",
    "    abs_diff = K.abs(y_true - y_pred)\n",
    "    ones = tf.ones_like(y_true)\n",
    "    abs_diff_reversed = K.abs(ones - abs_diff )   \n",
    "    minimum_from_two = tf.math.minimum(abs_diff, abs_diff_reversed) \n",
    "    return tf.math.reduce_mean(minimum_from_two, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0665bd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = RMSprop(learning_rate=0.001),\n",
    "              loss = abs_loss_function, \n",
    "              metrics = [abs_loss_function])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc4be299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-27 22:02:29.801626: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.33GiB (rounded to 7875000064)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-01-27 22:02:29.801707: I tensorflow/tsl/framework/bfc_allocator.cc:1034] BFCAllocator dump for GPU_0_bfc\n",
      "2023-01-27 22:02:29.801739: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (256): \tTotal Chunks: 24, Chunks in use: 24. 6.0KiB allocated for chunks. 6.0KiB in use in bin. 1.1KiB client-requested in use in bin.\n",
      "2023-01-27 22:02:29.801766: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (512): \tTotal Chunks: 1, Chunks in use: 1. 512B allocated for chunks. 512B in use in bin. 512B client-requested in use in bin.\n",
      "2023-01-27 22:02:29.801792: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1024): \tTotal Chunks: 2, Chunks in use: 2. 2.5KiB allocated for chunks. 2.5KiB in use in bin. 2.1KiB client-requested in use in bin.\n",
      "2023-01-27 22:02:29.801815: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-27 22:02:29.801837: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-27 22:02:29.801864: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8192): \tTotal Chunks: 2, Chunks in use: 1. 22.5KiB allocated for chunks. 8.0KiB in use in bin. 8.0KiB client-requested in use in bin.\n",
      "2023-01-27 22:02:29.801887: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-27 22:02:29.801914: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (32768): \tTotal Chunks: 6, Chunks in use: 5. 226.8KiB allocated for chunks. 180.0KiB in use in bin. 180.0KiB client-requested in use in bin.\n",
      "2023-01-27 22:02:29.801936: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-27 22:02:29.801958: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-27 22:02:29.801980: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-27 22:02:29.802006: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (524288): \tTotal Chunks: 1, Chunks in use: 1. 576.0KiB allocated for chunks. 576.0KiB in use in bin. 576.0KiB client-requested in use in bin.\n",
      "2023-01-27 22:02:29.802029: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1048576): \tTotal Chunks: 1, Chunks in use: 0. 1.12MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-27 22:02:29.802052: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-27 22:02:29.802074: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-27 22:02:29.802119: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-27 22:02:29.802142: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-27 22:02:29.802164: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-27 22:02:29.802188: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (67108864): \tTotal Chunks: 1, Chunks in use: 0. 74.45MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-27 22:02:29.802210: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-27 22:02:29.802234: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-27 22:02:29.802259: I tensorflow/tsl/framework/bfc_allocator.cc:1057] Bin for 7.33GiB was 256.00MiB, Chunk State: \n",
      "2023-01-27 22:02:29.802279: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 80098304\n",
      "2023-01-27 22:02:29.802306: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c000000 of size 1280 next 1\n",
      "2023-01-27 22:02:29.802327: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c000500 of size 256 next 2\n",
      "2023-01-27 22:02:29.802347: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c000600 of size 256 next 3\n",
      "2023-01-27 22:02:29.802366: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c000700 of size 256 next 5\n",
      "2023-01-27 22:02:29.802385: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c000800 of size 256 next 6\n",
      "2023-01-27 22:02:29.802403: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c000900 of size 256 next 4\n",
      "2023-01-27 22:02:29.802422: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c000a00 of size 256 next 7\n",
      "2023-01-27 22:02:29.802442: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c000b00 of size 256 next 12\n",
      "2023-01-27 22:02:29.802461: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c000c00 of size 256 next 15\n",
      "2023-01-27 22:02:29.802480: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c000d00 of size 256 next 17\n",
      "2023-01-27 22:02:29.802499: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c000e00 of size 256 next 19\n",
      "2023-01-27 22:02:29.802518: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c000f00 of size 256 next 21\n",
      "2023-01-27 22:02:29.802537: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c001000 of size 256 next 10\n",
      "2023-01-27 22:02:29.802555: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c001100 of size 256 next 11\n",
      "2023-01-27 22:02:29.802575: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c001200 of size 512 next 8\n",
      "2023-01-27 22:02:29.802595: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c001400 of size 1280 next 9\n",
      "2023-01-27 22:02:29.802614: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c001900 of size 256 next 24\n",
      "2023-01-27 22:02:29.802633: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c001a00 of size 256 next 23\n",
      "2023-01-27 22:02:29.802652: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c001b00 of size 256 next 28\n",
      "2023-01-27 22:02:29.802670: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c001c00 of size 256 next 29\n",
      "2023-01-27 22:02:29.802689: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c001d00 of size 256 next 27\n",
      "2023-01-27 22:02:29.802708: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c001e00 of size 256 next 33\n",
      "2023-01-27 22:02:29.802727: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c001f00 of size 256 next 30\n",
      "2023-01-27 22:02:29.802745: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c002000 of size 256 next 34\n",
      "2023-01-27 22:02:29.802764: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c002100 of size 256 next 35\n",
      "2023-01-27 22:02:29.802783: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c002200 of size 256 next 36\n",
      "2023-01-27 22:02:29.802802: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c002300 of size 256 next 37\n",
      "2023-01-27 22:02:29.802821: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f277c002400 of size 14848 next 31\n",
      "2023-01-27 22:02:29.802841: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c005e00 of size 8192 next 32\n",
      "2023-01-27 22:02:29.802861: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f277c007e00 of size 47872 next 14\n",
      "2023-01-27 22:02:29.802881: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c013900 of size 36864 next 13\n",
      "2023-01-27 22:02:29.802900: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c01c900 of size 36864 next 16\n",
      "2023-01-27 22:02:29.802919: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c025900 of size 36864 next 18\n",
      "2023-01-27 22:02:29.802938: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c02e900 of size 36864 next 20\n",
      "2023-01-27 22:02:29.802957: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c037900 of size 36864 next 22\n",
      "2023-01-27 22:02:29.802977: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f277c040900 of size 1179648 next 26\n",
      "2023-01-27 22:02:29.802997: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f277c160900 of size 589824 next 25\n",
      "2023-01-27 22:02:29.803017: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f277c1f0900 of size 78064384 next 18446744073709551615\n",
      "2023-01-27 22:02:29.803036: I tensorflow/tsl/framework/bfc_allocator.cc:1095]      Summary of in-use Chunks by size: \n",
      "2023-01-27 22:02:29.803059: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 24 Chunks of size 256 totalling 6.0KiB\n",
      "2023-01-27 22:02:29.803091: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 512 totalling 512B\n",
      "2023-01-27 22:02:29.803113: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 1280 totalling 2.5KiB\n",
      "2023-01-27 22:02:29.803133: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 8192 totalling 8.0KiB\n",
      "2023-01-27 22:02:29.803154: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 5 Chunks of size 36864 totalling 180.0KiB\n",
      "2023-01-27 22:02:29.803175: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 589824 totalling 576.0KiB\n",
      "2023-01-27 22:02:29.803196: I tensorflow/tsl/framework/bfc_allocator.cc:1102] Sum Total of in-use chunks: 773.0KiB\n",
      "2023-01-27 22:02:29.803216: I tensorflow/tsl/framework/bfc_allocator.cc:1104] total_region_allocated_bytes_: 80098304 memory_limit_: 88997888 available bytes: 8899584 curr_region_allocation_bytes_: 177995776\n",
      "2023-01-27 22:02:29.803245: I tensorflow/tsl/framework/bfc_allocator.cc:1110] Stats: \n",
      "Limit:                        88997888\n",
      "InUse:                          791552\n",
      "MaxInUse:                      1960192\n",
      "NumAllocs:                          79\n",
      "MaxAllocSize:                   589824\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-01-27 22:02:29.803276: W tensorflow/tsl/framework/bfc_allocator.cc:492] ***_________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_x_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_y_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/project/venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/project/venv/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "history = model.fit(x=train_x_list,\n",
    "                    y=train_y_list,\n",
    "                    batch_size=32,\n",
    "                    epochs=5,\n",
    "                    validation_split=0.1,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eacdf97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
