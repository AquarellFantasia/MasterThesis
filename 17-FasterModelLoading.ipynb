{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad176564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 11:39:01.385257: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-25 11:39:03.781361: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /appl/cudnn/v8.3.2.44-prod-cuda-11.5/lib:/appl/cuda/11.6.0/lib64:/appl/python/3.10.7/lib:/appl/gcc/11.3.0-binutils-2.38/lib64:/appl/gcc/11.3.0-binutils-2.38/lib:/lsf/10.1/linux3.10-glibc2.17-x86_64/lib\n",
      "2023-01-25 11:39:03.781719: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /appl/cudnn/v8.3.2.44-prod-cuda-11.5/lib:/appl/cuda/11.6.0/lib64:/appl/python/3.10.7/lib:/appl/gcc/11.3.0-binutils-2.38/lib64:/appl/gcc/11.3.0-binutils-2.38/lib:/lsf/10.1/linux3.10-glibc2.17-x86_64/lib\n",
      "2023-01-25 11:39:03.781733: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Model\n",
    "from keras.utils import Sequence\n",
    "from keras.utils import load_img\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9886ffe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('black_background_500x500.csv')\n",
    "train_df = df[df['ImagePath'].str.contains(\"train\")]\n",
    "test_df = df[df['ImagePath'].str.contains(\"test\")]\n",
    "valid_df = df[df['ImagePath'].str.contains(\"valid\")]\n",
    "\n",
    "input_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c46f0bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df_to_list(the_df, i_s):\n",
    "    the_df = the_df.reset_index()\n",
    "    x_list = np.zeros((len(the_df), i_s, i_s, 1))\n",
    "    y_list = np.zeros((len(the_df), 3))\n",
    "    for i, row in the_df.iterrows():\n",
    "        data = load_img(path = row['ImagePath'], color_mode = \"grayscale\")\n",
    "        data = tf.keras.utils.img_to_array(data, data_format=\"channels_last\", dtype=\"float32\")\n",
    "        data /= 255\n",
    "        x_list[i] = np.asarray(data)\n",
    "        y_list[i] = row[['phi1','PHI', 'phi2']].values\n",
    "    \n",
    "    return x_list, y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e34a4252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImagePath,image_name,phi1,PHI,phi2\n",
    "train_x_list,train_y_list = load_df_to_list(train_df, input_size)\n",
    "test_x_list,test_y_list   = load_df_to_list(test_df, input_size)\n",
    "valid_x_list,valid_y_list = load_df_to_list(valid_df, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "821ed390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8750, 500, 500, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5d80d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_x_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0550d470",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 11:40:39.854078: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-25 11:40:40.753686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14610 MB memory:  -> device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:af:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 500, 500, 1)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 496, 496, 4)       104       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 124, 124, 4)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 120, 120, 4)       404       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 30, 30, 4)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 26, 26, 4)         404       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 26, 26, 4)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2704)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 8115      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,027\n",
      "Trainable params: 9,027\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(input_size, input_size, 1))\n",
    "x = layers.Conv2D(filters=4, kernel_size=5, activation=\"relu\")(inputs)\n",
    "x = layers.MaxPooling2D(pool_size=4)(x)\n",
    "x = layers.Conv2D(filters=4, kernel_size=5, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=4)(x)\n",
    "x = layers.Conv2D(filters=4, kernel_size=5, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(3)(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfb817a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "  \n",
    "def abs_loss_function(y_true, y_pred):   \n",
    "    abs_diff = K.abs(y_true - y_pred)\n",
    "    ones = tf.ones_like(y_true)\n",
    "    abs_diff_reversed = K.abs(ones - abs_diff )   \n",
    "    minimum_from_two = tf.math.minimum(abs_diff, abs_diff_reversed) \n",
    "    return tf.math.reduce_mean(minimum_from_two, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0665bd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = RMSprop(learning_rate=0.001),\n",
    "              loss = abs_loss_function, \n",
    "              metrics = [abs_loss_function])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc4be299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 11:40:55.148645: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 7875000000 exceeds 10% of free system memory.\n",
      "2023-01-25 11:41:03.867764: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 7875000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 11:41:11.883017: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-01-25 11:41:13.071525: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247/247 [==============================] - 14s 34ms/step - loss: 0.2476 - abs_loss_function: 0.2476 - val_loss: 0.2495 - val_abs_loss_function: 0.2495\n",
      "Epoch 2/5\n",
      "247/247 [==============================] - 8s 32ms/step - loss: 0.2473 - abs_loss_function: 0.2473 - val_loss: 0.2494 - val_abs_loss_function: 0.2494\n",
      "Epoch 3/5\n",
      "247/247 [==============================] - 7s 28ms/step - loss: 0.2453 - abs_loss_function: 0.2453 - val_loss: 0.2421 - val_abs_loss_function: 0.2421\n",
      "Epoch 4/5\n",
      "247/247 [==============================] - 7s 27ms/step - loss: 0.2410 - abs_loss_function: 0.2410 - val_loss: 0.2422 - val_abs_loss_function: 0.2422\n",
      "Epoch 5/5\n",
      "247/247 [==============================] - 7s 27ms/step - loss: 0.2373 - abs_loss_function: 0.2373 - val_loss: 0.2494 - val_abs_loss_function: 0.2494\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=train_x_list,\n",
    "                    y=train_y_list,\n",
    "                    batch_size=32,\n",
    "                    epochs=5,\n",
    "                    validation_split=0.1,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eacdf97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
