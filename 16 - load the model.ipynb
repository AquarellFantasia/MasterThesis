{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad176564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-18 10:28:33.431827: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-18 10:28:37.984222: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /appl/cudnn/v8.3.2.44-prod-cuda-11.5/lib:/appl/cuda/12.0.0/lib64:/appl/python/3.10.7/lib:/appl/gcc/11.3.0-binutils-2.38/lib64:/appl/gcc/11.3.0-binutils-2.38/lib:/lsf/10.1/linux3.10-glibc2.17-x86_64/lib\n",
      "2023-01-18 10:28:37.984276: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-18 10:28:57.065982: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /appl/cudnn/v8.3.2.44-prod-cuda-11.5/lib:/appl/cuda/12.0.0/lib64:/appl/python/3.10.7/lib:/appl/gcc/11.3.0-binutils-2.38/lib64:/appl/gcc/11.3.0-binutils-2.38/lib:/lsf/10.1/linux3.10-glibc2.17-x86_64/lib\n",
      "2023-01-18 10:28:57.067170: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /appl/cudnn/v8.3.2.44-prod-cuda-11.5/lib:/appl/cuda/12.0.0/lib64:/appl/python/3.10.7/lib:/appl/gcc/11.3.0-binutils-2.38/lib64:/appl/gcc/11.3.0-binutils-2.38/lib:/lsf/10.1/linux3.10-glibc2.17-x86_64/lib\n",
      "2023-01-18 10:28:57.067209: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Model\n",
    "from keras.utils import Sequence\n",
    "from keras.utils import load_img\n",
    "from keras.optimizers import RMSprop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb1c0c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('black_background_500x500.csv')\n",
    "train_df = df[df['ImagePath'].str.contains(\"train\")]\n",
    "test_df = df[df['ImagePath'].str.contains(\"test\")]\n",
    "valid_df = df[df['ImagePath'].str.contains(\"valid\")]\n",
    "\n",
    "input_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f533699f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "################## data generator #######################\n",
    "#########################################################\n",
    "class datagenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, \n",
    "            batch_size, \n",
    "            img_size,\n",
    "            data_paths_df,\n",
    "            input_channels,\n",
    "            output_channels):\n",
    "         \n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.data_paths_df = data_paths_df\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "        self.data_paths = data_paths_df.values[:,1]\n",
    "        self.params = data_paths_df.values[:,3:6]\n",
    "        assert len(self.data_paths) == len(self.params)\n",
    "        \n",
    "        self.n = len(self.data_paths)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'updates indexes after each epoch'\n",
    "        self.data_paths_df = self.data_paths_df.sample(frac = 1)\n",
    "        self.data_paths = self.data_paths_df.values[:,1]\n",
    "        self.params = self.data_paths_df.values[:,3:6]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_data_paths = self.data_paths[index : index + self.batch_size]\n",
    "        batch_params_paths = self.params[index : index + self.batch_size]\n",
    "\n",
    "        return self.__dataloader(self.img_size,\n",
    "                batch_data_paths, batch_params_paths,\n",
    "                self.input_channels, self.output_channels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size\n",
    "\n",
    "    #################### data loader ########################\n",
    "    def __dataloader(self, \n",
    "            img_size,\n",
    "            data_paths,\n",
    "            batch_params_paths,\n",
    "            input_channels,\n",
    "            output_channels):\n",
    "        x = np.zeros((len(data_paths), img_size[0], img_size[1], input_channels))\n",
    "        y = batch_params_paths        \n",
    "        \n",
    "        for i in range(len(data_paths)):\n",
    "            data = load_img(path = data_paths[i], grayscale = True)\n",
    "            data = tf.keras.utils.img_to_array(data, data_format=\"channels_last\", dtype=\"float32\")\n",
    "            data /= 255\n",
    "            data.shape = (1,) + data.shape\n",
    "            x[i] = np.asarray(data)\n",
    "        return x.astype(\"float32\"), np.array(y).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "901d44f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def abs_loss_function(y_true, y_pred):   \n",
    "    abs_diff = K.abs(y_true - y_pred)\n",
    "    ones = tf.ones_like(y_true)\n",
    "    abs_diff_reversed = K.abs(ones - abs_diff )   \n",
    "    minimum_from_two = tf.math.minimum(abs_diff, abs_diff_reversed) \n",
    "    return tf.math.reduce_mean(minimum_from_two, axis=-1)\n",
    "\n",
    "def square_abs_min_loss(y_true, y_pred):   \n",
    "    abs_diff = K.abs(y_true - y_pred)\n",
    "    ones = tf.ones_like(y_true)\n",
    "    abs_diff_reversed = K.abs(tf.ones_like(y_true) - abs_diff )   \n",
    "    minimum_from_two = tf.math.minimum(abs_diff, abs_diff_reversed) \n",
    "    result = tf.math.square( (minimum_from_two[:, 0] + minimum_from_two[:, 1] + minimum_from_two[:, 2]) / 3 )\n",
    "    return K.mean(result)\n",
    "\n",
    "def square_abs_min_individual_loss(y_true, y_pred):   \n",
    "    abs_diff = K.abs(y_true - y_pred)\n",
    "    ones = tf.ones_like(y_true)\n",
    "    abs_diff_reversed = K.abs(tf.ones_like(y_true) - abs_diff )   \n",
    "    minimum_from_two = tf.math.minimum(abs_diff, abs_diff_reversed) \n",
    "    result = (tf.math.square(minimum_from_two[:, 0]) + \n",
    "              tf.math.square(minimum_from_two[:, 1]) + \n",
    "              tf.math.square(minimum_from_two[:, 2])) / 3 \n",
    "    return K.mean(result)\n",
    "\n",
    "############################# For debugging ####################################\n",
    "#     print(\"_________________ 1 __________________\")\n",
    "#     print(abs_diff_reversed.numpy())\n",
    "#     print(\"_________________ 2 __________________\")\n",
    "#     print(abs_diff.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36ed0c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model \n",
    "from tensorflow.keras.utils import CustomObjectScope\n",
    "\n",
    "with CustomObjectScope({'abs_loss_function': square_abs_min_loss}):\n",
    "    model = keras.models.load_model('Models/3db071e0968f11ed81960894ef90a55a_model_adam_001.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3b84982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### PREDICTIONS ###############\n",
      "@@@@@@@ [0.3647059]\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "predicted values [[ 37.6812     -1.2368847 114.12841  ]]\n",
      "@@@@@@@ [0.36862746]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted values [[ 37.6812     -1.2368847 114.12841  ]]\n",
      "@@@@@@@ [0.3647059]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "predicted values [[ 37.6812     -1.2368847 114.12841  ]]\n",
      "@@@@@@@ [0.4392157]\n",
      "----------3----------\n",
      "phi1 17.5\n",
      "PHI 15.5\n",
      "phi2 50.4\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted values [[ 37.6812     -1.2368847 114.12841  ]]\n",
      "@@@@@@@ [0.30980393]\n",
      "----------4----------\n",
      "phi1 47.5\n",
      "PHI 32.6\n",
      "phi2 29.8\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted values [[ 37.6812     -1.2368847 114.12841  ]]\n",
      "@@@@@@@ [0.42352942]\n",
      "----------5----------\n",
      "phi1 33.3\n",
      "PHI 39.6\n",
      "phi2 28.5\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted values [[ 37.6812     -1.2368847 114.12841  ]]\n",
      "@@@@@@@ [0.28235295]\n",
      "----------6----------\n",
      "phi1 60.8\n",
      "PHI 28.2\n",
      "phi2 9.9\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted values [[ 37.6812     -1.2368847 114.12841  ]]\n",
      "@@@@@@@ [0.36862746]\n",
      "----------7----------\n",
      "phi1 26.6\n",
      "PHI 6.8\n",
      "phi2 75.8\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "predicted values [[ 37.6812     -1.2368847 114.12841  ]]\n",
      "@@@@@@@ [0.32941177]\n",
      "----------8----------\n",
      "phi1 39.3\n",
      "PHI 40.9\n",
      "phi2 7.6\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "predicted values [[ 37.6812     -1.2368847 114.12841  ]]\n",
      "@@@@@@@ [0.4117647]\n",
      "----------9----------\n",
      "phi1 3.9\n",
      "PHI 87.4\n",
      "phi2 25.8\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted values [[ 37.6812     -1.2368847 114.12841  ]]\n",
      "############### PREDICTIONS ###############\n"
     ]
    }
   ],
   "source": [
    "def prdict_and_print(nr):\n",
    "    t = test_df.values[nr][1]\n",
    "    data = load_img(path = t, grayscale = True)\n",
    "    data = tf.keras.utils.img_to_array(data, data_format=\"channels_last\", dtype=\"float32\")\n",
    "    data /= 255\n",
    "    print(\"@@@@@@@\", data[250][50])\n",
    "    data.shape = (1,) + data.shape\n",
    "    X = np.asarray(data)\n",
    "    print(\"----------{}----------\".format(nr))\n",
    "    euler = t.split(\"_\")\n",
    "    print(\"phi1\", float(euler[3]))\n",
    "    print(\"PHI\",   float(euler[4]))\n",
    "    print(\"phi2\",  float(euler[5][:-4]))\n",
    "    yhat = model.predict(X)\n",
    "    print(\"predicted values\", yhat*90)\n",
    "\n",
    "    \n",
    "print(\"############### PREDICTIONS ###############\")\n",
    "for i in range(10):\n",
    "    prdict_and_print(i)\n",
    "print(\"############### PREDICTIONS ###############\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fc682f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e54ba01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
