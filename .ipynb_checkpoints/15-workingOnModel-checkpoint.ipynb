{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad176564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-22 10:25:27.931533: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-22 10:25:33.197632: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /appl/cudnn/v8.3.2.44-prod-cuda-11.5/lib:/appl/cuda/11.6.0/lib64:/appl/python/3.10.7/lib:/appl/gcc/11.3.0-binutils-2.38/lib64:/appl/gcc/11.3.0-binutils-2.38/lib:/lsf/10.1/linux3.10-glibc2.17-x86_64/lib\n",
      "2023-01-22 10:25:33.198458: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /appl/cudnn/v8.3.2.44-prod-cuda-11.5/lib:/appl/cuda/11.6.0/lib64:/appl/python/3.10.7/lib:/appl/gcc/11.3.0-binutils-2.38/lib64:/appl/gcc/11.3.0-binutils-2.38/lib:/lsf/10.1/linux3.10-glibc2.17-x86_64/lib\n",
      "2023-01-22 10:25:33.198496: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Model\n",
    "from keras.utils import Sequence\n",
    "from keras.utils import load_img\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c74d1b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jan 22 10:25:41 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 525.60.13    Driver Version: 525.60.13    CUDA Version: 12.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-PCIE...  On   | 00000000:37:00.0 Off |                    0 |\r\n",
      "| N/A   30C    P0    25W / 250W |      0MiB / 16384MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla V100-PCIE...  On   | 00000000:AF:00.0 Off |                    0 |\r\n",
      "| N/A   33C    P0    37W / 250W |  15580MiB / 16384MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    1   N/A  N/A     17370      C   .../project/venv/bin/python3    15576MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb1c0c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('black_background_500x500.csv')\n",
    "train_df = df[df['ImagePath'].str.contains(\"train\")]\n",
    "test_df = df[df['ImagePath'].str.contains(\"test\")]\n",
    "valid_df = df[df['ImagePath'].str.contains(\"valid\")]\n",
    "\n",
    "input_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f533699f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "################## data generator #######################\n",
    "#########################################################\n",
    "class datagenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, \n",
    "            batch_size, \n",
    "            img_size,\n",
    "            data_paths_df,\n",
    "            input_channels,\n",
    "            output_channels):\n",
    "         \n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.data_paths_df = data_paths_df\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "        self.data_paths = data_paths_df.values[:,1]\n",
    "        self.params = data_paths_df.values[:,3:6]\n",
    "        assert len(self.data_paths) == len(self.params)\n",
    "        \n",
    "        self.n = len(self.data_paths)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'updates indexes after each epoch'\n",
    "        self.data_paths_df = self.data_paths_df.sample(frac = 1)\n",
    "        self.data_paths = self.data_paths_df.values[:,1]\n",
    "        self.params = self.data_paths_df.values[:,3:6]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_data_paths = self.data_paths[index : index + self.batch_size]\n",
    "        batch_params_paths = self.params[index : index + self.batch_size]\n",
    "\n",
    "        return self.__dataloader(self.img_size,\n",
    "                batch_data_paths, batch_params_paths,\n",
    "                self.input_channels, self.output_channels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size\n",
    "\n",
    "    #################### data loader ########################\n",
    "    def __dataloader(self, \n",
    "            img_size,\n",
    "            data_paths,\n",
    "            batch_params_paths,\n",
    "            input_channels,\n",
    "            output_channels):\n",
    "        x = np.zeros((len(data_paths), img_size[0], img_size[1], input_channels))\n",
    "        y = batch_params_paths        \n",
    "        \n",
    "        for i in range(len(data_paths)):\n",
    "            data = load_img(path = data_paths[i], grayscale = True)\n",
    "            data = tf.keras.utils.img_to_array(data, data_format=\"channels_last\", dtype=\"float32\")\n",
    "            data /= 255\n",
    "            data.shape = (1,) + data.shape\n",
    "            x[i] = np.asarray(data)\n",
    "        return x.astype(\"float32\"), np.array(y).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76b23ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 500, 500, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 498, 498, 32)      320       \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 496, 496, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 124, 124, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 122, 122, 32)      9248      \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 120, 120, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 30, 30, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 26, 26, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 6, 6, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1152)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               147584    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 16)                2064      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 196,259\n",
      "Trainable params: 196,259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(input_size, input_size, 1))\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=4)(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=4)(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=4)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(3)(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "901d44f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "  \n",
    "def abs_loss_function(y_true, y_pred):   \n",
    "    abs_diff = K.abs(y_true - y_pred)\n",
    "    ones = tf.ones_like(y_true)\n",
    "    abs_diff_reversed = K.abs(ones - abs_diff )   \n",
    "    minimum_from_two = tf.math.minimum(abs_diff, abs_diff_reversed) \n",
    "    return tf.math.reduce_mean(minimum_from_two, axis=-1)\n",
    "\n",
    "def square_abs_min_loss(y_true, y_pred):   \n",
    "    abs_diff = K.abs(y_true - y_pred)\n",
    "    ones = tf.ones_like(y_true)\n",
    "    abs_diff_reversed = K.abs(tf.ones_like(y_true) - abs_diff )   \n",
    "    minimum_from_two = tf.math.minimum(abs_diff, abs_diff_reversed) \n",
    "    min_sq = tf.math.sqrt(minimum_from_two)\n",
    "    return tf.math.reduce_mean(min_sq, axis=-1) \n",
    "\n",
    "def smart_square_abs_min_loss(y_true, y_pred):  \n",
    "    punished_y_pred = tf.where((y_pred<0)|(y_pred>1), 3.0 + K.abs(y_pred),y_pred)\n",
    "    \n",
    "    abs_diff = K.abs(y_true - punished_y_pred)\n",
    "    ones = tf.ones_like(y_true)\n",
    "    abs_diff_reversed = K.abs(ones - abs_diff)   \n",
    "    minimum_from_two = tf.math.minimum(abs_diff, abs_diff_reversed) \n",
    "#     print(\"_________________ 1 __________________\")\n",
    "#     print(abs_diff.numpy())\n",
    "#     print(\"_________________ 2 __________________\")\n",
    "#     print(y_pred.numpy())\n",
    "    print(\"_________________ 3 __________________\")\n",
    "    print(punished_y_pred.numpy())\n",
    "    \n",
    "    return tf.math.reduce_mean(minimum_from_two, axis=-1)\n",
    "    \n",
    "############################# For debugging ####################################\n",
    "#     print(\"_________________ 1 __________________\")\n",
    "#     print(abs_diff_reversed.numpy())\n",
    "#     print(\"_________________ 2 __________________\")\n",
    "#     print(abs_diff.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce477929",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = RMSprop(learning_rate=0.001),\n",
    "              loss = smart_square_abs_min_loss, \n",
    "              metrics = [smart_square_abs_min_loss],\n",
    "              run_eagerly=True)  # Add run_eagerly=True to enable the numpy debugging\n",
    "\n",
    "tg = datagenerator(32, (input_size,input_size), train_df, 1, 3)\n",
    "vg = datagenerator(32, (input_size,input_size), valid_df, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cb2aa76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-22 10:34:50.162699: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 968.77MiB (rounded to 1015824384)requested by op Conv2D\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-01-22 10:34:50.162781: I tensorflow/tsl/framework/bfc_allocator.cc:1034] BFCAllocator dump for GPU_0_bfc\n",
      "2023-01-22 10:34:50.162818: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (256): \tTotal Chunks: 80, Chunks in use: 80. 20.0KiB allocated for chunks. 20.0KiB in use in bin. 4.1KiB client-requested in use in bin.\n",
      "2023-01-22 10:34:50.162848: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (512): \tTotal Chunks: 4, Chunks in use: 4. 2.0KiB allocated for chunks. 2.0KiB in use in bin. 2.0KiB client-requested in use in bin.\n",
      "2023-01-22 10:34:50.162876: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1024): \tTotal Chunks: 4, Chunks in use: 4. 5.0KiB allocated for chunks. 5.0KiB in use in bin. 4.4KiB client-requested in use in bin.\n",
      "2023-01-22 10:34:50.162902: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-22 10:34:50.162930: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4096): \tTotal Chunks: 1, Chunks in use: 1. 7.8KiB allocated for chunks. 7.8KiB in use in bin. 7.6KiB client-requested in use in bin.\n",
      "2023-01-22 10:34:50.162958: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8192): \tTotal Chunks: 13, Chunks in use: 11. 117.0KiB allocated for chunks. 99.8KiB in use in bin. 95.0KiB client-requested in use in bin.\n",
      "2023-01-22 10:34:50.162984: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-22 10:34:50.163013: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (32768): \tTotal Chunks: 18, Chunks in use: 17. 713.0KiB allocated for chunks. 657.0KiB in use in bin. 614.0KiB client-requested in use in bin.\n",
      "2023-01-22 10:34:50.163038: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-22 10:34:50.163062: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-22 10:34:50.163108: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-22 10:34:50.163135: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (524288): \tTotal Chunks: 6, Chunks in use: 4. 3.88MiB allocated for chunks. 2.63MiB in use in bin. 2.63MiB client-requested in use in bin.\n",
      "2023-01-22 10:34:50.163159: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-22 10:34:50.163181: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-22 10:34:50.163204: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-22 10:34:50.163226: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-22 10:34:50.163253: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16777216): \tTotal Chunks: 1, Chunks in use: 1. 30.52MiB allocated for chunks. 30.52MiB in use in bin. 30.52MiB client-requested in use in bin.\n",
      "2023-01-22 10:34:50.163278: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (33554432): \tTotal Chunks: 1, Chunks in use: 0. 41.14MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-22 10:34:50.163300: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-22 10:34:50.163323: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-22 10:34:50.163347: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-22 10:34:50.163372: I tensorflow/tsl/framework/bfc_allocator.cc:1057] Bin for 968.77MiB was 256.00MiB, Chunk State: \n",
      "2023-01-22 10:34:50.163392: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 80098304\n",
      "2023-01-22 10:34:50.163419: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8000000 of size 1280 next 1\n",
      "2023-01-22 10:34:50.163439: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8000500 of size 256 next 2\n",
      "2023-01-22 10:34:50.163459: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8000600 of size 256 next 3\n",
      "2023-01-22 10:34:50.163478: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8000700 of size 256 next 5\n",
      "2023-01-22 10:34:50.163497: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8000800 of size 256 next 6\n",
      "2023-01-22 10:34:50.163516: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8000900 of size 256 next 4\n",
      "2023-01-22 10:34:50.163535: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8000a00 of size 256 next 7\n",
      "2023-01-22 10:34:50.163554: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8000b00 of size 256 next 12\n",
      "2023-01-22 10:34:50.163573: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8000c00 of size 256 next 10\n",
      "2023-01-22 10:34:50.163592: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8000d00 of size 256 next 11\n",
      "2023-01-22 10:34:50.163611: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8000e00 of size 256 next 17\n",
      "2023-01-22 10:34:50.163629: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8000f00 of size 256 next 15\n",
      "2023-01-22 10:34:50.163648: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8001000 of size 256 next 16\n",
      "2023-01-22 10:34:50.163667: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8001100 of size 256 next 123\n",
      "2023-01-22 10:34:50.163686: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8001200 of size 256 next 126\n",
      "2023-01-22 10:34:50.163704: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8001300 of size 256 next 114\n",
      "2023-01-22 10:34:50.163724: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8001400 of size 256 next 107\n",
      "2023-01-22 10:34:50.163742: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8001500 of size 256 next 110\n",
      "2023-01-22 10:34:50.163761: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8001600 of size 256 next 117\n",
      "2023-01-22 10:34:50.163781: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8001700 of size 512 next 125\n",
      "2023-01-22 10:34:50.163800: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8001900 of size 256 next 122\n",
      "2023-01-22 10:34:50.163819: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8001a00 of size 256 next 115\n",
      "2023-01-22 10:34:50.163838: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8001b00 of size 256 next 108\n",
      "2023-01-22 10:34:50.163856: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8001c00 of size 256 next 113\n",
      "2023-01-22 10:34:50.163876: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8001d00 of size 256 next 124\n",
      "2023-01-22 10:34:50.163895: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8001e00 of size 1280 next 120\n",
      "2023-01-22 10:34:50.163914: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f61d8002300 of size 9472 next 8\n",
      "2023-01-22 10:34:50.163934: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8004800 of size 7936 next 9\n",
      "2023-01-22 10:34:50.163952: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8006700 of size 256 next 20\n",
      "2023-01-22 10:34:50.163972: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8006800 of size 256 next 18\n",
      "2023-01-22 10:34:50.163990: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8006900 of size 256 next 21\n",
      "2023-01-22 10:34:50.164009: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8006a00 of size 256 next 26\n",
      "2023-01-22 10:34:50.164028: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8006b00 of size 256 next 27\n",
      "2023-01-22 10:34:50.164047: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8006c00 of size 256 next 29\n",
      "2023-01-22 10:34:50.164065: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8006d00 of size 256 next 31\n",
      "2023-01-22 10:34:50.164095: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8006e00 of size 256 next 33\n",
      "2023-01-22 10:34:50.164114: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8006f00 of size 256 next 35\n",
      "2023-01-22 10:34:50.164133: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8007000 of size 512 next 38\n",
      "2023-01-22 10:34:50.164151: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8007200 of size 256 next 36\n",
      "2023-01-22 10:34:50.164170: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8007300 of size 256 next 37\n",
      "2023-01-22 10:34:50.164189: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8007400 of size 256 next 41\n",
      "2023-01-22 10:34:50.164208: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8007500 of size 256 next 42\n",
      "2023-01-22 10:34:50.164227: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8007600 of size 256 next 44\n",
      "2023-01-22 10:34:50.164245: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8007700 of size 256 next 46\n",
      "2023-01-22 10:34:50.164264: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8007800 of size 256 next 45\n",
      "2023-01-22 10:34:50.164283: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8007900 of size 256 next 47\n",
      "2023-01-22 10:34:50.164301: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8007a00 of size 256 next 48\n",
      "2023-01-22 10:34:50.164320: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8007b00 of size 256 next 49\n",
      "2023-01-22 10:34:50.164339: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8007c00 of size 256 next 51\n",
      "2023-01-22 10:34:50.164358: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8007d00 of size 256 next 52\n",
      "2023-01-22 10:34:50.164377: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8007e00 of size 256 next 50\n",
      "2023-01-22 10:34:50.164395: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8007f00 of size 256 next 56\n",
      "2023-01-22 10:34:50.164414: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8008000 of size 256 next 59\n",
      "2023-01-22 10:34:50.164433: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8008100 of size 256 next 61\n",
      "2023-01-22 10:34:50.164451: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8008200 of size 256 next 63\n",
      "2023-01-22 10:34:50.164470: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8008300 of size 256 next 65\n",
      "2023-01-22 10:34:50.164488: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8008400 of size 256 next 53\n",
      "2023-01-22 10:34:50.164508: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8008500 of size 256 next 55\n",
      "2023-01-22 10:34:50.164527: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8008600 of size 512 next 69\n",
      "2023-01-22 10:34:50.164545: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8008800 of size 256 next 67\n",
      "2023-01-22 10:34:50.164564: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8008900 of size 256 next 73\n",
      "2023-01-22 10:34:50.164582: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8008a00 of size 256 next 68\n",
      "2023-01-22 10:34:50.164601: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8008b00 of size 256 next 22\n",
      "2023-01-22 10:34:50.164621: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8008c00 of size 9216 next 23\n",
      "2023-01-22 10:34:50.164641: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800b000 of size 1280 next 54\n",
      "2023-01-22 10:34:50.164660: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800b500 of size 256 next 74\n",
      "2023-01-22 10:34:50.164678: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800b600 of size 256 next 75\n",
      "2023-01-22 10:34:50.164697: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800b700 of size 256 next 76\n",
      "2023-01-22 10:34:50.164716: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800b800 of size 256 next 77\n",
      "2023-01-22 10:34:50.164734: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800b900 of size 256 next 78\n",
      "2023-01-22 10:34:50.164755: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800ba00 of size 256 next 79\n",
      "2023-01-22 10:34:50.164774: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800bb00 of size 256 next 80\n",
      "2023-01-22 10:34:50.164792: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800bc00 of size 1280 next 81\n",
      "2023-01-22 10:34:50.164811: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800c100 of size 256 next 82\n",
      "2023-01-22 10:34:50.164830: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800c200 of size 256 next 83\n",
      "2023-01-22 10:34:50.164849: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800c300 of size 256 next 85\n",
      "2023-01-22 10:34:50.164867: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800c400 of size 256 next 87\n",
      "2023-01-22 10:34:50.164887: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800c500 of size 256 next 89\n",
      "2023-01-22 10:34:50.164905: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800c600 of size 256 next 91\n",
      "2023-01-22 10:34:50.164924: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800c700 of size 512 next 93\n",
      "2023-01-22 10:34:50.164943: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800c900 of size 256 next 94\n",
      "2023-01-22 10:34:50.164961: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800ca00 of size 256 next 95\n",
      "2023-01-22 10:34:50.164980: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800cb00 of size 256 next 96\n",
      "2023-01-22 10:34:50.164999: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800cc00 of size 256 next 97\n",
      "2023-01-22 10:34:50.165018: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800cd00 of size 256 next 98\n",
      "2023-01-22 10:34:50.165037: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800ce00 of size 256 next 99\n",
      "2023-01-22 10:34:50.165056: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800cf00 of size 256 next 100\n",
      "2023-01-22 10:34:50.165075: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800d000 of size 256 next 101\n",
      "2023-01-22 10:34:50.165103: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800d100 of size 256 next 102\n",
      "2023-01-22 10:34:50.165122: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800d200 of size 256 next 103\n",
      "2023-01-22 10:34:50.165141: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800d300 of size 256 next 25\n",
      "2023-01-22 10:34:50.165160: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800d400 of size 9216 next 24\n",
      "2023-01-22 10:34:50.165180: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800f800 of size 14080 next 19\n",
      "2023-01-22 10:34:50.165200: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8012f00 of size 49152 next 14\n",
      "2023-01-22 10:34:50.165220: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d801ef00 of size 50176 next 13\n",
      "2023-01-22 10:34:50.165239: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d802b300 of size 9216 next 28\n",
      "2023-01-22 10:34:50.165258: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d802d700 of size 9216 next 30\n",
      "2023-01-22 10:34:50.165277: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d802fb00 of size 9216 next 32\n",
      "2023-01-22 10:34:50.165299: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8031f00 of size 9216 next 34\n",
      "2023-01-22 10:34:50.165318: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8034300 of size 8192 next 43\n",
      "2023-01-22 10:34:50.165337: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8036300 of size 8192 next 72\n",
      "2023-01-22 10:34:50.165356: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8038300 of size 8192 next 71\n",
      "2023-01-22 10:34:50.165375: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d803a300 of size 57344 next 58\n",
      "2023-01-22 10:34:50.165395: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8048300 of size 36864 next 57\n",
      "2023-01-22 10:34:50.165414: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8051300 of size 36864 next 60\n",
      "2023-01-22 10:34:50.165434: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d805a300 of size 36864 next 62\n",
      "2023-01-22 10:34:50.165452: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8063300 of size 36864 next 64\n",
      "2023-01-22 10:34:50.165471: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d806c300 of size 36864 next 66\n",
      "2023-01-22 10:34:50.165490: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8075300 of size 36864 next 84\n",
      "2023-01-22 10:34:50.165508: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d807e300 of size 36864 next 86\n",
      "2023-01-22 10:34:50.165527: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8087300 of size 36864 next 88\n",
      "2023-01-22 10:34:50.165545: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8090300 of size 36864 next 90\n",
      "2023-01-22 10:34:50.165566: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8099300 of size 589824 next 92\n",
      "2023-01-22 10:34:50.165585: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f61d8129300 of size 8192 next 118\n",
      "2023-01-22 10:34:50.165604: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d812b300 of size 8192 next 104\n",
      "2023-01-22 10:34:50.165623: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f61d812d300 of size 57344 next 127\n",
      "2023-01-22 10:34:50.165642: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d813b300 of size 36864 next 121\n",
      "2023-01-22 10:34:50.165661: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8144300 of size 36864 next 116\n",
      "2023-01-22 10:34:50.165680: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d814d300 of size 36864 next 109\n",
      "2023-01-22 10:34:50.165699: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8156300 of size 36864 next 111\n",
      "2023-01-22 10:34:50.165718: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d815f300 of size 36864 next 119\n",
      "2023-01-22 10:34:50.165737: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f61d8168300 of size 720896 next 40\n",
      "2023-01-22 10:34:50.165756: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8218300 of size 991232 next 39\n",
      "2023-01-22 10:34:50.165775: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d830a300 of size 589824 next 70\n",
      "2023-01-22 10:34:50.165795: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f61d839a300 of size 589824 next 106\n",
      "2023-01-22 10:34:50.165814: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d842a300 of size 589824 next 112\n",
      "2023-01-22 10:34:50.165836: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d84ba300 of size 32000000 next 105\n",
      "2023-01-22 10:34:50.165856: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f61da33eb00 of size 43141376 next 18446744073709551615\n",
      "2023-01-22 10:34:50.165875: I tensorflow/tsl/framework/bfc_allocator.cc:1095]      Summary of in-use Chunks by size: \n",
      "2023-01-22 10:34:50.165898: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 80 Chunks of size 256 totalling 20.0KiB\n",
      "2023-01-22 10:34:50.165920: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 4 Chunks of size 512 totalling 2.0KiB\n",
      "2023-01-22 10:34:50.165940: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 4 Chunks of size 1280 totalling 5.0KiB\n",
      "2023-01-22 10:34:50.165961: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 7936 totalling 7.8KiB\n",
      "2023-01-22 10:34:50.165982: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 4 Chunks of size 8192 totalling 32.0KiB\n",
      "2023-01-22 10:34:50.166004: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 6 Chunks of size 9216 totalling 54.0KiB\n",
      "2023-01-22 10:34:50.166025: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 14080 totalling 13.8KiB\n",
      "2023-01-22 10:34:50.166046: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 14 Chunks of size 36864 totalling 504.0KiB\n",
      "2023-01-22 10:34:50.166067: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 49152 totalling 48.0KiB\n",
      "2023-01-22 10:34:50.166100: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 50176 totalling 49.0KiB\n",
      "2023-01-22 10:34:50.166121: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 57344 totalling 56.0KiB\n",
      "2023-01-22 10:34:50.166142: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 589824 totalling 1.69MiB\n",
      "2023-01-22 10:34:50.166163: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 991232 totalling 968.0KiB\n",
      "2023-01-22 10:34:50.166184: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 32000000 totalling 30.52MiB\n",
      "2023-01-22 10:34:50.166205: I tensorflow/tsl/framework/bfc_allocator.cc:1102] Sum Total of in-use chunks: 33.92MiB\n",
      "2023-01-22 10:34:50.166225: I tensorflow/tsl/framework/bfc_allocator.cc:1104] total_region_allocated_bytes_: 80098304 memory_limit_: 88997888 available bytes: 8899584 curr_region_allocation_bytes_: 177995776\n",
      "2023-01-22 10:34:50.166255: I tensorflow/tsl/framework/bfc_allocator.cc:1110] Stats: \n",
      "Limit:                        88997888\n",
      "InUse:                        35571200\n",
      "MaxInUse:                     35890176\n",
      "NumAllocs:                         307\n",
      "MaxAllocSize:                 32000000\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-01-22 10:34:50.166298: W tensorflow/tsl/framework/bfc_allocator.cc:492] ***********************************************_____________________________________________________\n",
      "2023-01-22 10:34:50.166348: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at conv_ops.cc:698 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[32,498,498,32] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Exception encountered when calling layer 'conv2d_16' (type Conv2D).\n\n{{function_node __wrapped__Conv2D_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[32,498,498,32] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]\n\nCall arguments received by layer 'conv2d_16' (type Conv2D):\n  • inputs=tf.Tensor(shape=(32, 500, 500, 1), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/project/venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/project/venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7215\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7214\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7215\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer 'conv2d_16' (type Conv2D).\n\n{{function_node __wrapped__Conv2D_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[32,498,498,32] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]\n\nCall arguments received by layer 'conv2d_16' (type Conv2D):\n  • inputs=tf.Tensor(shape=(32, 500, 500, 1), dtype=float32)"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=tg,\n",
    "                    batch_size=32,\n",
    "                    epochs=100,\n",
    "                    validation_data=vg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "348f3e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_a():\n",
    "    inputs = keras.Input(shape=(input_size, input_size, 1))\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=4)(x)\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=4)(x)\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=4)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dense(16, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(3)(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_model_b():\n",
    "    inputs = keras.Input(shape=(input_size, input_size, 1))\n",
    "    x = layers.Conv2D(filters=16, kernel_size=11, activation=\"relu\")(inputs)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=7, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=5, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dense(16, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(3)(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "def load_model_c():\n",
    "    inputs = keras.Input(shape=(input_size, input_size, 1))\n",
    "    x = layers.Conv2D(filters=16, kernel_size=11, activation=\"relu\")(inputs)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=7, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=5, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.01))(x)\n",
    "    x = layers.Dense(16, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.01))(x) \n",
    "    outputs = layers.Dense(3)(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def plot_accuracy_loss(history):\n",
    "    \"\"\"\n",
    "        Plot the accuracy and the loss during the training of the nn.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(12,5))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(221)\n",
    "    plt.plot(history.history['accuracy'],'bo--', label = \"acc\")\n",
    "    plt.plot(history.history['val_accuracy'],'ro--', label = \"val_accuracy\")\n",
    "    plt.title(\"train_acc vs val_acc\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot loss function\n",
    "    plt.subplot(222)\n",
    "    plt.plot(history.history['loss'],'bo--', label = \"loss\")\n",
    "    plt.plot(history.history['val_loss'],'ro--', label = \"val_loss\")\n",
    "    plt.title(\"train_loss vs val_loss\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "def load_and_train_model(model, epochs = 100, loss_func = abs_loss_function):\n",
    "    tg = datagenerator(32, (input_size,input_size), train_df, 1, 3)\n",
    "    vg = datagenerator(32, (input_size,input_size), valid_df, 1, 3)\n",
    "    model.compile(optimizer = RMSprop(learning_rate=0.001),\n",
    "                  loss = loss_func, \n",
    "                  metrics = [\"accuracy\", loss_func])  # Add run_eagerly=True to enable the numpy debugging\n",
    "    \n",
    "    history = model.fit(x=tg,\n",
    "                        batch_size=32,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=vg)\n",
    "    \n",
    "    \n",
    "    plot_accuracy_loss(history)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64b487d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 500, 500, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 498, 498, 32)      320       \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 496, 496, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 124, 124, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 122, 122, 32)      9248      \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 120, 120, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 30, 30, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 26, 26, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 6, 6, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1152)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               147584    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                2064      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 196,259\n",
      "Trainable params: 196,259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_a = load_model_a()\n",
    "model_a.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c7b8c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/utils/image_utils.py:409: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-22 10:26:16.291667: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 968.77MiB (rounded to 1015824384)requested by op model_1/conv2d_10/Relu\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-01-22 10:26:16.291764: I tensorflow/tsl/framework/bfc_allocator.cc:1034] BFCAllocator dump for GPU_0_bfc\n",
      "2023-01-22 10:26:16.291803: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (256): \tTotal Chunks: 83, Chunks in use: 82. 20.8KiB allocated for chunks. 20.5KiB in use in bin. 4.4KiB client-requested in use in bin.\n",
      "2023-01-22 10:26:16.291830: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (512): \tTotal Chunks: 6, Chunks in use: 6. 3.0KiB allocated for chunks. 3.0KiB in use in bin. 2.8KiB client-requested in use in bin.\n",
      "2023-01-22 10:26:16.291855: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1024): \tTotal Chunks: 4, Chunks in use: 4. 5.0KiB allocated for chunks. 5.0KiB in use in bin. 4.4KiB client-requested in use in bin.\n",
      "2023-01-22 10:26:16.291879: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-22 10:26:16.291904: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4096): \tTotal Chunks: 1, Chunks in use: 1. 7.8KiB allocated for chunks. 7.8KiB in use in bin. 7.6KiB client-requested in use in bin.\n",
      "2023-01-22 10:26:16.291931: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8192): \tTotal Chunks: 11, Chunks in use: 11. 101.5KiB allocated for chunks. 101.5KiB in use in bin. 95.0KiB client-requested in use in bin.\n",
      "2023-01-22 10:26:16.291954: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-22 10:26:16.291981: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (32768): \tTotal Chunks: 17, Chunks in use: 17. 657.0KiB allocated for chunks. 657.0KiB in use in bin. 614.0KiB client-requested in use in bin.\n",
      "2023-01-22 10:26:16.292003: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-22 10:26:16.292026: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-22 10:26:16.292048: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-22 10:26:16.292072: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (524288): \tTotal Chunks: 4, Chunks in use: 4. 2.93MiB allocated for chunks. 2.93MiB in use in bin. 2.63MiB client-requested in use in bin.\n",
      "2023-01-22 10:26:16.292114: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-22 10:26:16.292136: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-22 10:26:16.292158: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-22 10:26:16.292180: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-22 10:26:16.292207: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16777216): \tTotal Chunks: 1, Chunks in use: 1. 30.52MiB allocated for chunks. 30.52MiB in use in bin. 30.52MiB client-requested in use in bin.\n",
      "2023-01-22 10:26:16.292232: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (33554432): \tTotal Chunks: 1, Chunks in use: 0. 42.16MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-22 10:26:16.292254: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-22 10:26:16.292277: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-22 10:26:16.292300: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-01-22 10:26:16.292325: I tensorflow/tsl/framework/bfc_allocator.cc:1057] Bin for 968.77MiB was 256.00MiB, Chunk State: \n",
      "2023-01-22 10:26:16.292345: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 80098304\n",
      "2023-01-22 10:26:16.292370: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8000000 of size 1280 next 1\n",
      "2023-01-22 10:26:16.292391: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8000500 of size 256 next 2\n",
      "2023-01-22 10:26:16.292411: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8000600 of size 256 next 3\n",
      "2023-01-22 10:26:16.292430: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8000700 of size 256 next 5\n",
      "2023-01-22 10:26:16.292449: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8000800 of size 256 next 6\n",
      "2023-01-22 10:26:16.292467: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8000900 of size 256 next 4\n",
      "2023-01-22 10:26:16.292486: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8000a00 of size 256 next 7\n",
      "2023-01-22 10:26:16.292505: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8000b00 of size 256 next 12\n",
      "2023-01-22 10:26:16.292524: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8000c00 of size 256 next 10\n",
      "2023-01-22 10:26:16.292543: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8000d00 of size 256 next 11\n",
      "2023-01-22 10:26:16.292562: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8000e00 of size 256 next 17\n",
      "2023-01-22 10:26:16.292581: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8000f00 of size 256 next 15\n",
      "2023-01-22 10:26:16.292599: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8001000 of size 256 next 16\n",
      "2023-01-22 10:26:16.292618: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8001100 of size 256 next 104\n",
      "2023-01-22 10:26:16.292637: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8001200 of size 1280 next 105\n",
      "2023-01-22 10:26:16.292656: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8001700 of size 256 next 106\n",
      "2023-01-22 10:26:16.292676: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8001800 of size 512 next 107\n",
      "2023-01-22 10:26:16.292695: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8001a00 of size 256 next 109\n",
      "2023-01-22 10:26:16.292714: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8001b00 of size 256 next 110\n",
      "2023-01-22 10:26:16.292733: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8001c00 of size 256 next 111\n",
      "2023-01-22 10:26:16.292752: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8001d00 of size 256 next 113\n",
      "2023-01-22 10:26:16.292770: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8001e00 of size 256 next 114\n",
      "2023-01-22 10:26:16.292789: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8001f00 of size 256 next 116\n",
      "2023-01-22 10:26:16.292808: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8002000 of size 256 next 117\n",
      "2023-01-22 10:26:16.292828: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8002100 of size 9984 next 8\n",
      "2023-01-22 10:26:16.292848: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8004800 of size 7936 next 9\n",
      "2023-01-22 10:26:16.292867: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8006700 of size 256 next 20\n",
      "2023-01-22 10:26:16.292886: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8006800 of size 256 next 18\n",
      "2023-01-22 10:26:16.292905: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8006900 of size 256 next 21\n",
      "2023-01-22 10:26:16.292925: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8006a00 of size 256 next 26\n",
      "2023-01-22 10:26:16.292943: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8006b00 of size 256 next 27\n",
      "2023-01-22 10:26:16.292962: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8006c00 of size 256 next 29\n",
      "2023-01-22 10:26:16.292981: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8006d00 of size 256 next 31\n",
      "2023-01-22 10:26:16.292999: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8006e00 of size 256 next 33\n",
      "2023-01-22 10:26:16.293018: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8006f00 of size 256 next 35\n",
      "2023-01-22 10:26:16.293037: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8007000 of size 512 next 38\n",
      "2023-01-22 10:26:16.293056: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8007200 of size 256 next 36\n",
      "2023-01-22 10:26:16.293074: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8007300 of size 256 next 37\n",
      "2023-01-22 10:26:16.293103: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8007400 of size 256 next 41\n",
      "2023-01-22 10:26:16.293122: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8007500 of size 256 next 42\n",
      "2023-01-22 10:26:16.293141: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8007600 of size 256 next 44\n",
      "2023-01-22 10:26:16.293159: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8007700 of size 256 next 46\n",
      "2023-01-22 10:26:16.293178: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8007800 of size 256 next 45\n",
      "2023-01-22 10:26:16.293197: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8007900 of size 256 next 47\n",
      "2023-01-22 10:26:16.293216: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8007a00 of size 256 next 48\n",
      "2023-01-22 10:26:16.293234: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8007b00 of size 256 next 49\n",
      "2023-01-22 10:26:16.293253: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8007c00 of size 256 next 51\n",
      "2023-01-22 10:26:16.293272: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8007d00 of size 256 next 52\n",
      "2023-01-22 10:26:16.293290: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8007e00 of size 256 next 50\n",
      "2023-01-22 10:26:16.293309: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8007f00 of size 256 next 56\n",
      "2023-01-22 10:26:16.293328: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8008000 of size 256 next 59\n",
      "2023-01-22 10:26:16.293347: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8008100 of size 256 next 61\n",
      "2023-01-22 10:26:16.293365: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8008200 of size 256 next 63\n",
      "2023-01-22 10:26:16.293384: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8008300 of size 256 next 65\n",
      "2023-01-22 10:26:16.293403: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8008400 of size 256 next 53\n",
      "2023-01-22 10:26:16.293421: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8008500 of size 256 next 55\n",
      "2023-01-22 10:26:16.293440: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8008600 of size 512 next 69\n",
      "2023-01-22 10:26:16.293459: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8008800 of size 256 next 67\n",
      "2023-01-22 10:26:16.293477: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8008900 of size 256 next 73\n",
      "2023-01-22 10:26:16.293496: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8008a00 of size 256 next 68\n",
      "2023-01-22 10:26:16.293515: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8008b00 of size 256 next 22\n",
      "2023-01-22 10:26:16.293534: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8008c00 of size 9216 next 23\n",
      "2023-01-22 10:26:16.293554: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800b000 of size 1280 next 54\n",
      "2023-01-22 10:26:16.293572: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800b500 of size 256 next 74\n",
      "2023-01-22 10:26:16.293591: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800b600 of size 256 next 75\n",
      "2023-01-22 10:26:16.293610: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800b700 of size 256 next 76\n",
      "2023-01-22 10:26:16.293629: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800b800 of size 256 next 77\n",
      "2023-01-22 10:26:16.293648: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800b900 of size 256 next 78\n",
      "2023-01-22 10:26:16.293666: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800ba00 of size 256 next 79\n",
      "2023-01-22 10:26:16.293686: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800bb00 of size 256 next 80\n",
      "2023-01-22 10:26:16.293705: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800bc00 of size 1280 next 81\n",
      "2023-01-22 10:26:16.293724: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800c100 of size 256 next 82\n",
      "2023-01-22 10:26:16.293743: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800c200 of size 256 next 83\n",
      "2023-01-22 10:26:16.293762: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800c300 of size 256 next 85\n",
      "2023-01-22 10:26:16.293780: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800c400 of size 256 next 87\n",
      "2023-01-22 10:26:16.293799: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800c500 of size 256 next 89\n",
      "2023-01-22 10:26:16.293818: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800c600 of size 256 next 91\n",
      "2023-01-22 10:26:16.293837: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800c700 of size 512 next 93\n",
      "2023-01-22 10:26:16.293855: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800c900 of size 256 next 94\n",
      "2023-01-22 10:26:16.293874: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800ca00 of size 256 next 95\n",
      "2023-01-22 10:26:16.293893: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800cb00 of size 256 next 96\n",
      "2023-01-22 10:26:16.293912: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800cc00 of size 256 next 97\n",
      "2023-01-22 10:26:16.293931: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800cd00 of size 256 next 98\n",
      "2023-01-22 10:26:16.293950: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800ce00 of size 256 next 99\n",
      "2023-01-22 10:26:16.293969: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800cf00 of size 256 next 100\n",
      "2023-01-22 10:26:16.293988: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800d000 of size 256 next 101\n",
      "2023-01-22 10:26:16.294006: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800d100 of size 256 next 102\n",
      "2023-01-22 10:26:16.294025: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800d200 of size 256 next 103\n",
      "2023-01-22 10:26:16.294044: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800d300 of size 256 next 25\n",
      "2023-01-22 10:26:16.294063: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800d400 of size 9216 next 24\n",
      "2023-01-22 10:26:16.294094: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d800f800 of size 14080 next 19\n",
      "2023-01-22 10:26:16.294114: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8012f00 of size 49152 next 14\n",
      "2023-01-22 10:26:16.294134: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d801ef00 of size 50176 next 13\n",
      "2023-01-22 10:26:16.294153: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d802b300 of size 9216 next 28\n",
      "2023-01-22 10:26:16.294172: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d802d700 of size 9216 next 30\n",
      "2023-01-22 10:26:16.294191: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d802fb00 of size 9216 next 32\n",
      "2023-01-22 10:26:16.294210: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8031f00 of size 9216 next 34\n",
      "2023-01-22 10:26:16.294229: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8034300 of size 8192 next 43\n",
      "2023-01-22 10:26:16.294249: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8036300 of size 8192 next 72\n",
      "2023-01-22 10:26:16.294268: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8038300 of size 8192 next 71\n",
      "2023-01-22 10:26:16.294287: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d803a300 of size 57344 next 58\n",
      "2023-01-22 10:26:16.294307: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8048300 of size 36864 next 57\n",
      "2023-01-22 10:26:16.294326: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8051300 of size 36864 next 60\n",
      "2023-01-22 10:26:16.294345: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d805a300 of size 36864 next 62\n",
      "2023-01-22 10:26:16.294364: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8063300 of size 36864 next 64\n",
      "2023-01-22 10:26:16.294383: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d806c300 of size 36864 next 66\n",
      "2023-01-22 10:26:16.294401: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8075300 of size 36864 next 84\n",
      "2023-01-22 10:26:16.294420: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d807e300 of size 36864 next 86\n",
      "2023-01-22 10:26:16.294439: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8087300 of size 36864 next 88\n",
      "2023-01-22 10:26:16.294458: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8090300 of size 36864 next 90\n",
      "2023-01-22 10:26:16.294478: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8099300 of size 589824 next 92\n",
      "2023-01-22 10:26:16.294498: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8129300 of size 36864 next 108\n",
      "2023-01-22 10:26:16.294518: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8132300 of size 36864 next 112\n",
      "2023-01-22 10:26:16.294537: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d813b300 of size 905216 next 40\n",
      "2023-01-22 10:26:16.294557: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d8218300 of size 991232 next 39\n",
      "2023-01-22 10:26:16.294576: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d830a300 of size 589824 next 70\n",
      "2023-01-22 10:26:16.294595: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d839a300 of size 36864 next 115\n",
      "2023-01-22 10:26:16.294614: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d83a3300 of size 36864 next 118\n",
      "2023-01-22 10:26:16.294634: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d83ac300 of size 36864 next 119\n",
      "2023-01-22 10:26:16.294653: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d83b5300 of size 256 next 120\n",
      "2023-01-22 10:26:16.294672: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d83b5400 of size 256 next 121\n",
      "2023-01-22 10:26:16.294692: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61d83b5500 of size 32000000 next 122\n",
      "2023-01-22 10:26:16.294711: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61da239d00 of size 512 next 123\n",
      "2023-01-22 10:26:16.294730: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61da239f00 of size 512 next 124\n",
      "2023-01-22 10:26:16.294749: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f61da23a100 of size 256 next 125\n",
      "2023-01-22 10:26:16.294768: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61da23a200 of size 256 next 126\n",
      "2023-01-22 10:26:16.294787: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f61da23a300 of size 256 next 127\n",
      "2023-01-22 10:26:16.294806: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f61da23a400 of size 44208128 next 18446744073709551615\n",
      "2023-01-22 10:26:16.294825: I tensorflow/tsl/framework/bfc_allocator.cc:1095]      Summary of in-use Chunks by size: \n",
      "2023-01-22 10:26:16.294848: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 82 Chunks of size 256 totalling 20.5KiB\n",
      "2023-01-22 10:26:16.294870: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 6 Chunks of size 512 totalling 3.0KiB\n",
      "2023-01-22 10:26:16.294890: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 4 Chunks of size 1280 totalling 5.0KiB\n",
      "2023-01-22 10:26:16.294911: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 7936 totalling 7.8KiB\n",
      "2023-01-22 10:26:16.294932: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 8192 totalling 24.0KiB\n",
      "2023-01-22 10:26:16.294953: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 6 Chunks of size 9216 totalling 54.0KiB\n",
      "2023-01-22 10:26:16.294973: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 9984 totalling 9.8KiB\n",
      "2023-01-22 10:26:16.294994: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 14080 totalling 13.8KiB\n",
      "2023-01-22 10:26:16.295016: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 14 Chunks of size 36864 totalling 504.0KiB\n",
      "2023-01-22 10:26:16.295037: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 49152 totalling 48.0KiB\n",
      "2023-01-22 10:26:16.295058: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 50176 totalling 49.0KiB\n",
      "2023-01-22 10:26:16.295078: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 57344 totalling 56.0KiB\n",
      "2023-01-22 10:26:16.295111: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 589824 totalling 1.12MiB\n",
      "2023-01-22 10:26:16.295132: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 905216 totalling 884.0KiB\n",
      "2023-01-22 10:26:16.295153: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 991232 totalling 968.0KiB\n",
      "2023-01-22 10:26:16.295175: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 32000000 totalling 30.52MiB\n",
      "2023-01-22 10:26:16.295196: I tensorflow/tsl/framework/bfc_allocator.cc:1102] Sum Total of in-use chunks: 34.23MiB\n",
      "2023-01-22 10:26:16.295217: I tensorflow/tsl/framework/bfc_allocator.cc:1104] total_region_allocated_bytes_: 80098304 memory_limit_: 88997888 available bytes: 8899584 curr_region_allocation_bytes_: 177995776\n",
      "2023-01-22 10:26:16.295246: I tensorflow/tsl/framework/bfc_allocator.cc:1110] Stats: \n",
      "Limit:                        88997888\n",
      "InUse:                        35889920\n",
      "MaxInUse:                     35890176\n",
      "NumAllocs:                         239\n",
      "MaxAllocSize:                 32000000\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-01-22 10:26:16.295289: W tensorflow/tsl/framework/bfc_allocator.cc:492] *********************************************_______________________________________________________\n",
      "2023-01-22 10:26:16.295355: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at conv_ops_fused_impl.h:766 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[32,32,498,498] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_1/conv2d_10/Relu' defined at (most recent call last):\n    File \"/appl/python/3.10.7/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/appl/python/3.10.7/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 982, in launch_instance\n      app.start()\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/appl/python/3.10.7/lib/python3.10/asyncio/base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"/appl/python/3.10.7/lib/python3.10/asyncio/base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"/appl/python/3.10.7/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_cell\n      result = self._run_cell(\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2940, in _run_cell\n      return runner(coro)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3139, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3318, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_8023/3473977708.py\", line 1, in <module>\n      history_a = load_and_train_model(model_a, 100, abs_loss_function)\n    File \"/tmp/ipykernel_8023/2637437771.py\", line 104, in load_and_train_model\n      history = model.fit(x=tg,\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/layers/convolutional/base_conv.py\", line 314, in call\n      return self.activation(outputs)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/activations.py\", line 317, in relu\n      return backend.relu(\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/backend.py\", line 5369, in relu\n      x = tf.nn.relu(x)\nNode: 'model_1/conv2d_10/Relu'\nOOM when allocating tensor with shape[32,32,498,498] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/conv2d_10/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_2052]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history_a \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_train_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mabs_loss_function\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [6], line 104\u001b[0m, in \u001b[0;36mload_and_train_model\u001b[0;34m(model, epochs, loss_func)\u001b[0m\n\u001b[1;32m     99\u001b[0m vg \u001b[38;5;241m=\u001b[39m datagenerator(\u001b[38;5;241m32\u001b[39m, (input_size,input_size), valid_df, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    100\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer \u001b[38;5;241m=\u001b[39m RMSprop(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m),\n\u001b[1;32m    101\u001b[0m               loss \u001b[38;5;241m=\u001b[39m loss_func, \n\u001b[1;32m    102\u001b[0m               metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss_func])  \u001b[38;5;66;03m# Add run_eagerly=True to enable the numpy debugging\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m plot_accuracy_loss(history)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m~/project/venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/project/venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model_1/conv2d_10/Relu' defined at (most recent call last):\n    File \"/appl/python/3.10.7/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/appl/python/3.10.7/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 982, in launch_instance\n      app.start()\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/appl/python/3.10.7/lib/python3.10/asyncio/base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"/appl/python/3.10.7/lib/python3.10/asyncio/base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"/appl/python/3.10.7/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_cell\n      result = self._run_cell(\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2940, in _run_cell\n      return runner(coro)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3139, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3318, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_8023/3473977708.py\", line 1, in <module>\n      history_a = load_and_train_model(model_a, 100, abs_loss_function)\n    File \"/tmp/ipykernel_8023/2637437771.py\", line 104, in load_and_train_model\n      history = model.fit(x=tg,\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/layers/convolutional/base_conv.py\", line 314, in call\n      return self.activation(outputs)\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/activations.py\", line 317, in relu\n      return backend.relu(\n    File \"/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/backend.py\", line 5369, in relu\n      x = tf.nn.relu(x)\nNode: 'model_1/conv2d_10/Relu'\nOOM when allocating tensor with shape[32,32,498,498] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/conv2d_10/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_2052]"
     ]
    }
   ],
   "source": [
    "history_a = load_and_train_model(model_a, 100, abs_loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfee6523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 500, 500, 1)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 490, 490, 16)      1952      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 484, 484, 16)      12560     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 242, 242, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 238, 238, 16)      6416      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 236, 236, 16)      2320      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 118, 118, 16)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 116, 116, 16)      2320      \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 114, 114, 16)      2320      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 57, 57, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 55, 55, 16)        2320      \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 53, 53, 16)        2320      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 26, 26, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 24, 24, 16)        2320      \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 22, 22, 16)        2320      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 11, 11, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1936)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               247936    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                2064      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 287,219\n",
      "Trainable params: 287,219\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-22 10:25:52.466577: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-22 10:25:53.159438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 84 MB memory:  -> device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:af:00.0, compute capability: 7.0\n",
      "2023-01-22 10:25:53.201583: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:735] failed to allocate 84.88M (88997888 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    }
   ],
   "source": [
    "model_b = load_model_b()\n",
    "model_b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278d0a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_b = load_and_train_model(model_b, 100, abs_loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1179a5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_c = load_model_c()\n",
    "model_c.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4886c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_c = load_and_train_model(model_c, 100, abs_loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dd1aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_loss(history, name):\n",
    "    \"\"\"\n",
    "        Plot the accuracy and the loss during the training of the nn.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(12,5))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(221)\n",
    "    plt.plot(history.history['accuracy'],'bo--', label = \"acc\")\n",
    "    plt.plot(history.history['val_accuracy'],'ro--', label = \"val_accuracy\")\n",
    "    plt.title(\"train_acc vs val_acc\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot loss function\n",
    "    plt.subplot(222)\n",
    "    plt.plot(history.history['loss'],'bo--', label = \"loss\")\n",
    "    plt.plot(history.history['val_loss'],'ro--', label = \"val_loss\")\n",
    "    plt.title(\"train_loss vs val_loss\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "def load_and_train_model(model, epochs = 100, loss_func = abs_loss_function):\n",
    "    tg = datagenerator(32, (input_size,input_size), train_df, 1, 3)\n",
    "    vg = datagenerator(32, (input_size,input_size), valid_df, 1, 3)\n",
    "    model.compile(optimizer = RMSprop(learning_rate=0.001),\n",
    "                  loss = loss_func, \n",
    "                  metrics = [\"accuracy\", loss_func])  # Add run_eagerly=True to enable the numpy debugging\n",
    "    \n",
    "    history = model.fit(x=tg,\n",
    "                        batch_size=32,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=vg)\n",
    "    \n",
    "    \n",
    "    plot_accuracy_loss(history)\n",
    "    plt.savefig(\"{}.png\".format(name))\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58320726",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_loss(history_a)\n",
    "plot_accuracy_loss(history_b)\n",
    "plot_accuracy_loss(history_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d23dbb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407f977b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2674f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a198f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e376a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f86d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b7f00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tg = datagenerator(32, (input_size,input_size), test_df, 1, 3)\n",
    "results = model.evaluate(tg, batch_size=32)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17920843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273/273 [==============================] - 81s 295ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(tg)  \n",
    "pred_labels = np.argmax(predictions, axis = 1) # We take the highest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac897972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09319372, -0.09715339, -0.4401111 ],\n",
       "       [ 0.10896346, -0.09794684,  0.43132466],\n",
       "       [-0.11465664, -0.50270516,  0.34233922],\n",
       "       ...,\n",
       "       [-0.33013004,  0.02928903,  0.40266126],\n",
       "       [ 0.11292583,  0.03262499, -0.21218629],\n",
       "       [ 0.3510595 ,  0.09084932,  0.38770646]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c211ded7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database/black_background_500x500/test/f9e05a9a8aed11edae8b98f2b3f0b0a8_76.0_83.7_2.9.png\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[[71.460754 80.83591  14.106417]]\n"
     ]
    }
   ],
   "source": [
    "t = test_df.values[1][1]\n",
    "data = load_img(path = t, grayscale = True)\n",
    "data = tf.keras.utils.img_to_array(data, data_format=\"channels_last\", dtype=\"float32\")\n",
    "data /= 255\n",
    "data.shape = (1,) + data.shape\n",
    "X = np.asarray(data)\n",
    "\n",
    "print(t)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def predict_data(d):\n",
    "    yhat = model.predict(data)\n",
    "    yhat2 = np.where(yhat<0, 1+yhat, yhat)\n",
    "    print(yhat2*90)\n",
    "\n",
    "predict_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24791fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b84982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prdict_and_print(nr):\n",
    "    t = test_df.values[nr][1]\n",
    "    data = load_img(path = t, grayscale = True)\n",
    "    data = tf.keras.utils.img_to_array(data, data_format=\"channels_last\", dtype=\"float32\")\n",
    "    data /= 255\n",
    "    data.shape = (1,) + data.shape\n",
    "    X = np.asarray(data)\n",
    "    print(\"----------{}----------\".format(nr))\n",
    "    euler = test_df.values[nr]\n",
    "    print(\"phi1\", float(euler[3])*90)\n",
    "    print(\"PHI\",   float(euler[4])*90)\n",
    "    print(\"phi2\",  float(euler[5])*90)\n",
    "    yhat = model.predict(data)\n",
    "    print(\"predicted values\", yhat*90)\n",
    "\n",
    "    \n",
    "print(\"############### PREDICTIONS ###############\")\n",
    "for i in range(10):\n",
    "    prdict_and_print(i)\n",
    "print(\"############### PREDICTIONS ###############\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4de24180",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Best_model_so_far_abs_loss_function_RMSprop\"\n",
    "model.save(\"Models/{}.h5\".format(model_name), save_format = 'h5')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec3990ea",
   "metadata": {},
   "source": [
    "from keras.models import load_model \n",
    "from tensorflow.keras.utils import CustomObjectScope\n",
    "\n",
    "with CustomObjectScope({'square_abs_min_loss': square_abs_min_loss}):\n",
    "    model2 = keras.models.load_model('Models/one.h5')\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c5dc500",
   "metadata": {},
   "source": [
    "del model "
   ]
  },
  {
   "cell_type": "raw",
   "id": "66e2eafa",
   "metadata": {},
   "source": [
    "epochs = range(1, len(history.history[\"loss\"]) + 1)\n",
    "loss = history.history[\"loss\"]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6231e846",
   "metadata": {},
   "source": [
    "t = test_df.values[45][1]\n",
    "data = load_img(path = t, grayscale = True)\n",
    "data = tf.keras.utils.img_to_array(data, data_format=\"channels_last\", dtype=\"float32\")\n",
    "data /= 255\n",
    "data.shape = (1,) + data.shape\n",
    "X = np.asarray(data)\n",
    "\n",
    "yhat = model.predict(data)\n",
    "print(t)\n",
    "print(yhat*90)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "35a3b3f2",
   "metadata": {},
   "source": [
    "def custom_loss_function(y_true, y_pred):\n",
    "    # Calculate the error for each parameter using sqrt(2 - cos(y_hat - y_pred))\n",
    "    param_1_error = tf.math.sqrt(2 - tf.math.cos(y_true[:, 0] - y_pred[:, 0]))\n",
    "    param_2_error = tf.math.sqrt(2 - tf.math.cos(y_true[:, 1] - y_pred[:, 1]))\n",
    "    param_3_error = tf.math.sqrt(2 - tf.math.cos(y_true[:, 2] - y_pred[:, 2]))\n",
    "\n",
    "    # Calculate the total loss as the mean of the errors for each parameter\n",
    "    total_loss = (param_1_error + param_2_error + param_3_error) / 3\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "96510eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_accuracy_loss(history):\n",
    "    \"\"\"\n",
    "        Plot the accuracy and the loss during the training of the nn.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(12,5))\n",
    "\n",
    "    # Plot accuracy\n",
    "#     plt.subplot(221)\n",
    "#     plt.plot(history.history['accuracy'],'bo--', label = \"acc\")\n",
    "#     plt.plot(history.history['val_accuracy'],'ro--', label = \"val_accuracy\")\n",
    "#     plt.title(\"train_acc vs val_acc\")\n",
    "#     plt.ylabel(\"accuracy\")\n",
    "#     plt.xlabel(\"epochs\")\n",
    "#     plt.legend()\n",
    "    \n",
    "    # Plot loss function\n",
    "    plt.subplot(222)\n",
    "    plt.plot(history.history['loss'],'bo--', label = \"loss\")\n",
    "    plt.plot(history.history['val_loss'],'ro--', label = \"val_loss\")\n",
    "    plt.title(\"train_loss vs val_loss\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "\n",
    "    plt.legend()\n",
    "#     plt.savefig(\"graph_{}_{}_{}_{}.png\".format(input_size,input_size,input_size,input_size))\n",
    "plot_accuracy_loss(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
