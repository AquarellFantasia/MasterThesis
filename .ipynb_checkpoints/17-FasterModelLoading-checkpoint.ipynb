{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad176564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-22 12:43:18.744623: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-22 12:43:20.606184: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /appl/cudnn/v8.3.2.44-prod-cuda-11.5/lib:/appl/cuda/11.6.0/lib64:/appl/python/3.10.7/lib:/appl/gcc/11.3.0-binutils-2.38/lib64:/appl/gcc/11.3.0-binutils-2.38/lib:/lsf/10.1/linux3.10-glibc2.17-x86_64/lib\n",
      "2023-01-22 12:43:20.606957: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /appl/cudnn/v8.3.2.44-prod-cuda-11.5/lib:/appl/cuda/11.6.0/lib64:/appl/python/3.10.7/lib:/appl/gcc/11.3.0-binutils-2.38/lib64:/appl/gcc/11.3.0-binutils-2.38/lib:/lsf/10.1/linux3.10-glibc2.17-x86_64/lib\n",
      "2023-01-22 12:43:20.606968: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Model\n",
    "from keras.utils import Sequence\n",
    "from keras.utils import load_img\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74d1b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41361242",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb1c0c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('black_background_500x500.csv')\n",
    "train_df = df[df['ImagePath'].str.contains(\"train\")]\n",
    "test_df = df[df['ImagePath'].str.contains(\"test\")]\n",
    "valid_df = df[df['ImagePath'].str.contains(\"valid\")]\n",
    "\n",
    "input_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f533699f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "################## data generator #######################\n",
    "#########################################################\n",
    "class datagenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, \n",
    "            batch_size, \n",
    "            img_size,\n",
    "            data_paths_df,\n",
    "            input_channels,\n",
    "            output_channels):\n",
    "         \n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.data_paths_df = data_paths_df\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "        self.data_paths = data_paths_df.values[:,1]\n",
    "        self.params = data_paths_df.values[:,3:6]\n",
    "        assert len(self.data_paths) == len(self.params)\n",
    "        \n",
    "        self.n = len(self.data_paths)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'updates indexes after each epoch'\n",
    "        self.data_paths_df = self.data_paths_df.sample(frac = 1)\n",
    "        self.data_paths = self.data_paths_df.values[:,1]\n",
    "        self.params = self.data_paths_df.values[:,3:6]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_data_paths = self.data_paths[index : index + self.batch_size]\n",
    "        batch_params_paths = self.params[index : index + self.batch_size]\n",
    "\n",
    "        return self.__dataloader(self.img_size,\n",
    "                batch_data_paths, batch_params_paths,\n",
    "                self.input_channels, self.output_channels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size\n",
    "\n",
    "    #################### data loader ########################\n",
    "    def __dataloader(self, \n",
    "            img_size,\n",
    "            data_paths,\n",
    "            batch_params_paths,\n",
    "            input_channels,\n",
    "            output_channels):\n",
    "        x = np.zeros((len(data_paths), img_size[0], img_size[1], input_channels))\n",
    "        y = batch_params_paths        \n",
    "        \n",
    "        for i in range(len(data_paths)):\n",
    "            data = load_img(path = data_paths[i], grayscale = True)\n",
    "            data = tf.keras.utils.img_to_array(data, data_format=\"channels_last\", dtype=\"float32\")\n",
    "            data /= 255\n",
    "            data.shape = (1,) + data.shape\n",
    "            x[i] = np.asarray(data)\n",
    "        return x.astype(\"float32\"), np.array(y).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b23ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(input_size, input_size, 1))\n",
    "x = layers.Conv2D(filters=32, kernel_size=11, activation=\"relu\")(inputs)\n",
    "x = layers.Conv2D(filters=32, kernel_size=11, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=11, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=5, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=5, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=5, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=4)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(210, activation=\"relu\")(x)\n",
    "x = layers.Dense(210, activation=\"relu\")(x)\n",
    "x = layers.Dense(210, activation=\"relu\")(x)\n",
    "x = layers.Dense(32, activation=\"sigmoid\")(x)\n",
    "outputs = layers.Dense(3)(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "901d44f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "  \n",
    "def abs_loss_function(y_true, y_pred):   \n",
    "    abs_diff = K.abs(y_true - y_pred)\n",
    "    ones = tf.ones_like(y_true)\n",
    "    abs_diff_reversed = K.abs(ones - abs_diff )   \n",
    "    minimum_from_two = tf.math.minimum(abs_diff, abs_diff_reversed) \n",
    "    return tf.math.reduce_mean(minimum_from_two, axis=-1)\n",
    "\n",
    "def square_abs_min_loss(y_true, y_pred):   \n",
    "    abs_diff = K.abs(y_true - y_pred)\n",
    "    ones = tf.ones_like(y_true)\n",
    "    abs_diff_reversed = K.abs(tf.ones_like(y_true) - abs_diff )   \n",
    "    minimum_from_two = tf.math.minimum(abs_diff, abs_diff_reversed) \n",
    "    min_sq = tf.math.sqrt(minimum_from_two)\n",
    "    return tf.math.reduce_mean(min_sq, axis=-1) \n",
    "\n",
    "def smart_square_abs_min_loss(y_true, y_pred):  \n",
    "    punished_y_pred = tf.where((y_pred<0)|(y_pred>1), 3.0 + K.abs(y_pred),y_pred)\n",
    "    \n",
    "    abs_diff = K.abs(y_true - punished_y_pred)\n",
    "    ones = tf.ones_like(y_true)\n",
    "    abs_diff_reversed = K.abs(ones - abs_diff)   \n",
    "    minimum_from_two = tf.math.minimum(abs_diff, abs_diff_reversed) \n",
    "#     print(\"_________________ 1 __________________\")\n",
    "#     print(abs_diff.numpy())\n",
    "#     print(\"_________________ 2 __________________\")\n",
    "#     print(y_pred.numpy())\n",
    "#     print(\"_________________ 3 __________________\")\n",
    "#     print(punished_y_pred.numpy())\n",
    "    \n",
    "    return tf.math.reduce_mean(minimum_from_two, axis=-1)\n",
    "    \n",
    "############################# For debugging ####################################\n",
    "#     print(\"_________________ 1 __________________\")\n",
    "#     print(abs_diff_reversed.numpy())\n",
    "#     print(\"_________________ 2 __________________\")\n",
    "#     print(abs_diff.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce477929",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = RMSprop(learning_rate=0.001),\n",
    "              loss = smart_square_abs_min_loss, \n",
    "              metrics = [smart_square_abs_min_loss],\n",
    "              run_eagerly=True)  # Add run_eagerly=True to enable the numpy debugging\n",
    "\n",
    "tg = datagenerator(32, (input_size,input_size), train_df, 1, 3)\n",
    "vg = datagenerator(32, (input_size,input_size), valid_df, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb2aa76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(x=tg,\n",
    "                    batch_size=32,\n",
    "                    epochs=100,\n",
    "                    validation_data=vg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "348f3e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_a():\n",
    "    inputs = keras.Input(shape=(input_size, input_size, 1))\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=4)(x)\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=4)(x)\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=4)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dense(16, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(3)(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_model_b():\n",
    "    inputs = keras.Input(shape=(input_size, input_size, 1))\n",
    "    x = layers.Conv2D(filters=16, kernel_size=11, activation=\"relu\")(inputs)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=7, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=5, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dense(16, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(3)(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "def load_model_c():\n",
    "    inputs = keras.Input(shape=(input_size, input_size, 1))\n",
    "    x = layers.Conv2D(filters=16, kernel_size=11, activation=\"relu\")(inputs)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=7, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=5, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.01))(x)\n",
    "    x = layers.Dense(16, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.01))(x) \n",
    "    outputs = layers.Dense(3)(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def plot_accuracy_loss(history):\n",
    "    \"\"\"\n",
    "        Plot the accuracy and the loss during the training of the nn.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(12,5))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(221)\n",
    "    plt.plot(history.history['accuracy'],'bo--', label = \"acc\")\n",
    "    plt.plot(history.history['val_accuracy'],'ro--', label = \"val_accuracy\")\n",
    "    plt.title(\"train_acc vs val_acc\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot loss function\n",
    "    plt.subplot(222)\n",
    "    plt.plot(history.history['loss'],'bo--', label = \"loss\")\n",
    "    plt.plot(history.history['val_loss'],'ro--', label = \"val_loss\")\n",
    "    plt.title(\"train_loss vs val_loss\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "def load_and_train_model(model, epochs = 100, loss_func = abs_loss_function):\n",
    "    tg = datagenerator(32, (input_size,input_size), train_df, 1, 3)\n",
    "    vg = datagenerator(32, (input_size,input_size), valid_df, 1, 3)\n",
    "    model.compile(optimizer = RMSprop(learning_rate=0.001),\n",
    "                  loss = loss_func, \n",
    "                  metrics = [\"accuracy\", loss_func])  # Add run_eagerly=True to enable the numpy debugging\n",
    "    \n",
    "    history = model.fit(x=tg,\n",
    "                        batch_size=32,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=vg)\n",
    "    \n",
    "    \n",
    "    plot_accuracy_loss(history)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568e8bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_m = eval(\"load_model_c\")\n",
    "model_ask = func_m()\n",
    "model_ask.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64b487d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 500, 500, 1)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 498, 498, 32)      320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 496, 496, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 124, 124, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 122, 122, 32)      9248      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 120, 120, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 30, 30, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 26, 26, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1152)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               147584    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                2064      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 196,259\n",
      "Trainable params: 196,259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-22 12:44:09.437885: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-22 12:44:10.170203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14610 MB memory:  -> device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:af:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "model_a = load_model_a()\n",
    "model_a.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c7b8c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/utils/image_utils.py:409: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-22 12:44:16.518630: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273/273 [==============================] - 75s 260ms/step - loss: 0.2407 - accuracy: 0.3147 - abs_loss_function: 0.2407 - val_loss: 0.2550 - val_accuracy: 0.2923 - val_abs_loss_function: 0.2550\n",
      "Epoch 2/100\n",
      "273/273 [==============================] - 72s 263ms/step - loss: 0.2403 - accuracy: 0.3237 - abs_loss_function: 0.2403 - val_loss: 0.2813 - val_accuracy: 0.3397 - val_abs_loss_function: 0.2813\n",
      "Epoch 3/100\n",
      "273/273 [==============================] - 68s 250ms/step - loss: 0.2430 - accuracy: 0.3403 - abs_loss_function: 0.2430 - val_loss: 0.2620 - val_accuracy: 0.3599 - val_abs_loss_function: 0.2620\n",
      "Epoch 4/100\n",
      "273/273 [==============================] - 68s 247ms/step - loss: 0.1893 - accuracy: 0.2873 - abs_loss_function: 0.1893 - val_loss: 0.2437 - val_accuracy: 0.3468 - val_abs_loss_function: 0.2437\n",
      "Epoch 5/100\n",
      "273/273 [==============================] - 80s 293ms/step - loss: 0.1189 - accuracy: 0.2546 - abs_loss_function: 0.1189 - val_loss: 0.2117 - val_accuracy: 0.3286 - val_abs_loss_function: 0.2117\n",
      "Epoch 6/100\n",
      "273/273 [==============================] - 70s 256ms/step - loss: 0.1039 - accuracy: 0.2684 - abs_loss_function: 0.1039 - val_loss: 0.2625 - val_accuracy: 0.3831 - val_abs_loss_function: 0.2625\n",
      "Epoch 7/100\n",
      "273/273 [==============================] - 73s 267ms/step - loss: 0.0910 - accuracy: 0.2722 - abs_loss_function: 0.0910 - val_loss: 0.2003 - val_accuracy: 0.3175 - val_abs_loss_function: 0.2003\n",
      "Epoch 8/100\n",
      "273/273 [==============================] - 80s 293ms/step - loss: 0.0812 - accuracy: 0.2415 - abs_loss_function: 0.0812 - val_loss: 0.2128 - val_accuracy: 0.3810 - val_abs_loss_function: 0.2128\n",
      "Epoch 9/100\n",
      "273/273 [==============================] - 83s 305ms/step - loss: 0.0764 - accuracy: 0.2692 - abs_loss_function: 0.0764 - val_loss: 0.1975 - val_accuracy: 0.2782 - val_abs_loss_function: 0.1975\n",
      "Epoch 10/100\n",
      "273/273 [==============================] - 70s 257ms/step - loss: 0.0743 - accuracy: 0.2334 - abs_loss_function: 0.0743 - val_loss: 0.2075 - val_accuracy: 0.3659 - val_abs_loss_function: 0.2075\n",
      "Epoch 11/100\n",
      "273/273 [==============================] - 75s 273ms/step - loss: 0.0700 - accuracy: 0.2842 - abs_loss_function: 0.0700 - val_loss: 0.1967 - val_accuracy: 0.3468 - val_abs_loss_function: 0.1967\n",
      "Epoch 12/100\n",
      "273/273 [==============================] - 73s 268ms/step - loss: 0.0680 - accuracy: 0.2693 - abs_loss_function: 0.0680 - val_loss: 0.1978 - val_accuracy: 0.2167 - val_abs_loss_function: 0.1978\n",
      "Epoch 13/100\n",
      "273/273 [==============================] - 74s 271ms/step - loss: 0.0635 - accuracy: 0.2344 - abs_loss_function: 0.0635 - val_loss: 0.2115 - val_accuracy: 0.2167 - val_abs_loss_function: 0.2115\n",
      "Epoch 14/100\n",
      "273/273 [==============================] - 74s 272ms/step - loss: 0.0631 - accuracy: 0.2406 - abs_loss_function: 0.0631 - val_loss: 0.1682 - val_accuracy: 0.2480 - val_abs_loss_function: 0.1682\n",
      "Epoch 15/100\n",
      "273/273 [==============================] - 72s 263ms/step - loss: 0.0605 - accuracy: 0.2877 - abs_loss_function: 0.0605 - val_loss: 0.1933 - val_accuracy: 0.3438 - val_abs_loss_function: 0.1933\n",
      "Epoch 16/100\n",
      "273/273 [==============================] - 62s 225ms/step - loss: 0.0544 - accuracy: 0.2850 - abs_loss_function: 0.0544 - val_loss: 0.1883 - val_accuracy: 0.2288 - val_abs_loss_function: 0.1883\n",
      "Epoch 17/100\n",
      "273/273 [==============================] - 63s 230ms/step - loss: 0.0568 - accuracy: 0.2461 - abs_loss_function: 0.0568 - val_loss: 0.1609 - val_accuracy: 0.2954 - val_abs_loss_function: 0.1609\n",
      "Epoch 18/100\n",
      "273/273 [==============================] - 72s 264ms/step - loss: 0.0517 - accuracy: 0.2475 - abs_loss_function: 0.0517 - val_loss: 0.1557 - val_accuracy: 0.3145 - val_abs_loss_function: 0.1557\n",
      "Epoch 19/100\n",
      "273/273 [==============================] - 74s 271ms/step - loss: 0.0496 - accuracy: 0.2570 - abs_loss_function: 0.0496 - val_loss: 0.1612 - val_accuracy: 0.2601 - val_abs_loss_function: 0.1612\n",
      "Epoch 20/100\n",
      "273/273 [==============================] - 73s 265ms/step - loss: 0.0478 - accuracy: 0.2535 - abs_loss_function: 0.0478 - val_loss: 0.1492 - val_accuracy: 0.1240 - val_abs_loss_function: 0.1492\n",
      "Epoch 21/100\n",
      "273/273 [==============================] - 73s 268ms/step - loss: 0.0500 - accuracy: 0.2603 - abs_loss_function: 0.0500 - val_loss: 0.1653 - val_accuracy: 0.2571 - val_abs_loss_function: 0.1653\n",
      "Epoch 22/100\n",
      "273/273 [==============================] - 73s 267ms/step - loss: 0.0467 - accuracy: 0.2395 - abs_loss_function: 0.0467 - val_loss: 0.1552 - val_accuracy: 0.3054 - val_abs_loss_function: 0.1552\n",
      "Epoch 23/100\n",
      "273/273 [==============================] - 74s 270ms/step - loss: 0.0443 - accuracy: 0.2188 - abs_loss_function: 0.0443 - val_loss: 0.1259 - val_accuracy: 0.1321 - val_abs_loss_function: 0.1259\n",
      "Epoch 24/100\n",
      "273/273 [==============================] - 75s 275ms/step - loss: 0.0441 - accuracy: 0.2468 - abs_loss_function: 0.0441 - val_loss: 0.1271 - val_accuracy: 0.1603 - val_abs_loss_function: 0.1271\n",
      "Epoch 25/100\n",
      "273/273 [==============================] - 68s 250ms/step - loss: 0.0425 - accuracy: 0.2951 - abs_loss_function: 0.0425 - val_loss: 0.1572 - val_accuracy: 0.2369 - val_abs_loss_function: 0.1572\n",
      "Epoch 26/100\n",
      "273/273 [==============================] - 66s 243ms/step - loss: 0.0405 - accuracy: 0.2949 - abs_loss_function: 0.0405 - val_loss: 0.1585 - val_accuracy: 0.3044 - val_abs_loss_function: 0.1585\n",
      "Epoch 27/100\n",
      "273/273 [==============================] - 67s 244ms/step - loss: 0.0402 - accuracy: 0.2373 - abs_loss_function: 0.0402 - val_loss: 0.1316 - val_accuracy: 0.2208 - val_abs_loss_function: 0.1316\n",
      "Epoch 28/100\n",
      "273/273 [==============================] - 72s 264ms/step - loss: 0.0394 - accuracy: 0.2305 - abs_loss_function: 0.0394 - val_loss: 0.1147 - val_accuracy: 0.1300 - val_abs_loss_function: 0.1147\n",
      "Epoch 29/100\n",
      "208/273 [=====================>........] - ETA: 15s - loss: 0.0422 - accuracy: 0.2468 - abs_loss_function: 0.0422"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history_a \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_train_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mabs_loss_function\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [5], line 104\u001b[0m, in \u001b[0;36mload_and_train_model\u001b[0;34m(model, epochs, loss_func)\u001b[0m\n\u001b[1;32m     99\u001b[0m vg \u001b[38;5;241m=\u001b[39m datagenerator(\u001b[38;5;241m32\u001b[39m, (input_size,input_size), valid_df, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    100\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer \u001b[38;5;241m=\u001b[39m RMSprop(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m),\n\u001b[1;32m    101\u001b[0m               loss \u001b[38;5;241m=\u001b[39m loss_func, \n\u001b[1;32m    102\u001b[0m               metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss_func])  \u001b[38;5;66;03m# Add run_eagerly=True to enable the numpy debugging\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m plot_accuracy_loss(history)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m~/project/venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/project/venv/lib/python3.10/site-packages/keras/engine/training.py:1656\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1654\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[1;32m   1655\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1656\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1658\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/project/venv/lib/python3.10/site-packages/keras/callbacks.py:476\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \n\u001b[1;32m    471\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 476\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/project/venv/lib/python3.10/site-packages/keras/callbacks.py:323\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 323\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    328\u001b[0m     )\n",
      "File \u001b[0;32m~/project/venv/lib/python3.10/site-packages/keras/callbacks.py:346\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    349\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/project/venv/lib/python3.10/site-packages/keras/callbacks.py:394\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    393\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 394\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/project/venv/lib/python3.10/site-packages/keras/callbacks.py:1094\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1094\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/project/venv/lib/python3.10/site-packages/keras/callbacks.py:1170\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1169\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1170\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/project/venv/lib/python3.10/site-packages/keras/utils/tf_utils.py:665\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[1;32m    663\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m--> 665\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/project/venv/lib/python3.10/site-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/project/venv/lib/python3.10/site-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/project/venv/lib/python3.10/site-packages/keras/utils/tf_utils.py:658\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 658\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    659\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[1;32m    661\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m~/project/venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1155\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m \n\u001b[1;32m   1134\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1155\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/project/venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1121\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1120\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1122\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history_a = load_and_train_model(model_a, 100, abs_loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfee6523",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b = load_model_b()\n",
    "model_b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278d0a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_b = load_and_train_model(model_b, 100, abs_loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1179a5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_c = load_model_c()\n",
    "model_c.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4886c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_c = load_and_train_model(model_c, 100, abs_loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dd1aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_loss(history, name):\n",
    "    \"\"\"\n",
    "        Plot the accuracy and the loss during the training of the nn.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(12,5))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(221)\n",
    "    plt.plot(history.history['accuracy'],'bo--', label = \"acc\")\n",
    "    plt.plot(history.history['val_accuracy'],'ro--', label = \"val_accuracy\")\n",
    "    plt.title(\"train_acc vs val_acc\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot loss function\n",
    "    plt.subplot(222)\n",
    "    plt.plot(history.history['loss'],'bo--', label = \"loss\")\n",
    "    plt.plot(history.history['val_loss'],'ro--', label = \"val_loss\")\n",
    "    plt.title(\"train_loss vs val_loss\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "def load_and_train_model(model, epochs = 100, loss_func = abs_loss_function):\n",
    "    tg = datagenerator(32, (input_size,input_size), train_df, 1, 3)\n",
    "    vg = datagenerator(32, (input_size,input_size), valid_df, 1, 3)\n",
    "    model.compile(optimizer = RMSprop(learning_rate=0.001),\n",
    "                  loss = loss_func, \n",
    "                  metrics = [\"accuracy\", loss_func])  # Add run_eagerly=True to enable the numpy debugging\n",
    "    \n",
    "    history = model.fit(x=tg,\n",
    "                        batch_size=32,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=vg)\n",
    "    \n",
    "    \n",
    "    plot_accuracy_loss(history)\n",
    "    plt.savefig(\"{}.png\".format(name))\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58320726",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_loss(history_a)\n",
    "plot_accuracy_loss(history_b)\n",
    "plot_accuracy_loss(history_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d23dbb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407f977b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2674f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a198f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e376a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f86d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b7f00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tg = datagenerator(32, (input_size,input_size), test_df, 1, 3)\n",
    "results = model.evaluate(tg, batch_size=32)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17920843",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(tg)  \n",
    "pred_labels = np.argmax(predictions, axis = 1) # We take the highest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac897972",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c211ded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = test_df.values[1][1]\n",
    "data = load_img(path = t, grayscale = True)\n",
    "data = tf.keras.utils.img_to_array(data, data_format=\"channels_last\", dtype=\"float32\")\n",
    "data /= 255\n",
    "data.shape = (1,) + data.shape\n",
    "X = np.asarray(data)\n",
    "\n",
    "print(t)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def predict_data(d):\n",
    "    yhat = model.predict(data)\n",
    "    yhat2 = np.where(yhat<0, 1+yhat, yhat)\n",
    "    print(yhat2*90)\n",
    "\n",
    "predict_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24791fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b84982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prdict_and_print(nr):\n",
    "    t = test_df.values[nr][1]\n",
    "    data = load_img(path = t, grayscale = True)\n",
    "    data = tf.keras.utils.img_to_array(data, data_format=\"channels_last\", dtype=\"float32\")\n",
    "    data /= 255\n",
    "    data.shape = (1,) + data.shape\n",
    "    X = np.asarray(data)\n",
    "    print(\"----------{}----------\".format(nr))\n",
    "    euler = test_df.values[nr]\n",
    "    print(\"phi1\", float(euler[3])*90)\n",
    "    print(\"PHI\",   float(euler[4])*90)\n",
    "    print(\"phi2\",  float(euler[5])*90)\n",
    "    yhat = model.predict(data)\n",
    "    print(\"predicted values\", yhat*90)\n",
    "\n",
    "    \n",
    "print(\"############### PREDICTIONS ###############\")\n",
    "for i in range(10):\n",
    "    prdict_and_print(i)\n",
    "print(\"############### PREDICTIONS ###############\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de24180",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Best_model_so_far_abs_loss_function_RMSprop\"\n",
    "model.save(\"Models/{}.h5\".format(model_name), save_format = 'h5')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec3990ea",
   "metadata": {},
   "source": [
    "from keras.models import load_model \n",
    "from tensorflow.keras.utils import CustomObjectScope\n",
    "\n",
    "with CustomObjectScope({'square_abs_min_loss': square_abs_min_loss}):\n",
    "    model2 = keras.models.load_model('Models/one.h5')\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c5dc500",
   "metadata": {},
   "source": [
    "del model "
   ]
  },
  {
   "cell_type": "raw",
   "id": "66e2eafa",
   "metadata": {},
   "source": [
    "epochs = range(1, len(history.history[\"loss\"]) + 1)\n",
    "loss = history.history[\"loss\"]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6231e846",
   "metadata": {},
   "source": [
    "t = test_df.values[45][1]\n",
    "data = load_img(path = t, grayscale = True)\n",
    "data = tf.keras.utils.img_to_array(data, data_format=\"channels_last\", dtype=\"float32\")\n",
    "data /= 255\n",
    "data.shape = (1,) + data.shape\n",
    "X = np.asarray(data)\n",
    "\n",
    "yhat = model.predict(data)\n",
    "print(t)\n",
    "print(yhat*90)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "35a3b3f2",
   "metadata": {},
   "source": [
    "def custom_loss_function(y_true, y_pred):\n",
    "    # Calculate the error for each parameter using sqrt(2 - cos(y_hat - y_pred))\n",
    "    param_1_error = tf.math.sqrt(2 - tf.math.cos(y_true[:, 0] - y_pred[:, 0]))\n",
    "    param_2_error = tf.math.sqrt(2 - tf.math.cos(y_true[:, 1] - y_pred[:, 1]))\n",
    "    param_3_error = tf.math.sqrt(2 - tf.math.cos(y_true[:, 2] - y_pred[:, 2]))\n",
    "\n",
    "    # Calculate the total loss as the mean of the errors for each parameter\n",
    "    total_loss = (param_1_error + param_2_error + param_3_error) / 3\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96510eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_loss(history):\n",
    "    \"\"\"\n",
    "        Plot the accuracy and the loss during the training of the nn.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(12,5))\n",
    "\n",
    "    # Plot accuracy\n",
    "#     plt.subplot(221)\n",
    "#     plt.plot(history.history['accuracy'],'bo--', label = \"acc\")\n",
    "#     plt.plot(history.history['val_accuracy'],'ro--', label = \"val_accuracy\")\n",
    "#     plt.title(\"train_acc vs val_acc\")\n",
    "#     plt.ylabel(\"accuracy\")\n",
    "#     plt.xlabel(\"epochs\")\n",
    "#     plt.legend()\n",
    "    \n",
    "    # Plot loss function\n",
    "    plt.subplot(222)\n",
    "    plt.plot(history.history['loss'],'bo--', label = \"loss\")\n",
    "    plt.plot(history.history['val_loss'],'ro--', label = \"val_loss\")\n",
    "    plt.title(\"train_loss vs val_loss\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "\n",
    "    plt.legend()\n",
    "#     plt.savefig(\"graph_{}_{}_{}_{}.png\".format(input_size,input_size,input_size,input_size))\n",
    "plot_accuracy_loss(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
