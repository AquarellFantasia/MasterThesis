{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf753cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5d32c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_bsub_file(n, o, l, d, m):    \n",
    "    f = open(\"{}/Scripts/{}.bsub\".format(d, n), \"w\")\n",
    "    f.write('''\n",
    "#!/bin/bash\n",
    "### General options\n",
    "### -- specify queue --   NOTE: TitanX is significantly faster than K80\n",
    "#BSUB -q gpuv100\n",
    "#BSUB -gpu \"num=1:mode=exclusive_process\"\n",
    "### -- set the job Name --\n",
    "#BSUB -J s202741-train\n",
    "### -- ask for number of cores (default: 1) --\n",
    "#BSUB -n 4\n",
    "#BSUB -R \"span[hosts=1]\"\n",
    "### -- set walltime limit: hh:mm --  maximum 24 hours for GPU-queues right now\n",
    "#BSUB -W 5:00\n",
    "# request 5GB of memory\n",
    "#BSUB -R \"rusage[mem=5GB]\"\n",
    "### -- Specify the output and error file. %J is the job-id --\n",
    "### -- -o and -e mean append, -oo and -eo mean overwrite --\n",
    "#BSUB -o {}/Logs/{}%J.out\n",
    "# -- end of LSF options --\n",
    "\n",
    "# Necessary modules\n",
    "cd ..\n",
    "source venv/bin/activate\n",
    "\n",
    "python trainModelIter4.py 100 \\\"{}\\\" \"{}\" \"black_background_500x500.csv\" 2 \\\"{}\\\" \"{}\" \"load_model_{}\"\n",
    "\n",
    "    '''.format(d, n, o, l, n, d, m))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c1856ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bsubs(directory):\n",
    "    script_paths = []\n",
    "    os.mkdir(directory)\n",
    "    os.mkdir(\"{}/Graphs\".format(directory))\n",
    "    os.mkdir(\"{}/Logs\".format(directory))\n",
    "    os.mkdir(\"{}/Scripts\".format(directory))\n",
    "    os.mkdir(\"{}/Models\".format(directory))\n",
    "    optimizers = [\"RMSprop\"]\n",
    "    rates = [0.0005, 0.001, 0.002]\n",
    "    loss_funcs = [\"abs_loss_function\", \"sqrt_abs_min_loss\", \"smart_sqrt_abs_min_loss\"]\n",
    "    models = [\"a\",\"b\",\"c\",\"d\",\"e\",\"f\", \"g\", \"h\", \"i\", \"j\", \"k\"]\n",
    "    for model in models:\n",
    "        for optimizer in optimizers:        \n",
    "            for rate in rates:\n",
    "                for loss_func in loss_funcs:\n",
    "                    rate_s = str(rate).replace('.', '')\n",
    "\n",
    "                    if optimizer == \"Adam\":\n",
    "                        opt = \"{}(learning_rate={}, amsgrad=True)\".format(optimizer,rate)\n",
    "                        name = \"{}_{}_{}_model_{}_amsgrad_true\".format(optimizer, loss_func, rate_s, model)\n",
    "                        write_bsub_file(name, opt, loss_func, directory, model)\n",
    "\n",
    "                        opt = \"{}(learning_rate={}, amsgrad=False)\".format(optimizer,rate)\n",
    "                        name = \"{}_{}_{}_model_{}_amsgrad_false\".format(optimizer, loss_func, rate_s)\n",
    "                        write_bsub_file(name, opt, loss_func, directory, model)\n",
    "\n",
    "                    else: \n",
    "                        opt = \"{}(learning_rate={})\".format(optimizer,rate)\n",
    "                        name = \"{}_{}_{}_model_{}_\".format(optimizer, loss_func, rate_s, model)\n",
    "                        write_bsub_file(name, opt, loss_func, directory, model)\n",
    "                    \n",
    "    return script_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f841bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def excecute_cmd(cmd):\n",
    "    out = \"\"\n",
    "    os.system('{} > output.txt'.format(cmd))\n",
    "    file = open('output.txt','r')\n",
    "    out += file.read()\n",
    "    file.close()\n",
    "    os.remove(\"output.txt\")\n",
    "    return out\n",
    "\n",
    "\n",
    "def delete_all_jobs():\n",
    "    job_str = excecute_cmd(\"qstat gpuv100\") \n",
    "    jobs = job_str.split(\":\")\n",
    "    job_ids = []\n",
    "    for i in range(1, len(jobs)):\n",
    "        job_ids.append(jobs[i].replace(\" \", \"\").split(\"s202741-trai\")[1][0:8])\n",
    "    for job in job_ids:\n",
    "        os.system('qdel {}'.format(job))\n",
    "        \n",
    "def queue_job(path):\n",
    "    job_str = excecute_cmd(\"bsub < {}\".format(path))\n",
    "    \n",
    "def queue_all_jobs(path):\n",
    "    l = os.listdir(\"{}/Scripts\".format(path))\n",
    "    for script_file in l:\n",
    "        queue_job(\"{}/Scripts/{}\".format(path,script_file))\n",
    "        \n",
    "def run_jobs(path):\n",
    "    create_bsubs(path)\n",
    "    queue_all_jobs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32ddde79",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_jobs(\"iter7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c19df89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Request <15245013> is being terminated\n",
      "Request <15245011> is being terminated\n",
      "Request <15245014> is being terminated\n",
      "Request <15245012> is being terminated\n",
      "Request <15245015> is being terminated\n",
      "Request <15245016> is being terminated\n",
      "Request <15245017> is being terminated\n",
      "Request <15245018> is being terminated\n",
      "Request <15245019> is being terminated\n",
      "Request <15245020> is being terminated\n",
      "Request <15245021> is being terminated\n",
      "Request <15245022> is being terminated\n",
      "Request <15245023> is being terminated\n",
      "Request <15245024> is being terminated\n",
      "Request <15245025> is being terminated\n",
      "Request <15245026> is being terminated\n",
      "Request <15245027> is being terminated\n",
      "Request <15245028> is being terminated\n",
      "Request <15245029> is being terminated\n",
      "Request <15245030> is being terminated\n",
      "Request <15245031> is being terminated\n",
      "Request <15245032> is being terminated\n",
      "Request <15245033> is being terminated\n",
      "Request <15245034> is being terminated\n",
      "Request <15245035> is being terminated\n",
      "Request <15245036> is being terminated\n",
      "Request <15245037> is being terminated\n",
      "Request <15245038> is being terminated\n",
      "Request <15245039> is being terminated\n",
      "Request <15245040> is being terminated\n",
      "Request <15245041> is being terminated\n",
      "Request <15245042> is being terminated\n",
      "Request <15245043> is being terminated\n",
      "Request <15245044> is being terminated\n",
      "Request <15245045> is being terminated\n",
      "Request <15245046> is being terminated\n",
      "Request <15245047> is being terminated\n",
      "Request <15245048> is being terminated\n",
      "Request <15245049> is being terminated\n",
      "Request <15245050> is being terminated\n",
      "Request <15245051> is being terminated\n",
      "Request <15245052> is being terminated\n",
      "Request <15245053> is being terminated\n",
      "Request <15245054> is being terminated\n",
      "Request <15245055> is being terminated\n",
      "Request <15245056> is being terminated\n",
      "Request <15245057> is being terminated\n",
      "Request <15245058> is being terminated\n",
      "Request <15245059> is being terminated\n",
      "Request <15245060> is being terminated\n",
      "Request <15245061> is being terminated\n",
      "Request <15245062> is being terminated\n",
      "Request <15245063> is being terminated\n",
      "Request <15245064> is being terminated\n",
      "Request <15245065> is being terminated\n",
      "Request <15245066> is being terminated\n",
      "Request <15245067> is being terminated\n",
      "Request <15245068> is being terminated\n",
      "Request <15245069> is being terminated\n",
      "Request <15245070> is being terminated\n",
      "Request <15245071> is being terminated\n",
      "Request <15245072> is being terminated\n",
      "Request <15245073> is being terminated\n",
      "Request <15245074> is being terminated\n",
      "Request <15245075> is being terminated\n",
      "Request <15245076> is being terminated\n",
      "Request <15245077> is being terminated\n",
      "Request <15245078> is being terminated\n",
      "Request <15245079> is being terminated\n",
      "Request <15245080> is being terminated\n",
      "Request <15245081> is being terminated\n",
      "Request <15245082> is being terminated\n",
      "Request <15245083> is being terminated\n",
      "Request <15245084> is being terminated\n",
      "Request <15245085> is being terminated\n",
      "Request <15245086> is being terminated\n",
      "Request <15245087> is being terminated\n",
      "Request <15245088> is being terminated\n",
      "Request <15245089> is being terminated\n",
      "Request <15245090> is being terminated\n",
      "Request <15245091> is being terminated\n",
      "Request <15245092> is being terminated\n",
      "Request <15245093> is being terminated\n",
      "Request <15245094> is being terminated\n",
      "Request <15245095> is being terminated\n",
      "Request <15245096> is being terminated\n",
      "Request <15245097> is being terminated\n",
      "Request <15245098> is being terminated\n",
      "Request <15245099> is being terminated\n",
      "Request <15245100> is being terminated\n",
      "Request <15245101> is being terminated\n"
     ]
    }
   ],
   "source": [
    "delete_all_jobs()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773e7a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "root_path = '/'\n",
    "file_path = 'zhome/ab/7/153983/project/scripts'\n",
    "\n",
    "# Join the root path and file path to create a full path\n",
    "full_path = os.path.join(root_path, file_path)\n",
    "os.listdir(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d2e921",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
