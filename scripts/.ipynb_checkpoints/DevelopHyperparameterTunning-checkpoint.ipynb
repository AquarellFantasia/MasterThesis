{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf753cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5d32c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_bsub_file(n, o, l, d, m):    \n",
    "    f = open(\"{}/Scripts/{}.bsub\".format(d, n), \"w\")\n",
    "    f.write('''\n",
    "#!/bin/bash\n",
    "### General options\n",
    "### -- specify queue --   NOTE: TitanX is significantly faster than K80\n",
    "#BSUB -q gpuv100\n",
    "#BSUB -gpu \"num=1:mode=exclusive_process\"\n",
    "### -- set the job Name --\n",
    "#BSUB -J s202741-train\n",
    "### -- ask for number of cores (default: 1) --\n",
    "#BSUB -n 4\n",
    "#BSUB -R \"span[hosts=1]\"\n",
    "### -- set walltime limit: hh:mm --  maximum 24 hours for GPU-queues right now\n",
    "#BSUB -W 5:00\n",
    "# request 5GB of memory\n",
    "#BSUB -R \"rusage[mem=5GB]\"\n",
    "### -- Specify the output and error file. %J is the job-id --\n",
    "### -- -o and -e mean append, -oo and -eo mean overwrite --\n",
    "#BSUB -o {}/Logs/{}%J.out\n",
    "# -- end of LSF options --\n",
    "\n",
    "# Necessary modules\n",
    "cd ..\n",
    "source venv/bin/activate\n",
    "\n",
    "python trainModelIter3.py 100 \\\"{}\\\" \"{}\" \"black_background_500x500.csv\" 2 \\\"{}\\\" \"{}\" \"load_model_{}\"\n",
    "\n",
    "    '''.format(d, n, o, l, n, d, m))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c1856ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bsubs(directory):\n",
    "    script_paths = []\n",
    "    os.mkdir(directory)\n",
    "    os.mkdir(\"{}/Graphs\".format(directory))\n",
    "    os.mkdir(\"{}/Logs\".format(directory))\n",
    "    os.mkdir(\"{}/Scripts\".format(directory))\n",
    "    os.mkdir(\"{}/Models\".format(directory))\n",
    "    optimizers = [\"RMSprop\"]\n",
    "    rates = [0.0005, 0.001, 0.002]\n",
    "    loss_funcs = [\"abs_loss_function\", \"sqrt_abs_min_loss\", \"smart_sqrt_abs_min_loss\"]\n",
    "    models = [\"a\",\"b\",\"c\",\"d\",\"e\",\"f\", \"g\", \"h\", \"i\", \"j\", \"k\"]\n",
    "    for model in models:\n",
    "        for optimizer in optimizers:        \n",
    "            for rate in rates:\n",
    "                for loss_func in loss_funcs:\n",
    "                    rate_s = str(rate).replace('.', '')\n",
    "\n",
    "                    if optimizer == \"Adam\":\n",
    "                        opt = \"{}(learning_rate={}, amsgrad=True)\".format(optimizer,rate)\n",
    "                        name = \"{}_{}_{}_model_{}_amsgrad_true\".format(optimizer, loss_func, rate_s, model)\n",
    "                        write_bsub_file(name, opt, loss_func, directory, model)\n",
    "\n",
    "                        opt = \"{}(learning_rate={}, amsgrad=False)\".format(optimizer,rate)\n",
    "                        name = \"{}_{}_{}_model_{}_amsgrad_false\".format(optimizer, loss_func, rate_s)\n",
    "                        write_bsub_file(name, opt, loss_func, directory, model)\n",
    "\n",
    "                    else: \n",
    "                        opt = \"{}(learning_rate={})\".format(optimizer,rate)\n",
    "                        name = \"{}_{}_{}_model_{}_\".format(optimizer, loss_func, rate_s, model)\n",
    "                        write_bsub_file(name, opt, loss_func, directory, model)\n",
    "                    \n",
    "    return script_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f841bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def excecute_cmd(cmd):\n",
    "    out = \"\"\n",
    "    os.system('{} > output.txt'.format(cmd))\n",
    "    file = open('output.txt','r')\n",
    "    out += file.read()\n",
    "    file.close()\n",
    "    os.remove(\"output.txt\")\n",
    "    return out\n",
    "\n",
    "\n",
    "def delete_all_jobs():\n",
    "    job_str = excecute_cmd(\"qstat gpuv100\") \n",
    "    jobs = job_str.split(\":\")\n",
    "    job_ids = []\n",
    "    for i in range(1, len(jobs)):\n",
    "        job_ids.append(jobs[i].replace(\" \", \"\").split(\"s202741-trai\")[1][0:8])\n",
    "    for job in job_ids:\n",
    "        os.system('qdel {}'.format(job))\n",
    "        \n",
    "def queue_job(path):\n",
    "    job_str = excecute_cmd(\"bsub < {}\".format(path))\n",
    "    \n",
    "def queue_all_jobs(path):\n",
    "    l = os.listdir(\"{}/Scripts\".format(path))\n",
    "    for script_file in l:\n",
    "        queue_job(\"{}/Scripts/{}\".format(path,script_file))\n",
    "        \n",
    "def run_jobs(path):\n",
    "    create_bsubs(path)\n",
    "    queue_all_jobs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32ddde79",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_jobs(\"iter6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c19df89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Request <15232222> is being terminated\n",
      "Request <15232223> is being terminated\n",
      "Request <15232224> is being terminated\n",
      "Request <15232225> is being terminated\n",
      "Request <15232226> is being terminated\n",
      "Request <15232227> is being terminated\n",
      "Request <15232228> is being terminated\n",
      "Request <15232229> is being terminated\n",
      "Request <15232230> is being terminated\n",
      "Request <15232231> is being terminated\n",
      "Request <15232232> is being terminated\n",
      "Request <15232233> is being terminated\n",
      "Request <15232234> is being terminated\n",
      "Request <15232235> is being terminated\n",
      "Request <15232236> is being terminated\n",
      "Request <15232237> is being terminated\n",
      "Request <15232238> is being terminated\n",
      "Request <15232239> is being terminated\n",
      "Request <15232240> is being terminated\n",
      "Request <15232241> is being terminated\n",
      "Request <15232242> is being terminated\n",
      "Request <15232243> is being terminated\n",
      "Request <15232244> is being terminated\n",
      "Request <15232245> is being terminated\n",
      "Request <15232246> is being terminated\n",
      "Request <15232247> is being terminated\n",
      "Request <15232248> is being terminated\n",
      "Request <15232249> is being terminated\n",
      "Request <15232250> is being terminated\n",
      "Request <15232251> is being terminated\n",
      "Request <15232252> is being terminated\n",
      "Request <15232253> is being terminated\n",
      "Request <15232254> is being terminated\n",
      "Request <15232255> is being terminated\n",
      "Request <15232256> is being terminated\n",
      "Request <15232257> is being terminated\n",
      "Request <15232258> is being terminated\n",
      "Request <15232259> is being terminated\n",
      "Request <15232260> is being terminated\n",
      "Request <15232261> is being terminated\n",
      "Request <15232262> is being terminated\n",
      "Request <15232263> is being terminated\n",
      "Request <15232264> is being terminated\n",
      "Request <15232265> is being terminated\n",
      "Request <15232266> is being terminated\n",
      "Request <15232267> is being terminated\n",
      "Request <15232268> is being terminated\n",
      "Request <15232269> is being terminated\n",
      "Request <15232270> is being terminated\n",
      "Request <15232271> is being terminated\n",
      "Request <15232272> is being terminated\n",
      "Request <15232273> is being terminated\n",
      "Request <15232274> is being terminated\n",
      "Request <15232275> is being terminated\n",
      "Request <15232276> is being terminated\n",
      "Request <15232277> is being terminated\n",
      "Request <15232278> is being terminated\n",
      "Request <15232279> is being terminated\n",
      "Request <15232280> is being terminated\n",
      "Request <15232281> is being terminated\n",
      "Request <15232282> is being terminated\n",
      "Request <15232283> is being terminated\n",
      "Request <15232284> is being terminated\n",
      "Request <15232285> is being terminated\n",
      "Request <15232286> is being terminated\n",
      "Request <15232287> is being terminated\n",
      "Request <15232288> is being terminated\n",
      "Request <15232289> is being terminated\n",
      "Request <15232290> is being terminated\n",
      "Request <15232291> is being terminated\n",
      "Request <15232292> is being terminated\n",
      "Request <15232293> is being terminated\n",
      "Request <15232294> is being terminated\n",
      "Request <15232295> is being terminated\n",
      "Request <15232296> is being terminated\n",
      "Request <15232297> is being terminated\n",
      "Request <15232298> is being terminated\n",
      "Request <15232299> is being terminated\n",
      "Request <15232300> is being terminated\n",
      "Request <15232301> is being terminated\n",
      "Request <15232302> is being terminated\n",
      "Request <15232303> is being terminated\n",
      "Request <15232304> is being terminated\n",
      "Request <15232305> is being terminated\n",
      "Request <15232306> is being terminated\n",
      "Request <15232307> is being terminated\n",
      "Request <15232308> is being terminated\n",
      "Request <15232309> is being terminated\n",
      "Request <15232310> is being terminated\n",
      "Request <15232311> is being terminated\n",
      "Request <15232312> is being terminated\n",
      "Request <15232313> is being terminated\n",
      "Request <15232314> is being terminated\n",
      "Request <15232315> is being terminated\n",
      "Request <15232316> is being terminated\n",
      "Request <15232317> is being terminated\n",
      "Request <15232318> is being terminated\n"
     ]
    }
   ],
   "source": [
    "delete_all_jobs()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773e7a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "root_path = '/'\n",
    "file_path = 'zhome/ab/7/153983/project/scripts'\n",
    "\n",
    "# Join the root path and file path to create a full path\n",
    "full_path = os.path.join(root_path, file_path)\n",
    "os.listdir(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d2e921",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
