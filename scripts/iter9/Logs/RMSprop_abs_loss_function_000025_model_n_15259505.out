Loaded dependency [python3/3.10.7]: gcc/11.3.0-binutils-2.38
Loaded module: python3/3.10.7

Loading python3/3.10.7
  Loading requirement: gcc/11.3.0-binutils-2.38
Loaded module: cuda/11.6
Loaded module: cudnn/v8.3.2.44-prod-cuda-11.X
2023-01-29 05:38:09.897698: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-01-29 05:38:11.496118: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /appl/cudnn/v8.3.2.44-prod-cuda-11.5/lib:/appl/cuda/11.6.0/lib64:/appl/python/3.10.7/lib:/appl/gcc/11.3.0-binutils-2.38/lib64:/appl/gcc/11.3.0-binutils-2.38/lib:/lsf/10.1/linux3.10-glibc2.17-x86_64/lib
2023-01-29 05:38:11.496819: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /appl/cudnn/v8.3.2.44-prod-cuda-11.5/lib:/appl/cuda/11.6.0/lib64:/appl/python/3.10.7/lib:/appl/gcc/11.3.0-binutils-2.38/lib64:/appl/gcc/11.3.0-binutils-2.38/lib:/lsf/10.1/linux3.10-glibc2.17-x86_64/lib
2023-01-29 05:38:11.496832: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-01-29 05:38:14.754727: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-01-29 05:38:15.459042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30961 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:3a:00.0, compute capability: 7.0
Epochs:  100
Optimizer:  RMSprop(learning_rate=0.00025)
Loss function name:  abs_loss_function
Csv file used:  black_background_500x500.csv
Verbose:  2
Unique name:  RMSprop_abs_loss_function_000025_model_n_
Output folder:  iter9
Model name:  load_model_n
 
        ################ MODEL ############### 
 
    filt = 64
    inputs = keras.Input(shape=(input_size, input_size, 1))
    x = layers.Conv2D(filters=filt, kernel_size=3, activation="relu")(inputs)
    x = layers.MaxPooling2D(pool_size=4)(x)
    x = layers.Conv2D(filters=filt, kernel_size=3, activation="relu")(x)
    x = layers.Conv2D(filters=filt, kernel_size=3, activation="relu")(x)
    x = layers.MaxPooling2D(pool_size=4)(x)
    x = layers.Conv2D(filters=filt, kernel_size=3, activation="relu")(x)
    x = layers.Conv2D(filters=filt, kernel_size=3, activation="relu")(x)
    x = layers.MaxPooling2D(pool_size=4)(x)
    x = layers.Conv2D(filters=filt, kernel_size=3, activation="relu")(x)
    x = layers.Conv2D(filters=filt, kernel_size=3, activation="relu")(x)
    x = layers.MaxPooling2D(pool_size=2)(x)
    x = layers.Flatten()(x)
    x = layers.Dense(128, activation="relu")(x)
    x = layers.Dense(16, activation="relu")(x)
    outputs = layers.Dense(3)(x)


    
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 500, 500, 1)]     0         
                                                                 
 conv2d (Conv2D)             (None, 498, 498, 64)      640       
                                                                 
 max_pooling2d (MaxPooling2D  (None, 124, 124, 64)     0         
 )                                                               
                                                                 
 conv2d_1 (Conv2D)           (None, 122, 122, 64)      36928     
                                                                 
 conv2d_2 (Conv2D)           (None, 120, 120, 64)      36928     
                                                                 
 max_pooling2d_1 (MaxPooling  (None, 30, 30, 64)       0         
 2D)                                                             
                                                                 
 conv2d_3 (Conv2D)           (None, 28, 28, 64)        36928     
                                                                 
 conv2d_4 (Conv2D)           (None, 26, 26, 64)        36928     
                                                                 
 max_pooling2d_2 (MaxPooling  (None, 6, 6, 64)         0         
 2D)                                                             
                                                                 
 conv2d_5 (Conv2D)           (None, 4, 4, 64)          36928     
                                                                 
 conv2d_6 (Conv2D)           (None, 2, 2, 64)          36928     
                                                                 
 max_pooling2d_3 (MaxPooling  (None, 1, 1, 64)         0         
 2D)                                                             
                                                                 
 flatten (Flatten)           (None, 64)                0         
                                                                 
 dense (Dense)               (None, 128)               8320      
                                                                 
 dense_1 (Dense)             (None, 16)                2064      
                                                                 
 dense_2 (Dense)             (None, 3)                 51        
                                                                 
=================================================================
Total params: 232,643
Trainable params: 232,643
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
2023-01-29 05:38:18.749611: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8302
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 1/31 [..............................] - ETA: 10s - loss: 0.2595 - abs_loss_function: 0.2595 - accuracy: 0.4062 2/31 [>.............................] - ETA: 6s - loss: 0.2580 - abs_loss_function: 0.2580 - accuracy: 0.4062  3/31 [=>............................] - ETA: 6s - loss: 0.2601 - abs_loss_function: 0.2601 - accuracy: 0.4167 4/31 [==>...........................] - ETA: 6s - loss: 0.2596 - abs_loss_function: 0.2596 - accuracy: 0.4219 5/31 [===>..........................] - ETA: 6s - loss: 0.2595 - abs_loss_function: 0.2595 - accuracy: 0.4250 6/31 [====>.........................] - ETA: 6s - loss: 0.2585 - abs_loss_function: 0.2585 - accuracy: 0.4271 7/31 [=====>........................] - ETA: 5s - loss: 0.2572 - abs_loss_function: 0.2572 - accuracy: 0.4286 8/31 [======>.......................] - ETA: 5s - loss: 0.2558 - abs_loss_function: 0.2558 - accuracy: 0.4297 9/31 [=======>......................] - ETA: 5s - loss: 0.2551 - abs_loss_function: 0.2551 - accuracy: 0.427110/31 [========>.....................] - ETA: 5s - loss: 0.2539 - abs_loss_function: 0.2539 - accuracy: 0.425011/31 [=========>....................] - ETA: 4s - loss: 0.2533 - abs_loss_function: 0.2533 - accuracy: 0.423312/31 [==========>...................] - ETA: 4s - loss: 0.2529 - abs_loss_function: 0.2529 - accuracy: 0.421913/31 [===========>..................] - ETA: 4s - loss: 0.2526 - abs_loss_function: 0.2526 - accuracy: 0.420714/31 [============>.................] - ETA: 4s - loss: 0.2524 - abs_loss_function: 0.2524 - accuracy: 0.419615/31 [=============>................] - ETA: 3s - loss: 0.2522 - abs_loss_function: 0.2522 - accuracy: 0.418716/31 [==============>...............] - ETA: 3s - loss: 0.2517 - abs_loss_function: 0.2517 - accuracy: 0.416017/31 [===============>..............] - ETA: 3s - loss: 0.2513 - abs_loss_function: 0.2513 - accuracy: 0.415418/31 [================>.............] - ETA: 3s - loss: 0.2511 - abs_loss_function: 0.2511 - accuracy: 0.416719/31 [=================>............] - ETA: 2s - loss: 0.2507 - abs_loss_function: 0.2507 - accuracy: 0.416120/31 [==================>...........] - ETA: 2s - loss: 0.2505 - abs_loss_function: 0.2505 - accuracy: 0.415621/31 [===================>..........] - ETA: 2s - loss: 0.2501 - abs_loss_function: 0.2501 - accuracy: 0.415222/31 [====================>.........] - ETA: 2s - loss: 0.2498 - abs_loss_function: 0.2498 - accuracy: 0.414823/31 [=====================>........] - ETA: 1s - loss: 0.2496 - abs_loss_function: 0.2496 - accuracy: 0.413024/31 [======================>.......] - ETA: 1s - loss: 0.2494 - abs_loss_function: 0.2494 - accuracy: 0.412825/31 [=======================>......] - ETA: 1s - loss: 0.2491 - abs_loss_function: 0.2491 - accuracy: 0.411226/31 [========================>.....] - ETA: 1s - loss: 0.2488 - abs_loss_function: 0.2488 - accuracy: 0.409927/31 [=========================>....] - ETA: 0s - loss: 0.2486 - abs_loss_function: 0.2486 - accuracy: 0.408628/31 [==========================>...] - ETA: 0s - loss: 0.2482 - abs_loss_function: 0.2482 - accuracy: 0.407429/31 [===========================>..] - ETA: 0s - loss: 0.2479 - abs_loss_function: 0.2479 - accuracy: 0.405230/31 [============================>.] - ETA: 0s - loss: 0.2475 - abs_loss_function: 0.2475 - accuracy: 0.403131/31 [==============================] - ETA: 0s - loss: 0.2471 - abs_loss_function: 0.2471 - accuracy: 0.401231/31 [==============================] - 8s 248ms/step - loss: 0.2471 - abs_loss_function: 0.2471 - accuracy: 0.4012
/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/utils/image_utils.py:409: UserWarning: grayscale is deprecated. Please use color_mode = "grayscale"
  warnings.warn(
Loss on test data:  0.24707196652889252
----------0----------
phi1 54.7
PHI 36.1
phi2 23.5
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 204ms/step
predicted values [[-6.8906727 -5.1897826  2.331098 ]]
----------1----------
phi1 76.0
PHI 83.7
phi2 2.9
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
predicted values [[-6.9816294 -5.271492   2.3917205]]
----------2----------
phi1 17.8
PHI 63.8
phi2 50.8
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 18ms/step
predicted values [[-6.7395597 -5.05608    2.2839296]]
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++
273/273 - 86s - loss: 0.2402 - abs_loss_function: 0.2402 - accuracy: 0.3140 - val_loss: 0.2653 - val_abs_loss_function: 0.2653 - val_accuracy: 0.2923 - 86s/epoch - 315ms/step
Epoch 2/100
273/273 - 72s - loss: 0.2428 - abs_loss_function: 0.2428 - accuracy: 0.3043 - val_loss: 0.2456 - val_abs_loss_function: 0.2456 - val_accuracy: 0.4304 - 72s/epoch - 265ms/step
Epoch 3/100
273/273 - 83s - loss: 0.2400 - abs_loss_function: 0.2400 - accuracy: 0.3304 - val_loss: 0.2241 - val_abs_loss_function: 0.2241 - val_accuracy: 0.3226 - 83s/epoch - 303ms/step
Epoch 4/100
273/273 - 73s - loss: 0.2371 - abs_loss_function: 0.2371 - accuracy: 0.2880 - val_loss: 0.2716 - val_abs_loss_function: 0.2716 - val_accuracy: 0.3800 - 73s/epoch - 268ms/step
Epoch 5/100
273/273 - 73s - loss: 0.2314 - abs_loss_function: 0.2314 - accuracy: 0.3583 - val_loss: 0.2203 - val_abs_loss_function: 0.2203 - val_accuracy: 0.2490 - 73s/epoch - 268ms/step
Epoch 6/100
273/273 - 71s - loss: 0.1998 - abs_loss_function: 0.1998 - accuracy: 0.2763 - val_loss: 0.2176 - val_abs_loss_function: 0.2176 - val_accuracy: 0.4587 - 71s/epoch - 259ms/step
Epoch 7/100
273/273 - 86s - loss: 0.1871 - abs_loss_function: 0.1871 - accuracy: 0.2280 - val_loss: 0.2485 - val_abs_loss_function: 0.2485 - val_accuracy: 0.3468 - 86s/epoch - 315ms/step
Epoch 8/100
273/273 - 82s - loss: 0.1737 - abs_loss_function: 0.1737 - accuracy: 0.2731 - val_loss: 0.2610 - val_abs_loss_function: 0.2610 - val_accuracy: 0.4163 - 82s/epoch - 300ms/step
Epoch 9/100
273/273 - 83s - loss: 0.1512 - abs_loss_function: 0.1512 - accuracy: 0.2895 - val_loss: 0.2428 - val_abs_loss_function: 0.2428 - val_accuracy: 0.3196 - 83s/epoch - 304ms/step
Epoch 10/100
273/273 - 86s - loss: 0.1472 - abs_loss_function: 0.1472 - accuracy: 0.2743 - val_loss: 0.2368 - val_abs_loss_function: 0.2368 - val_accuracy: 0.4355 - 86s/epoch - 317ms/step
Epoch 11/100
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 1/31 [..............................] - ETA: 10s - loss: 0.2423 - abs_loss_function: 0.2423 - accuracy: 0.4688 2/31 [>.............................] - ETA: 8s - loss: 0.2430 - abs_loss_function: 0.2430 - accuracy: 0.4688  3/31 [=>............................] - ETA: 8s - loss: 0.2431 - abs_loss_function: 0.2431 - accuracy: 0.4583 4/31 [==>...........................] - ETA: 7s - loss: 0.2436 - abs_loss_function: 0.2436 - accuracy: 0.4531 5/31 [===>..........................] - ETA: 7s - loss: 0.2441 - abs_loss_function: 0.2441 - accuracy: 0.4437 6/31 [====>.........................] - ETA: 6s - loss: 0.2440 - abs_loss_function: 0.2440 - accuracy: 0.4323 7/31 [=====>........................] - ETA: 6s - loss: 0.2442 - abs_loss_function: 0.2442 - accuracy: 0.4241 8/31 [======>.......................] - ETA: 6s - loss: 0.2448 - abs_loss_function: 0.2448 - accuracy: 0.4219 9/31 [=======>......................] - ETA: 6s - loss: 0.2447 - abs_loss_function: 0.2447 - accuracy: 0.423610/31 [========>.....................] - ETA: 5s - loss: 0.2449 - abs_loss_function: 0.2449 - accuracy: 0.425011/31 [=========>....................] - ETA: 5s - loss: 0.2448 - abs_loss_function: 0.2448 - accuracy: 0.423312/31 [==========>...................] - ETA: 5s - loss: 0.2447 - abs_loss_function: 0.2447 - accuracy: 0.421913/31 [===========>..................] - ETA: 5s - loss: 0.2446 - abs_loss_function: 0.2446 - accuracy: 0.420714/31 [============>.................] - ETA: 4s - loss: 0.2448 - abs_loss_function: 0.2448 - accuracy: 0.419615/31 [=============>................] - ETA: 4s - loss: 0.2450 - abs_loss_function: 0.2450 - accuracy: 0.420816/31 [==============>...............] - ETA: 4s - loss: 0.2448 - abs_loss_function: 0.2448 - accuracy: 0.423817/31 [===============>..............] - ETA: 4s - loss: 0.2449 - abs_loss_function: 0.2449 - accuracy: 0.428318/31 [================>.............] - ETA: 3s - loss: 0.2449 - abs_loss_function: 0.2449 - accuracy: 0.430619/31 [=================>............] - ETA: 3s - loss: 0.2450 - abs_loss_function: 0.2450 - accuracy: 0.430920/31 [==================>...........] - ETA: 3s - loss: 0.2448 - abs_loss_function: 0.2448 - accuracy: 0.432821/31 [===================>..........] - ETA: 2s - loss: 0.2448 - abs_loss_function: 0.2448 - accuracy: 0.434522/31 [====================>.........] - ETA: 2s - loss: 0.2449 - abs_loss_function: 0.2449 - accuracy: 0.436123/31 [=====================>........] - ETA: 2s - loss: 0.2453 - abs_loss_function: 0.2453 - accuracy: 0.437524/31 [======================>.......] - ETA: 1s - loss: 0.2456 - abs_loss_function: 0.2456 - accuracy: 0.437525/31 [=======================>......] - ETA: 1s - loss: 0.2463 - abs_loss_function: 0.2463 - accuracy: 0.437526/31 [========================>.....] - ETA: 1s - loss: 0.2470 - abs_loss_function: 0.2470 - accuracy: 0.437527/31 [=========================>....] - ETA: 1s - loss: 0.2474 - abs_loss_function: 0.2474 - accuracy: 0.436328/31 [==========================>...] - ETA: 0s - loss: 0.2479 - abs_loss_function: 0.2479 - accuracy: 0.435329/31 [===========================>..] - ETA: 0s - loss: 0.2484 - abs_loss_function: 0.2484 - accuracy: 0.433230/31 [============================>.] - ETA: 0s - loss: 0.2490 - abs_loss_function: 0.2490 - accuracy: 0.432331/31 [==============================] - ETA: 0s - loss: 0.2495 - abs_loss_function: 0.2495 - accuracy: 0.430431/31 [==============================] - 9s 286ms/step - loss: 0.2495 - abs_loss_function: 0.2495 - accuracy: 0.4304
Loss on test data:  0.2494744509458542
----------0----------
phi1 54.7
PHI 36.1
phi2 23.5
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
predicted values [[38.65299   10.745876   6.4826155]]
----------1----------
phi1 76.0
PHI 83.7
phi2 2.9
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
predicted values [[22.551731  17.40079    3.8616414]]
----------2----------
phi1 17.8
PHI 63.8
phi2 50.8
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 18ms/step
predicted values [[-26.2391   -15.775706 -11.176013]]
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++
273/273 - 82s - loss: 0.1391 - abs_loss_function: 0.1391 - accuracy: 0.2819 - val_loss: 0.2431 - val_abs_loss_function: 0.2431 - val_accuracy: 0.2964 - 82s/epoch - 301ms/step
Epoch 12/100
273/273 - 74s - loss: 0.1275 - abs_loss_function: 0.1275 - accuracy: 0.2604 - val_loss: 0.2331 - val_abs_loss_function: 0.2331 - val_accuracy: 0.2742 - 74s/epoch - 270ms/step
Epoch 13/100
273/273 - 84s - loss: 0.1217 - abs_loss_function: 0.1217 - accuracy: 0.2785 - val_loss: 0.2501 - val_abs_loss_function: 0.2501 - val_accuracy: 0.2923 - 84s/epoch - 309ms/step
Epoch 14/100
273/273 - 82s - loss: 0.1093 - abs_loss_function: 0.1093 - accuracy: 0.2655 - val_loss: 0.2578 - val_abs_loss_function: 0.2578 - val_accuracy: 0.3377 - 82s/epoch - 301ms/step
Epoch 15/100
273/273 - 82s - loss: 0.1074 - abs_loss_function: 0.1074 - accuracy: 0.2553 - val_loss: 0.2863 - val_abs_loss_function: 0.2863 - val_accuracy: 0.2581 - 82s/epoch - 300ms/step
Epoch 16/100
273/273 - 86s - loss: 0.1069 - abs_loss_function: 0.1069 - accuracy: 0.3275 - val_loss: 0.2500 - val_abs_loss_function: 0.2500 - val_accuracy: 0.4093 - 86s/epoch - 314ms/step
Epoch 17/100
273/273 - 73s - loss: 0.0990 - abs_loss_function: 0.0990 - accuracy: 0.2922 - val_loss: 0.2355 - val_abs_loss_function: 0.2355 - val_accuracy: 0.3911 - 73s/epoch - 267ms/step
Epoch 18/100
273/273 - 75s - loss: 0.0994 - abs_loss_function: 0.0994 - accuracy: 0.2767 - val_loss: 0.2361 - val_abs_loss_function: 0.2361 - val_accuracy: 0.2480 - 75s/epoch - 276ms/step
Epoch 19/100
273/273 - 76s - loss: 0.0945 - abs_loss_function: 0.0945 - accuracy: 0.2572 - val_loss: 0.2390 - val_abs_loss_function: 0.2390 - val_accuracy: 0.2520 - 76s/epoch - 277ms/step
Epoch 20/100
273/273 - 73s - loss: 0.0929 - abs_loss_function: 0.0929 - accuracy: 0.2451 - val_loss: 0.2512 - val_abs_loss_function: 0.2512 - val_accuracy: 0.4486 - 73s/epoch - 269ms/step
Epoch 21/100
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 1/31 [..............................] - ETA: 8s - loss: 0.2645 - abs_loss_function: 0.2645 - accuracy: 0.4062 2/31 [>.............................] - ETA: 7s - loss: 0.2646 - abs_loss_function: 0.2646 - accuracy: 0.3906 3/31 [=>............................] - ETA: 6s - loss: 0.2656 - abs_loss_function: 0.2656 - accuracy: 0.3854 4/31 [==>...........................] - ETA: 6s - loss: 0.2667 - abs_loss_function: 0.2667 - accuracy: 0.3750 5/31 [===>..........................] - ETA: 6s - loss: 0.2664 - abs_loss_function: 0.2664 - accuracy: 0.3625 6/31 [====>.........................] - ETA: 5s - loss: 0.2656 - abs_loss_function: 0.2656 - accuracy: 0.3542 7/31 [=====>........................] - ETA: 5s - loss: 0.2653 - abs_loss_function: 0.2653 - accuracy: 0.3482 8/31 [======>.......................] - ETA: 5s - loss: 0.2645 - abs_loss_function: 0.2645 - accuracy: 0.3438 9/31 [=======>......................] - ETA: 5s - loss: 0.2631 - abs_loss_function: 0.2631 - accuracy: 0.336810/31 [========>.....................] - ETA: 5s - loss: 0.2621 - abs_loss_function: 0.2621 - accuracy: 0.331311/31 [=========>....................] - ETA: 4s - loss: 0.2615 - abs_loss_function: 0.2615 - accuracy: 0.326712/31 [==========>...................] - ETA: 4s - loss: 0.2611 - abs_loss_function: 0.2611 - accuracy: 0.325513/31 [===========>..................] - ETA: 4s - loss: 0.2609 - abs_loss_function: 0.2609 - accuracy: 0.326914/31 [============>.................] - ETA: 4s - loss: 0.2606 - abs_loss_function: 0.2606 - accuracy: 0.328115/31 [=============>................] - ETA: 3s - loss: 0.2601 - abs_loss_function: 0.2601 - accuracy: 0.329216/31 [==============>...............] - ETA: 3s - loss: 0.2601 - abs_loss_function: 0.2601 - accuracy: 0.332017/31 [===============>..............] - ETA: 3s - loss: 0.2602 - abs_loss_function: 0.2602 - accuracy: 0.334618/31 [================>.............] - ETA: 3s - loss: 0.2599 - abs_loss_function: 0.2599 - accuracy: 0.336819/31 [=================>............] - ETA: 2s - loss: 0.2598 - abs_loss_function: 0.2598 - accuracy: 0.340520/31 [==================>...........] - ETA: 2s - loss: 0.2599 - abs_loss_function: 0.2599 - accuracy: 0.343821/31 [===================>..........] - ETA: 2s - loss: 0.2597 - abs_loss_function: 0.2597 - accuracy: 0.346722/31 [====================>.........] - ETA: 2s - loss: 0.2593 - abs_loss_function: 0.2593 - accuracy: 0.349423/31 [=====================>........] - ETA: 1s - loss: 0.2587 - abs_loss_function: 0.2587 - accuracy: 0.351924/31 [======================>.......] - ETA: 1s - loss: 0.2584 - abs_loss_function: 0.2584 - accuracy: 0.354225/31 [=======================>......] - ETA: 1s - loss: 0.2583 - abs_loss_function: 0.2583 - accuracy: 0.356226/31 [========================>.....] - ETA: 1s - loss: 0.2584 - abs_loss_function: 0.2584 - accuracy: 0.359427/31 [=========================>....] - ETA: 0s - loss: 0.2583 - abs_loss_function: 0.2583 - accuracy: 0.362328/31 [==========================>...] - ETA: 0s - loss: 0.2581 - abs_loss_function: 0.2581 - accuracy: 0.365029/31 [===========================>..] - ETA: 0s - loss: 0.2578 - abs_loss_function: 0.2578 - accuracy: 0.366430/31 [============================>.] - ETA: 0s - loss: 0.2576 - abs_loss_function: 0.2576 - accuracy: 0.368831/31 [==============================] - ETA: 0s - loss: 0.2572 - abs_loss_function: 0.2572 - accuracy: 0.370031/31 [==============================] - 8s 241ms/step - loss: 0.2572 - abs_loss_function: 0.2572 - accuracy: 0.3700
Loss on test data:  0.25721535086631775
----------0----------
phi1 54.7
PHI 36.1
phi2 23.5
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
predicted values [[ 31.95246  -26.219618   4.134342]]
----------1----------
phi1 76.0
PHI 83.7
phi2 2.9
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
predicted values [[34.85233  21.693605 38.33741 ]]
----------2----------
phi1 17.8
PHI 63.8
phi2 50.8
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 18ms/step
predicted values [[ 30.274622 -48.61353  -19.671743]]
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++
273/273 - 81s - loss: 0.0947 - abs_loss_function: 0.0947 - accuracy: 0.2838 - val_loss: 0.2657 - val_abs_loss_function: 0.2657 - val_accuracy: 0.4173 - 81s/epoch - 298ms/step
Epoch 22/100
273/273 - 73s - loss: 0.0910 - abs_loss_function: 0.0910 - accuracy: 0.2487 - val_loss: 0.2414 - val_abs_loss_function: 0.2414 - val_accuracy: 0.3266 - 73s/epoch - 269ms/step
Epoch 23/100
273/273 - 71s - loss: 0.0869 - abs_loss_function: 0.0869 - accuracy: 0.2622 - val_loss: 0.2519 - val_abs_loss_function: 0.2519 - val_accuracy: 0.3659 - 71s/epoch - 262ms/step
Epoch 24/100
273/273 - 65s - loss: 0.0901 - abs_loss_function: 0.0901 - accuracy: 0.2539 - val_loss: 0.2862 - val_abs_loss_function: 0.2862 - val_accuracy: 0.3427 - 65s/epoch - 239ms/step
Epoch 25/100
273/273 - 64s - loss: 0.0859 - abs_loss_function: 0.0859 - accuracy: 0.2826 - val_loss: 0.2446 - val_abs_loss_function: 0.2446 - val_accuracy: 0.3700 - 64s/epoch - 235ms/step
Epoch 26/100
273/273 - 70s - loss: 0.0862 - abs_loss_function: 0.0862 - accuracy: 0.2443 - val_loss: 0.2498 - val_abs_loss_function: 0.2498 - val_accuracy: 0.2933 - 70s/epoch - 255ms/step
Epoch 27/100
273/273 - 71s - loss: 0.0839 - abs_loss_function: 0.0839 - accuracy: 0.2574 - val_loss: 0.2413 - val_abs_loss_function: 0.2413 - val_accuracy: 0.2177 - 71s/epoch - 262ms/step
Epoch 28/100
273/273 - 69s - loss: 0.0834 - abs_loss_function: 0.0834 - accuracy: 0.2973 - val_loss: 0.2343 - val_abs_loss_function: 0.2343 - val_accuracy: 0.3196 - 69s/epoch - 254ms/step
Epoch 29/100
273/273 - 71s - loss: 0.0829 - abs_loss_function: 0.0829 - accuracy: 0.2896 - val_loss: 0.2408 - val_abs_loss_function: 0.2408 - val_accuracy: 0.2843 - 71s/epoch - 259ms/step
Epoch 30/100
273/273 - 71s - loss: 0.0803 - abs_loss_function: 0.0803 - accuracy: 0.2470 - val_loss: 0.2483 - val_abs_loss_function: 0.2483 - val_accuracy: 0.3276 - 71s/epoch - 259ms/step
Epoch 31/100
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 1/31 [..............................] - ETA: 8s - loss: 0.2329 - abs_loss_function: 0.2329 - accuracy: 0.1562 2/31 [>.............................] - ETA: 6s - loss: 0.2335 - abs_loss_function: 0.2335 - accuracy: 0.1562 3/31 [=>............................] - ETA: 6s - loss: 0.2328 - abs_loss_function: 0.2328 - accuracy: 0.1562 4/31 [==>...........................] - ETA: 6s - loss: 0.2315 - abs_loss_function: 0.2315 - accuracy: 0.1562 5/31 [===>..........................] - ETA: 5s - loss: 0.2309 - abs_loss_function: 0.2309 - accuracy: 0.1625 6/31 [====>.........................] - ETA: 5s - loss: 0.2300 - abs_loss_function: 0.2300 - accuracy: 0.1667 7/31 [=====>........................] - ETA: 5s - loss: 0.2294 - abs_loss_function: 0.2294 - accuracy: 0.1696 8/31 [======>.......................] - ETA: 5s - loss: 0.2298 - abs_loss_function: 0.2298 - accuracy: 0.1719 9/31 [=======>......................] - ETA: 4s - loss: 0.2296 - abs_loss_function: 0.2296 - accuracy: 0.170110/31 [========>.....................] - ETA: 4s - loss: 0.2295 - abs_loss_function: 0.2295 - accuracy: 0.168811/31 [=========>....................] - ETA: 4s - loss: 0.2292 - abs_loss_function: 0.2292 - accuracy: 0.167612/31 [==========>...................] - ETA: 4s - loss: 0.2286 - abs_loss_function: 0.2286 - accuracy: 0.166713/31 [===========>..................] - ETA: 3s - loss: 0.2283 - abs_loss_function: 0.2283 - accuracy: 0.165914/31 [============>.................] - ETA: 3s - loss: 0.2278 - abs_loss_function: 0.2278 - accuracy: 0.165215/31 [=============>................] - ETA: 3s - loss: 0.2278 - abs_loss_function: 0.2278 - accuracy: 0.166716/31 [==============>...............] - ETA: 3s - loss: 0.2278 - abs_loss_function: 0.2278 - accuracy: 0.168017/31 [===============>..............] - ETA: 3s - loss: 0.2279 - abs_loss_function: 0.2279 - accuracy: 0.167318/31 [================>.............] - ETA: 2s - loss: 0.2280 - abs_loss_function: 0.2280 - accuracy: 0.166719/31 [=================>............] - ETA: 2s - loss: 0.2281 - abs_loss_function: 0.2281 - accuracy: 0.166120/31 [==================>...........] - ETA: 2s - loss: 0.2282 - abs_loss_function: 0.2282 - accuracy: 0.167221/31 [===================>..........] - ETA: 2s - loss: 0.2285 - abs_loss_function: 0.2285 - accuracy: 0.169622/31 [====================>.........] - ETA: 2s - loss: 0.2289 - abs_loss_function: 0.2289 - accuracy: 0.170523/31 [=====================>........] - ETA: 1s - loss: 0.2290 - abs_loss_function: 0.2290 - accuracy: 0.171224/31 [======================>.......] - ETA: 1s - loss: 0.2291 - abs_loss_function: 0.2291 - accuracy: 0.173225/31 [=======================>......] - ETA: 1s - loss: 0.2288 - abs_loss_function: 0.2288 - accuracy: 0.175026/31 [========================>.....] - ETA: 1s - loss: 0.2285 - abs_loss_function: 0.2285 - accuracy: 0.176727/31 [=========================>....] - ETA: 0s - loss: 0.2285 - abs_loss_function: 0.2285 - accuracy: 0.178228/31 [==========================>...] - ETA: 0s - loss: 0.2285 - abs_loss_function: 0.2285 - accuracy: 0.179729/31 [===========================>..] - ETA: 0s - loss: 0.2286 - abs_loss_function: 0.2286 - accuracy: 0.180030/31 [============================>.] - ETA: 0s - loss: 0.2287 - abs_loss_function: 0.2287 - accuracy: 0.181331/31 [==============================] - ETA: 0s - loss: 0.2288 - abs_loss_function: 0.2288 - accuracy: 0.182531/31 [==============================] - 7s 224ms/step - loss: 0.2288 - abs_loss_function: 0.2288 - accuracy: 0.1825
Loss on test data:  0.22883763909339905
----------0----------
phi1 54.7
PHI 36.1
phi2 23.5
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
predicted values [[25.364235  -2.7053857 10.679347 ]]
----------1----------
phi1 76.0
PHI 83.7
phi2 2.9
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 20ms/step
predicted values [[14.82529  11.569633 14.145281]]
----------2----------
phi1 17.8
PHI 63.8
phi2 50.8
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
predicted values [[  5.6904817  -3.573319  -15.412356 ]]
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++
273/273 - 73s - loss: 0.0765 - abs_loss_function: 0.0765 - accuracy: 0.2288 - val_loss: 0.2391 - val_abs_loss_function: 0.2391 - val_accuracy: 0.3256 - 73s/epoch - 268ms/step
Epoch 32/100
273/273 - 71s - loss: 0.0752 - abs_loss_function: 0.0752 - accuracy: 0.2861 - val_loss: 0.2351 - val_abs_loss_function: 0.2351 - val_accuracy: 0.2339 - 71s/epoch - 259ms/step
Epoch 33/100
273/273 - 73s - loss: 0.0745 - abs_loss_function: 0.0745 - accuracy: 0.2688 - val_loss: 0.2311 - val_abs_loss_function: 0.2311 - val_accuracy: 0.2409 - 73s/epoch - 267ms/step
Epoch 34/100
273/273 - 71s - loss: 0.0768 - abs_loss_function: 0.0768 - accuracy: 0.2435 - val_loss: 0.2464 - val_abs_loss_function: 0.2464 - val_accuracy: 0.2218 - 71s/epoch - 259ms/step
Epoch 35/100
273/273 - 73s - loss: 0.0750 - abs_loss_function: 0.0750 - accuracy: 0.2304 - val_loss: 0.2323 - val_abs_loss_function: 0.2323 - val_accuracy: 0.2933 - 73s/epoch - 266ms/step
Epoch 36/100
273/273 - 75s - loss: 0.0757 - abs_loss_function: 0.0757 - accuracy: 0.2539 - val_loss: 0.2550 - val_abs_loss_function: 0.2550 - val_accuracy: 0.2752 - 75s/epoch - 273ms/step
Epoch 37/100
273/273 - 77s - loss: 0.0739 - abs_loss_function: 0.0739 - accuracy: 0.2717 - val_loss: 0.2616 - val_abs_loss_function: 0.2616 - val_accuracy: 0.3690 - 77s/epoch - 284ms/step
Epoch 38/100
273/273 - 90s - loss: 0.0750 - abs_loss_function: 0.0750 - accuracy: 0.2603 - val_loss: 0.2460 - val_abs_loss_function: 0.2460 - val_accuracy: 0.2077 - 90s/epoch - 331ms/step
Epoch 39/100
273/273 - 80s - loss: 0.0723 - abs_loss_function: 0.0723 - accuracy: 0.2447 - val_loss: 0.2287 - val_abs_loss_function: 0.2287 - val_accuracy: 0.3014 - 80s/epoch - 294ms/step
Epoch 40/100
273/273 - 84s - loss: 0.0715 - abs_loss_function: 0.0715 - accuracy: 0.2308 - val_loss: 0.2477 - val_abs_loss_function: 0.2477 - val_accuracy: 0.2863 - 84s/epoch - 306ms/step
Epoch 41/100
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 1/31 [..............................] - ETA: 10s - loss: 0.2357 - abs_loss_function: 0.2357 - accuracy: 0.3125 2/31 [>.............................] - ETA: 7s - loss: 0.2350 - abs_loss_function: 0.2350 - accuracy: 0.3125  3/31 [=>............................] - ETA: 7s - loss: 0.2344 - abs_loss_function: 0.2344 - accuracy: 0.3125 4/31 [==>...........................] - ETA: 7s - loss: 0.2340 - abs_loss_function: 0.2340 - accuracy: 0.3203 5/31 [===>..........................] - ETA: 6s - loss: 0.2330 - abs_loss_function: 0.2330 - accuracy: 0.3250 6/31 [====>.........................] - ETA: 6s - loss: 0.2322 - abs_loss_function: 0.2322 - accuracy: 0.3281 7/31 [=====>........................] - ETA: 6s - loss: 0.2315 - abs_loss_function: 0.2315 - accuracy: 0.3259 8/31 [======>.......................] - ETA: 6s - loss: 0.2305 - abs_loss_function: 0.2305 - accuracy: 0.3242 9/31 [=======>......................] - ETA: 5s - loss: 0.2301 - abs_loss_function: 0.2301 - accuracy: 0.326410/31 [========>.....................] - ETA: 5s - loss: 0.2300 - abs_loss_function: 0.2300 - accuracy: 0.328111/31 [=========>....................] - ETA: 5s - loss: 0.2296 - abs_loss_function: 0.2296 - accuracy: 0.326712/31 [==========>...................] - ETA: 5s - loss: 0.2301 - abs_loss_function: 0.2301 - accuracy: 0.328113/31 [===========>..................] - ETA: 4s - loss: 0.2303 - abs_loss_function: 0.2303 - accuracy: 0.329314/31 [============>.................] - ETA: 4s - loss: 0.2309 - abs_loss_function: 0.2309 - accuracy: 0.330415/31 [=============>................] - ETA: 4s - loss: 0.2318 - abs_loss_function: 0.2318 - accuracy: 0.333316/31 [==============>...............] - ETA: 4s - loss: 0.2328 - abs_loss_function: 0.2328 - accuracy: 0.337917/31 [===============>..............] - ETA: 3s - loss: 0.2334 - abs_loss_function: 0.2334 - accuracy: 0.343818/31 [================>.............] - ETA: 3s - loss: 0.2339 - abs_loss_function: 0.2339 - accuracy: 0.347219/31 [=================>............] - ETA: 3s - loss: 0.2345 - abs_loss_function: 0.2345 - accuracy: 0.350320/31 [==================>...........] - ETA: 3s - loss: 0.2347 - abs_loss_function: 0.2347 - accuracy: 0.351621/31 [===================>..........] - ETA: 2s - loss: 0.2347 - abs_loss_function: 0.2347 - accuracy: 0.352722/31 [====================>.........] - ETA: 2s - loss: 0.2345 - abs_loss_function: 0.2345 - accuracy: 0.353723/31 [=====================>........] - ETA: 2s - loss: 0.2343 - abs_loss_function: 0.2343 - accuracy: 0.356024/31 [======================>.......] - ETA: 1s - loss: 0.2342 - abs_loss_function: 0.2342 - accuracy: 0.359425/31 [=======================>......] - ETA: 1s - loss: 0.2340 - abs_loss_function: 0.2340 - accuracy: 0.362526/31 [========================>.....] - ETA: 1s - loss: 0.2339 - abs_loss_function: 0.2339 - accuracy: 0.366627/31 [=========================>....] - ETA: 1s - loss: 0.2338 - abs_loss_function: 0.2338 - accuracy: 0.369228/31 [==========================>...] - ETA: 0s - loss: 0.2336 - abs_loss_function: 0.2336 - accuracy: 0.371729/31 [===========================>..] - ETA: 0s - loss: 0.2334 - abs_loss_function: 0.2334 - accuracy: 0.372830/31 [============================>.] - ETA: 0s - loss: 0.2333 - abs_loss_function: 0.2333 - accuracy: 0.374031/31 [==============================] - ETA: 0s - loss: 0.2334 - abs_loss_function: 0.2334 - accuracy: 0.375031/31 [==============================] - 9s 274ms/step - loss: 0.2334 - abs_loss_function: 0.2334 - accuracy: 0.3750
Loss on test data:  0.23342058062553406
----------0----------
phi1 54.7
PHI 36.1
phi2 23.5
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 19ms/step
predicted values [[38.135487   7.5373573 10.085877 ]]
----------1----------
phi1 76.0
PHI 83.7
phi2 2.9
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 18ms/step
predicted values [[ 8.147976  5.489079 -9.915071]]
----------2----------
phi1 17.8
PHI 63.8
phi2 50.8
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 18ms/step
predicted values [[  3.3469446 -21.657434  -38.728546 ]]
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++
273/273 - 80s - loss: 0.0718 - abs_loss_function: 0.0718 - accuracy: 0.2325 - val_loss: 0.2403 - val_abs_loss_function: 0.2403 - val_accuracy: 0.3236 - 80s/epoch - 293ms/step
Epoch 42/100
273/273 - 72s - loss: 0.0712 - abs_loss_function: 0.0712 - accuracy: 0.2611 - val_loss: 0.2525 - val_abs_loss_function: 0.2525 - val_accuracy: 0.2833 - 72s/epoch - 264ms/step
Epoch 43/100
273/273 - 73s - loss: 0.0728 - abs_loss_function: 0.0728 - accuracy: 0.2719 - val_loss: 0.2491 - val_abs_loss_function: 0.2491 - val_accuracy: 0.2641 - 73s/epoch - 266ms/step
Epoch 44/100
273/273 - 81s - loss: 0.0703 - abs_loss_function: 0.0703 - accuracy: 0.2213 - val_loss: 0.2451 - val_abs_loss_function: 0.2451 - val_accuracy: 0.1915 - 81s/epoch - 298ms/step
Epoch 45/100
