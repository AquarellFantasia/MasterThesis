{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c750ae68",
   "metadata": {},
   "source": [
    "# - This notebook shows the experiments with convolutional blocks -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad176564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.utils import Sequence\n",
    "from keras.utils import load_img\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74d1b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug info\n",
    "!nvidia-smi\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1c0c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the image location data\n",
    "df = pd.read_csv('black_background_500x500.csv')\n",
    "train_df = df[df['ImagePath'].str.contains(\"train\")]\n",
    "test_df = df[df['ImagePath'].str.contains(\"test\")]\n",
    "valid_df = df[df['ImagePath'].str.contains(\"valid\")]\n",
    "\n",
    "input_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f533699f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generator \n",
    "\n",
    "class datagenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, \n",
    "            batch_size, \n",
    "            img_size,\n",
    "            data_paths_df,\n",
    "            input_channels,\n",
    "            output_channels):\n",
    "         \n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.data_paths_df = data_paths_df\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "        self.data_paths = data_paths_df.values[:,1]\n",
    "        self.params = data_paths_df.values[:,3:6]\n",
    "        assert len(self.data_paths) == len(self.params)\n",
    "        \n",
    "        self.n = len(self.data_paths)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'updates indexes after each epoch'\n",
    "        self.data_paths_df = self.data_paths_df.sample(frac = 1)\n",
    "        self.data_paths = self.data_paths_df.values[:,1]\n",
    "        self.params = self.data_paths_df.values[:,3:6]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_data_paths = self.data_paths[index : index + self.batch_size]\n",
    "        batch_params_paths = self.params[index : index + self.batch_size]\n",
    "\n",
    "        return self.__dataloader(self.img_size,\n",
    "                batch_data_paths, batch_params_paths,\n",
    "                self.input_channels, self.output_channels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size\n",
    "\n",
    "    #################### data loader ########################\n",
    "    def __dataloader(self, \n",
    "            img_size,\n",
    "            data_paths,\n",
    "            batch_params_paths,\n",
    "            input_channels,\n",
    "            output_channels):\n",
    "        x = np.zeros((len(data_paths), img_size[0], img_size[1], input_channels))\n",
    "        y = batch_params_paths        \n",
    "        \n",
    "        for i in range(len(data_paths)):\n",
    "            data = load_img(path = data_paths[i], color_mode = \"grayscale\")\n",
    "            data = tf.keras.utils.img_to_array(data, data_format=\"channels_last\", dtype=\"float32\")\n",
    "            data /= 255\n",
    "            x[i] = np.asarray(data)\n",
    "        return x.astype(\"float32\"), np.array(y).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb55ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitons of convolutional blocks\n",
    "def conv_block(x, filters, kernel_size, regul):\n",
    "    if regul:\n",
    "        biasregul = regularizers.l2(regul)\n",
    "        kernelregul = regularizers.l2(regul)\n",
    "    else:\n",
    "        biasregul = kernelregul = None\n",
    "    x = layers.Conv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            kernel_initializer='RandomNormal',\n",
    "            padding=\"same\",\n",
    "            bias_initializer=initializers.Constant(0.1),\n",
    "            kernel_regularizer=kernelregul,\n",
    "            bias_regularizer=biasregul\n",
    "            )(x)\n",
    "    x = layers.PReLU(\n",
    "            shared_axes=[1,2],\n",
    "            alpha_initializer=tf.initializers.Constant(0.01),\n",
    "            )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "#     x = layers.Activation(\"relu\")(x)\n",
    "#     x = layers.Dropout(rate=0.5)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def mega_conv_block(x, filters, kernel_size, regul):\n",
    "    # Skip\n",
    "    previous_block_activation = x\n",
    "    # Residual block\n",
    "    x = conv_block(x, channels, 5, regul)\n",
    "    x = conv_block(x, channels, 3, regul)\n",
    "    x = conv_block(x, channels, 3, regul)\n",
    "    x = layers.concatenate([x, previous_block_activation])\n",
    "    # Exit \n",
    "    x = conv_block(x, channels, 3, regul)\n",
    "    # Max pool\n",
    "    x = layers.MaxPooling2D(pool_size=4, padding='same')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1210eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model\n",
    "regul = 0.01\n",
    "channels = 4\n",
    "inputs = keras.Input(shape=(input_size, input_size, 1))\n",
    "x = inputs\n",
    "# Entry\n",
    "x = conv_block(x, channels, 11, regul)\n",
    "x = conv_block(x, channels, 11, regul)\n",
    "x = layers.MaxPooling2D(pool_size=4, padding='same')(x)\n",
    "x = conv_block(x, channels, 5, regul)\n",
    "x = conv_block(x, channels, 5, regul)\n",
    "x = layers.MaxPooling2D(pool_size=4, padding='same')(x)\n",
    "x = conv_block(x, channels, 3, regul)\n",
    "x = conv_block(x, channels, 3, regul)\n",
    "x = layers.MaxPooling2D(pool_size=4, padding='same')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(64)(x)\n",
    "x = layers.Dropout(rate=0.5)(x)\n",
    "outputs = layers.Dense(3)(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901d44f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def abs_loss_function(y_true, y_pred):   \n",
    "    abs_diff = K.abs(y_true - y_pred)\n",
    "    ones = tf.ones_like(y_true)\n",
    "    abs_diff_reversed = K.abs(ones - abs_diff )   \n",
    "    minimum_from_two = tf.math.minimum(abs_diff, abs_diff_reversed) \n",
    "    return tf.math.reduce_mean(minimum_from_two, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621c458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback function\n",
    "test_g = datagenerator(32, (input_size,input_size), test_df, 1, 3)\n",
    "evaluation_list = []\n",
    "accuracy_list = []\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "            m_e = self.model.evaluate(test_g, batch_size=32)\n",
    "            for i in range(10):\n",
    "                evaluation_list.append(m_e[0])\n",
    "                accuracy_list.append(m_e[2])\n",
    "            print(\"Loss on test data: \", m_e[0])\n",
    "            for nr in range(3):\n",
    "                t = test_df.values[nr][1]\n",
    "                data = load_img(path = t, grayscale = True)\n",
    "                data = tf.keras.utils.img_to_array(data, data_format=\"channels_last\", dtype=\"float32\")\n",
    "                data /= 255\n",
    "                data.shape = (1,) + data.shape\n",
    "                X = np.asarray(data)\n",
    "                print(\"----------{}----------\".format(nr))\n",
    "                euler = t.split(\"_\")\n",
    "                print(\"phi1\", float(euler[3]))\n",
    "                print(\"PHI\",   float(euler[4]))\n",
    "                print(\"phi2\",  float(euler[5][:-4]))\n",
    "                yhat = model.predict(data)\n",
    "                print(\"predicted values\", yhat*90)\n",
    "            print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce477929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and run the model \n",
    "model.compile(optimizer = RMSprop(learning_rate=0.001),\n",
    "              loss = abs_loss_function, \n",
    "              metrics = [abs_loss_function, \"accuracy\"],\n",
    "              run_eagerly=True)  # Add run_eagerly=True to enable the numpy debugging\n",
    "\n",
    "tg = datagenerator(32, (input_size,input_size), train_df, 1, 3)\n",
    "vg = datagenerator(32, (input_size,input_size), valid_df, 1, 3)\n",
    "history = model.fit(x=tg,\n",
    "                    batch_size=32,\n",
    "                    epochs=100,\n",
    "                    validation_data=vg,\n",
    "                    callbacks=[LossHistory()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5da96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,5))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(221)\n",
    "plt.plot(history.history['accuracy'],'bo--', label = \"acc\")\n",
    "plt.plot(history.history['val_accuracy'],'ro--', label = \"val_accuracy\")\n",
    "plt.plot(accuracy_list,'go--', label = \"eval_acc\")\n",
    "plt.title(\"train_acc vs val_acc\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss function\n",
    "plt.subplot(222)\n",
    "plt.plot(history.history['loss'],'bo--', label = \"loss\")\n",
    "plt.plot(history.history['val_loss'],'ro--', label = \"val_loss\")\n",
    "plt.plot(evaluation_list,'go--', label = \"eval_loss\")\n",
    "plt.title(\"train_loss vs val_loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
