{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17f66450",
   "metadata": {},
   "source": [
    "# -This notebook shows an experiment of taking the best model and running it for 300 epochs, to see if there is going to be an improvement after 100 epochs-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27249cc",
   "metadata": {},
   "source": [
    "# Imports and data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad176564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-29 01:00:45.253348: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "############################# Imports ################################\n",
    "######################################################################\n",
    "import sys\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import CustomObjectScope\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.models import load_model \n",
    "from keras.utils import Sequence\n",
    "from keras.utils import load_img\n",
    "from keras.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c74d1b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jan 29 01:00:50 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 525.60.13    Driver Version: 525.60.13    CUDA Version: 12.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-PCIE...  On   | 00000000:37:00.0 Off |                    0 |\r\n",
      "| N/A   35C    P0    39W / 250W |  15102MiB / 16384MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla V100-PCIE...  On   | 00000000:AF:00.0 Off |                    0 |\r\n",
      "| N/A   28C    P0    25W / 250W |      0MiB / 16384MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      5511      C   ...4/Masters/venv/bin/python    15098MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################################################    \n",
    "########################### Debug info ###############################    \n",
    "######################################################################  \n",
    "!nvidia-smi\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb1c0c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################    \n",
    "####################### Load refference data #########################    \n",
    "######################################################################  \n",
    "df = pd.read_csv('black_background_500x500.csv')\n",
    "train_df = df[df['ImagePath'].str.contains(\"train\")]\n",
    "test_df = df[df['ImagePath'].str.contains(\"test\")]\n",
    "valid_df = df[df['ImagePath'].str.contains(\"valid\")]\n",
    "\n",
    "input_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f533699f",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "############################ data generator ##########################\n",
    "######################################################################\n",
    "class datagenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, \n",
    "            batch_size, \n",
    "            img_size,\n",
    "            data_paths_df,\n",
    "            input_channels,\n",
    "            output_channels):\n",
    "         \n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.data_paths_df = data_paths_df\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "        self.data_paths = data_paths_df.values[:,1]\n",
    "        self.params = data_paths_df.values[:,3:6]\n",
    "        assert len(self.data_paths) == len(self.params)\n",
    "        \n",
    "        self.n = len(self.data_paths)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'updates indexes after each epoch'\n",
    "        self.data_paths_df = self.data_paths_df.sample(frac = 1)\n",
    "        self.data_paths = self.data_paths_df.values[:,1]\n",
    "        self.params = self.data_paths_df.values[:,3:6]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_data_paths = self.data_paths[index : index + self.batch_size]\n",
    "        batch_params_paths = self.params[index : index + self.batch_size]\n",
    "\n",
    "        return self.__dataloader(self.img_size,\n",
    "                batch_data_paths, batch_params_paths,\n",
    "                self.input_channels, self.output_channels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size\n",
    "\n",
    "    #################### data loader ########################\n",
    "    def __dataloader(self, \n",
    "            img_size,\n",
    "            data_paths,\n",
    "            batch_params_paths,\n",
    "            input_channels,\n",
    "            output_channels):\n",
    "        x = np.zeros((len(data_paths), img_size[0], img_size[1], input_channels))\n",
    "        y = batch_params_paths        \n",
    "        \n",
    "        for i in range(len(data_paths)):\n",
    "            data = load_img(path = data_paths[i], color_mode = \"grayscale\")\n",
    "            data = tf.keras.utils.img_to_array(data, data_format=\"channels_last\", dtype=\"float32\")\n",
    "            data /= 255\n",
    "            x[i] = np.asarray(data)\n",
    "        return x.astype(\"float32\"), np.array(y).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913735f4",
   "metadata": {},
   "source": [
    "# Definitions of important functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "901d44f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################    \n",
    "########################## Loss functions ############################    \n",
    "###################################################################### \n",
    "import keras.backend as K\n",
    "  \n",
    "def abs_loss_function(y_true, y_pred):   \n",
    "    abs_diff = K.abs(y_true - y_pred)\n",
    "    ones = tf.ones_like(y_true)\n",
    "    abs_diff_reversed = K.abs(ones - abs_diff )   \n",
    "    minimum_from_two = tf.math.minimum(abs_diff, abs_diff_reversed) \n",
    "    return tf.math.reduce_mean(minimum_from_two, axis=-1)\n",
    "\n",
    "def square_abs_min_loss(y_true, y_pred):   \n",
    "    abs_diff = K.abs(y_true - y_pred)\n",
    "    ones = tf.ones_like(y_true)\n",
    "    abs_diff_reversed = K.abs(tf.ones_like(y_true) - abs_diff )   \n",
    "    minimum_from_two = tf.math.minimum(abs_diff, abs_diff_reversed) \n",
    "    min_sq = tf.math.sqrt(minimum_from_two)\n",
    "    return tf.math.reduce_mean(min_sq, axis=-1) \n",
    "\n",
    "def smart_square_abs_min_loss(y_true, y_pred):  \n",
    "    punished_y_pred = tf.where((y_pred<0)|(y_pred>1), 3.0 + K.abs(y_pred),y_pred)\n",
    "    abs_diff = K.abs(y_true - punished_y_pred)\n",
    "    ones = tf.ones_like(y_true)\n",
    "    abs_diff_reversed = K.abs(ones - abs_diff)   \n",
    "    minimum_from_two = tf.math.minimum(abs_diff, abs_diff_reversed)     \n",
    "    return tf.math.reduce_mean(minimum_from_two, axis=-1)\n",
    "    \n",
    "############################# For debugging ####################################\n",
    "#     print(\"_________________ 1 __________________\")\n",
    "#     print(abs_diff_reversed.numpy())\n",
    "#     print(\"_________________ 2 __________________\")\n",
    "#     print(abs_diff.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "621c458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################    \n",
    "############## Callback function to print evaluation #################    \n",
    "###################################################################### \n",
    "test_g = datagenerator(32, (input_size,input_size), test_df, 1, 3)\n",
    "evaluation_list = []\n",
    "accuracy_list = []\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch % 5 == 0:\n",
    "            print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "            m_e = self.model.evaluate(test_g, batch_size=32)\n",
    "            for i in range(60):\n",
    "                evaluation_list.append(m_e[0])\n",
    "                accuracy_list.append(m_e[2])\n",
    "            print(\"Loss on test data: \", m_e[0])\n",
    "            for nr in range(3):\n",
    "                t = test_df.values[nr][1]\n",
    "                data = load_img(path = t, grayscale = True)\n",
    "                data = tf.keras.utils.img_to_array(data, data_format=\"channels_last\", dtype=\"float32\")\n",
    "                data /= 255\n",
    "                data.shape = (1,) + data.shape\n",
    "                X = np.asarray(data)\n",
    "                print(\"----------{}----------\".format(nr))\n",
    "                euler = t.split(\"_\")\n",
    "                print(\"phi1\", float(euler[3]))\n",
    "                print(\"PHI\",   float(euler[4]))\n",
    "                print(\"phi2\",  float(euler[5][:-4]))\n",
    "                yhat = model.predict(data)\n",
    "                print(\"predicted values\", yhat*90)\n",
    "            print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "            model.save(\"TempModels/epoch{}.h5\".format(epoch), save_format = 'h5')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed4b21b",
   "metadata": {},
   "source": [
    "# Experiment section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cb55ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "############################# Experiments ############################\n",
    "######################################################################\n",
    "def conv_block(x, filters, kernel_size, regul):\n",
    "    if regul:\n",
    "        biasregul = regularizers.l2(regul)\n",
    "        kernelregul = regularizers.l2(regul)\n",
    "    else:\n",
    "        biasregul = kernelregul = None\n",
    "    x = ReflectionPadding2D(padding=((kernel_size-1),\n",
    "                                     (kernel_size-1)))(x)\n",
    "    x = layers.Conv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=\"valid\",\n",
    "            #activation=lambda x: activations.relu(x, alpha=0.1),\n",
    "            kernel_initializer='RandomNormal',\n",
    "            bias_initializer=initializers.Constant(0.1),\n",
    "            kernel_regularizer=kernelregul,\n",
    "            bias_regularizer=biasregul\n",
    "            )(x)\n",
    "    x = layers.PReLU(\n",
    "            shared_axes=[1,2],\n",
    "            alpha_initializer=tf.initializers.Constant(0.01),\n",
    "            )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    #x = layers.Activation(\"relu\")(x)\n",
    "    #x = layers.Dropout(rate=0.5)(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e309dfa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 500, 500, 1)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 498, 498, 32)      320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 496, 496, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 124, 124, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 122, 122, 32)      9248      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 120, 120, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 30, 30, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 26, 26, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1152)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               147584    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                2064      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 196,259\n",
      "Trainable params: 196,259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "######################################################################    \n",
    "######################## Loading the model ###########################    \n",
    "###################################################################### \n",
    "inputs = keras.Input(shape=(input_size, input_size, 1))\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=4)(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=4)(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=4)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(3)(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce477929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.2801 - smart_square_abs_min_loss: 0.2801 - accuracy: 0.2932+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 266ms/step - loss: 0.2579 - smart_square_abs_min_loss: 0.2579 - accuracy: 0.4012\n",
      "Loss on test data:  0.2578640580177307\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/utils/image_utils.py:409: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 226ms/step\n",
      "predicted values [[ 4.7328153  2.8319077 13.617306 ]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[ 3.2477434  1.4213505 11.37334  ]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[ 5.42036   3.300544 13.797027]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 84s 304ms/step - loss: 0.2801 - smart_square_abs_min_loss: 0.2801 - accuracy: 0.2932 - val_loss: 0.2569 - val_smart_square_abs_min_loss: 0.2569 - val_accuracy: 0.2923\n",
      "Epoch 2/300\n",
      "273/273 [==============================] - 75s 274ms/step - loss: 0.3010 - smart_square_abs_min_loss: 0.3010 - accuracy: 0.2475 - val_loss: 0.4693 - val_smart_square_abs_min_loss: 0.4693 - val_accuracy: 0.3478\n",
      "Epoch 3/300\n",
      "273/273 [==============================] - 72s 264ms/step - loss: 0.2572 - smart_square_abs_min_loss: 0.2572 - accuracy: 0.3067 - val_loss: 0.2576 - val_smart_square_abs_min_loss: 0.2576 - val_accuracy: 0.3619\n",
      "Epoch 4/300\n",
      "273/273 [==============================] - 74s 270ms/step - loss: 0.2282 - smart_square_abs_min_loss: 0.2282 - accuracy: 0.4084 - val_loss: 0.3249 - val_smart_square_abs_min_loss: 0.3249 - val_accuracy: 0.3206\n",
      "Epoch 5/300\n",
      "273/273 [==============================] - 78s 285ms/step - loss: 0.2445 - smart_square_abs_min_loss: 0.2445 - accuracy: 0.3438 - val_loss: 0.2994 - val_smart_square_abs_min_loss: 0.2994 - val_accuracy: 0.3337\n",
      "Epoch 6/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.2353 - smart_square_abs_min_loss: 0.2353 - accuracy: 0.4013+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 274ms/step - loss: 0.2889 - smart_square_abs_min_loss: 0.2889 - accuracy: 0.2278\n",
      "Loss on test data:  0.28886479139328003\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[56.70788  33.555153  9.082936]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[49.320244 12.055392 11.054396]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[ 5.0963955 30.494715  43.652145 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 90s 331ms/step - loss: 0.2353 - smart_square_abs_min_loss: 0.2353 - accuracy: 0.4013 - val_loss: 0.3049 - val_smart_square_abs_min_loss: 0.3049 - val_accuracy: 0.4950\n",
      "Epoch 7/300\n",
      "273/273 [==============================] - 72s 262ms/step - loss: 0.2271 - smart_square_abs_min_loss: 0.2271 - accuracy: 0.4423 - val_loss: 0.2984 - val_smart_square_abs_min_loss: 0.2984 - val_accuracy: 0.3347\n",
      "Epoch 8/300\n",
      "273/273 [==============================] - 70s 254ms/step - loss: 0.2128 - smart_square_abs_min_loss: 0.2128 - accuracy: 0.3777 - val_loss: 0.2272 - val_smart_square_abs_min_loss: 0.2272 - val_accuracy: 0.3256\n",
      "Epoch 9/300\n",
      "273/273 [==============================] - 75s 276ms/step - loss: 0.1973 - smart_square_abs_min_loss: 0.1973 - accuracy: 0.4524 - val_loss: 0.2494 - val_smart_square_abs_min_loss: 0.2494 - val_accuracy: 0.3226\n",
      "Epoch 10/300\n",
      "273/273 [==============================] - 80s 294ms/step - loss: 0.1842 - smart_square_abs_min_loss: 0.1842 - accuracy: 0.4733 - val_loss: 0.2774 - val_smart_square_abs_min_loss: 0.2774 - val_accuracy: 0.2661\n",
      "Epoch 11/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.2002 - smart_square_abs_min_loss: 0.2002 - accuracy: 0.4410+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 271ms/step - loss: 0.2502 - smart_square_abs_min_loss: 0.2502 - accuracy: 0.4133\n",
      "Loss on test data:  0.2501865029335022\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[72.967964  6.401289 20.533768]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[51.01298    7.4122014 29.261374 ]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[ 7.8575454 46.356403  59.40895  ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 80s 294ms/step - loss: 0.2002 - smart_square_abs_min_loss: 0.2002 - accuracy: 0.4410 - val_loss: 0.2396 - val_smart_square_abs_min_loss: 0.2396 - val_accuracy: 0.3881\n",
      "Epoch 12/300\n",
      "273/273 [==============================] - 70s 258ms/step - loss: 0.2043 - smart_square_abs_min_loss: 0.2043 - accuracy: 0.4793 - val_loss: 0.2453 - val_smart_square_abs_min_loss: 0.2453 - val_accuracy: 0.3720\n",
      "Epoch 13/300\n",
      "273/273 [==============================] - 74s 269ms/step - loss: 0.1882 - smart_square_abs_min_loss: 0.1882 - accuracy: 0.4953 - val_loss: 0.2313 - val_smart_square_abs_min_loss: 0.2313 - val_accuracy: 0.4667\n",
      "Epoch 14/300\n",
      "273/273 [==============================] - 73s 267ms/step - loss: 0.1867 - smart_square_abs_min_loss: 0.1867 - accuracy: 0.5001 - val_loss: 0.2397 - val_smart_square_abs_min_loss: 0.2397 - val_accuracy: 0.3478\n",
      "Epoch 15/300\n",
      "273/273 [==============================] - 71s 260ms/step - loss: 0.1799 - smart_square_abs_min_loss: 0.1799 - accuracy: 0.4932 - val_loss: 0.2376 - val_smart_square_abs_min_loss: 0.2376 - val_accuracy: 0.3619\n",
      "Epoch 16/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.1629 - smart_square_abs_min_loss: 0.1629 - accuracy: 0.5248+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 240ms/step - loss: 0.2113 - smart_square_abs_min_loss: 0.2113 - accuracy: 0.3750\n",
      "Loss on test data:  0.2113141417503357\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[49.693775 41.37691  18.316397]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[23.581663  5.880193 69.533005]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "predicted values [[31.262114 61.40036  17.343473]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 75s 276ms/step - loss: 0.1629 - smart_square_abs_min_loss: 0.1629 - accuracy: 0.5248 - val_loss: 0.2703 - val_smart_square_abs_min_loss: 0.2703 - val_accuracy: 0.3417\n",
      "Epoch 17/300\n",
      "273/273 [==============================] - 81s 298ms/step - loss: 0.1586 - smart_square_abs_min_loss: 0.1586 - accuracy: 0.5584 - val_loss: 0.2227 - val_smart_square_abs_min_loss: 0.2227 - val_accuracy: 0.4385\n",
      "Epoch 18/300\n",
      "273/273 [==============================] - 85s 313ms/step - loss: 0.1515 - smart_square_abs_min_loss: 0.1515 - accuracy: 0.5588 - val_loss: 0.1994 - val_smart_square_abs_min_loss: 0.1994 - val_accuracy: 0.3589\n",
      "Epoch 19/300\n",
      "273/273 [==============================] - 79s 289ms/step - loss: 0.1606 - smart_square_abs_min_loss: 0.1606 - accuracy: 0.5341 - val_loss: 0.3461 - val_smart_square_abs_min_loss: 0.3461 - val_accuracy: 0.4194\n",
      "Epoch 20/300\n",
      "273/273 [==============================] - 82s 301ms/step - loss: 0.1526 - smart_square_abs_min_loss: 0.1526 - accuracy: 0.5651 - val_loss: 0.2027 - val_smart_square_abs_min_loss: 0.2027 - val_accuracy: 0.5464\n",
      "Epoch 21/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.1450 - smart_square_abs_min_loss: 0.1450 - accuracy: 0.5967+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 254ms/step - loss: 0.1921 - smart_square_abs_min_loss: 0.1921 - accuracy: 0.3730\n",
      "Loss on test data:  0.19210627675056458\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[88.837845 47.622837 60.56981 ]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[29.470768 39.79611  45.99025 ]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[42.287796 50.36097  31.139322]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 91s 332ms/step - loss: 0.1450 - smart_square_abs_min_loss: 0.1450 - accuracy: 0.5967 - val_loss: 0.2151 - val_smart_square_abs_min_loss: 0.2151 - val_accuracy: 0.4466\n",
      "Epoch 22/300\n",
      "273/273 [==============================] - 84s 309ms/step - loss: 0.1552 - smart_square_abs_min_loss: 0.1552 - accuracy: 0.5695 - val_loss: 0.1856 - val_smart_square_abs_min_loss: 0.1856 - val_accuracy: 0.4294\n",
      "Epoch 23/300\n",
      "273/273 [==============================] - 79s 291ms/step - loss: 0.1465 - smart_square_abs_min_loss: 0.1465 - accuracy: 0.6083 - val_loss: 0.1578 - val_smart_square_abs_min_loss: 0.1578 - val_accuracy: 0.5444\n",
      "Epoch 24/300\n",
      "273/273 [==============================] - 76s 277ms/step - loss: 0.1497 - smart_square_abs_min_loss: 0.1497 - accuracy: 0.5686 - val_loss: 0.1950 - val_smart_square_abs_min_loss: 0.1950 - val_accuracy: 0.4597\n",
      "Epoch 25/300\n",
      "273/273 [==============================] - 81s 297ms/step - loss: 0.1413 - smart_square_abs_min_loss: 0.1413 - accuracy: 0.5828 - val_loss: 0.1689 - val_smart_square_abs_min_loss: 0.1689 - val_accuracy: 0.4778\n",
      "Epoch 26/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.1408 - smart_square_abs_min_loss: 0.1408 - accuracy: 0.6033+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 274ms/step - loss: 0.1775 - smart_square_abs_min_loss: 0.1775 - accuracy: 0.5151\n",
      "Loss on test data:  0.1775234043598175\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[75.3716   52.09355  28.983644]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "predicted values [[37.68202 36.7694  22.12283]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[11.974503 51.479004 48.11192 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 91s 334ms/step - loss: 0.1408 - smart_square_abs_min_loss: 0.1408 - accuracy: 0.6033 - val_loss: 0.2279 - val_smart_square_abs_min_loss: 0.2279 - val_accuracy: 0.5484\n",
      "Epoch 27/300\n",
      "273/273 [==============================] - 78s 287ms/step - loss: 0.1331 - smart_square_abs_min_loss: 0.1331 - accuracy: 0.6190 - val_loss: 0.2258 - val_smart_square_abs_min_loss: 0.2258 - val_accuracy: 0.6482\n",
      "Epoch 28/300\n",
      "273/273 [==============================] - 79s 288ms/step - loss: 0.1249 - smart_square_abs_min_loss: 0.1249 - accuracy: 0.6276 - val_loss: 0.1596 - val_smart_square_abs_min_loss: 0.1596 - val_accuracy: 0.5696\n",
      "Epoch 29/300\n",
      "273/273 [==============================] - 79s 290ms/step - loss: 0.1280 - smart_square_abs_min_loss: 0.1280 - accuracy: 0.6268 - val_loss: 0.1690 - val_smart_square_abs_min_loss: 0.1690 - val_accuracy: 0.5433\n",
      "Epoch 30/300\n",
      "273/273 [==============================] - 76s 280ms/step - loss: 0.1250 - smart_square_abs_min_loss: 0.1250 - accuracy: 0.6261 - val_loss: 0.1720 - val_smart_square_abs_min_loss: 0.1720 - val_accuracy: 0.6613\n",
      "Epoch 31/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.1303 - smart_square_abs_min_loss: 0.1303 - accuracy: 0.5990+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 272ms/step - loss: 0.1643 - smart_square_abs_min_loss: 0.1643 - accuracy: 0.5534\n",
      "Loss on test data:  0.1643451750278473\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[77.12239 50.8602  31.95104]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[39.063988 43.41136  20.35645 ]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[27.656761 63.348064 49.97701 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 94s 342ms/step - loss: 0.1303 - smart_square_abs_min_loss: 0.1303 - accuracy: 0.5990 - val_loss: 0.1696 - val_smart_square_abs_min_loss: 0.1696 - val_accuracy: 0.4365\n",
      "Epoch 32/300\n",
      "273/273 [==============================] - 77s 281ms/step - loss: 0.1224 - smart_square_abs_min_loss: 0.1224 - accuracy: 0.6489 - val_loss: 0.1692 - val_smart_square_abs_min_loss: 0.1692 - val_accuracy: 0.4577\n",
      "Epoch 33/300\n",
      "273/273 [==============================] - 81s 295ms/step - loss: 0.1365 - smart_square_abs_min_loss: 0.1365 - accuracy: 0.6208 - val_loss: 0.2334 - val_smart_square_abs_min_loss: 0.2334 - val_accuracy: 0.5625\n",
      "Epoch 34/300\n",
      "273/273 [==============================] - 84s 309ms/step - loss: 0.1244 - smart_square_abs_min_loss: 0.1244 - accuracy: 0.6134 - val_loss: 0.1917 - val_smart_square_abs_min_loss: 0.1917 - val_accuracy: 0.5030\n",
      "Epoch 35/300\n",
      "273/273 [==============================] - 78s 284ms/step - loss: 0.1171 - smart_square_abs_min_loss: 0.1171 - accuracy: 0.6748 - val_loss: 0.1562 - val_smart_square_abs_min_loss: 0.1562 - val_accuracy: 0.4899\n",
      "Epoch 36/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.1143 - smart_square_abs_min_loss: 0.1143 - accuracy: 0.6660+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 256ms/step - loss: 0.1794 - smart_square_abs_min_loss: 0.1794 - accuracy: 0.5121\n",
      "Loss on test data:  0.17943094670772552\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[59.195625 38.641136 23.601294]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[31.844322 34.460793 16.035114]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "predicted values [[26.039314 55.187904 44.983585]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 89s 324ms/step - loss: 0.1143 - smart_square_abs_min_loss: 0.1143 - accuracy: 0.6660 - val_loss: 0.1344 - val_smart_square_abs_min_loss: 0.1344 - val_accuracy: 0.6058\n",
      "Epoch 37/300\n",
      "273/273 [==============================] - 76s 277ms/step - loss: 0.1222 - smart_square_abs_min_loss: 0.1222 - accuracy: 0.6424 - val_loss: 0.1357 - val_smart_square_abs_min_loss: 0.1357 - val_accuracy: 0.6139\n",
      "Epoch 38/300\n",
      "273/273 [==============================] - 82s 301ms/step - loss: 0.1070 - smart_square_abs_min_loss: 0.1070 - accuracy: 0.6272 - val_loss: 0.1464 - val_smart_square_abs_min_loss: 0.1464 - val_accuracy: 0.5131\n",
      "Epoch 39/300\n",
      "273/273 [==============================] - 79s 291ms/step - loss: 0.1257 - smart_square_abs_min_loss: 0.1257 - accuracy: 0.6391 - val_loss: 0.1496 - val_smart_square_abs_min_loss: 0.1496 - val_accuracy: 0.5766\n",
      "Epoch 40/300\n",
      "273/273 [==============================] - 80s 293ms/step - loss: 0.1284 - smart_square_abs_min_loss: 0.1284 - accuracy: 0.6237 - val_loss: 0.1838 - val_smart_square_abs_min_loss: 0.1838 - val_accuracy: 0.3760\n",
      "Epoch 41/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.1238 - smart_square_abs_min_loss: 0.1238 - accuracy: 0.6377+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 245ms/step - loss: 0.1594 - smart_square_abs_min_loss: 0.1594 - accuracy: 0.5867\n",
      "Loss on test data:  0.1593550741672516\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[57.051266 43.107334 21.935553]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "predicted values [[17.958384 36.080086  9.740531]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "predicted values [[17.469538 60.936893 46.06784 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 87s 320ms/step - loss: 0.1238 - smart_square_abs_min_loss: 0.1238 - accuracy: 0.6377 - val_loss: 0.1685 - val_smart_square_abs_min_loss: 0.1685 - val_accuracy: 0.6200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/300\n",
      "273/273 [==============================] - 79s 290ms/step - loss: 0.1059 - smart_square_abs_min_loss: 0.1059 - accuracy: 0.6830 - val_loss: 0.1477 - val_smart_square_abs_min_loss: 0.1477 - val_accuracy: 0.4970\n",
      "Epoch 43/300\n",
      "273/273 [==============================] - 70s 257ms/step - loss: 0.1159 - smart_square_abs_min_loss: 0.1159 - accuracy: 0.6376 - val_loss: 0.1449 - val_smart_square_abs_min_loss: 0.1449 - val_accuracy: 0.5998\n",
      "Epoch 44/300\n",
      "273/273 [==============================] - 79s 291ms/step - loss: 0.1070 - smart_square_abs_min_loss: 0.1070 - accuracy: 0.6621 - val_loss: 0.1400 - val_smart_square_abs_min_loss: 0.1400 - val_accuracy: 0.4708\n",
      "Epoch 45/300\n",
      "273/273 [==============================] - 77s 282ms/step - loss: 0.1257 - smart_square_abs_min_loss: 0.1257 - accuracy: 0.6385 - val_loss: 0.1643 - val_smart_square_abs_min_loss: 0.1643 - val_accuracy: 0.5192\n",
      "Epoch 46/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0976 - smart_square_abs_min_loss: 0.0976 - accuracy: 0.6986+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 265ms/step - loss: 0.1376 - smart_square_abs_min_loss: 0.1376 - accuracy: 0.4506\n",
      "Loss on test data:  0.13756750524044037\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "predicted values [[60.313118 41.976704 23.97448 ]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "predicted values [[30.352255 39.171295 15.926053]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[12.778972 61.20737  51.73883 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 90s 328ms/step - loss: 0.0976 - smart_square_abs_min_loss: 0.0976 - accuracy: 0.6986 - val_loss: 0.1892 - val_smart_square_abs_min_loss: 0.1892 - val_accuracy: 0.5524\n",
      "Epoch 47/300\n",
      "273/273 [==============================] - 81s 296ms/step - loss: 0.0999 - smart_square_abs_min_loss: 0.0999 - accuracy: 0.6943 - val_loss: 0.1417 - val_smart_square_abs_min_loss: 0.1417 - val_accuracy: 0.6079\n",
      "Epoch 48/300\n",
      "273/273 [==============================] - 79s 289ms/step - loss: 0.1124 - smart_square_abs_min_loss: 0.1124 - accuracy: 0.6439 - val_loss: 0.2014 - val_smart_square_abs_min_loss: 0.2014 - val_accuracy: 0.6381\n",
      "Epoch 49/300\n",
      "273/273 [==============================] - 85s 310ms/step - loss: 0.0997 - smart_square_abs_min_loss: 0.0997 - accuracy: 0.6981 - val_loss: 0.1365 - val_smart_square_abs_min_loss: 0.1365 - val_accuracy: 0.6966\n",
      "Epoch 50/300\n",
      "273/273 [==============================] - 83s 302ms/step - loss: 0.1173 - smart_square_abs_min_loss: 0.1173 - accuracy: 0.6496 - val_loss: 0.1782 - val_smart_square_abs_min_loss: 0.1782 - val_accuracy: 0.5212\n",
      "Epoch 51/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0937 - smart_square_abs_min_loss: 0.0937 - accuracy: 0.6923+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 263ms/step - loss: 0.1280 - smart_square_abs_min_loss: 0.1280 - accuracy: 0.6109\n",
      "Loss on test data:  0.12796345353126526\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[64.77377  36.851025 27.086811]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[34.039307  36.773422   7.8269563]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "predicted values [[17.564661 53.925453 45.41236 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 88s 324ms/step - loss: 0.0937 - smart_square_abs_min_loss: 0.0937 - accuracy: 0.6923 - val_loss: 0.1699 - val_smart_square_abs_min_loss: 0.1699 - val_accuracy: 0.4395\n",
      "Epoch 52/300\n",
      "273/273 [==============================] - 82s 301ms/step - loss: 0.0964 - smart_square_abs_min_loss: 0.0964 - accuracy: 0.7004 - val_loss: 0.1331 - val_smart_square_abs_min_loss: 0.1331 - val_accuracy: 0.4909\n",
      "Epoch 53/300\n",
      "273/273 [==============================] - 75s 274ms/step - loss: 0.1042 - smart_square_abs_min_loss: 0.1042 - accuracy: 0.6774 - val_loss: 0.1639 - val_smart_square_abs_min_loss: 0.1639 - val_accuracy: 0.6421\n",
      "Epoch 54/300\n",
      "273/273 [==============================] - 83s 302ms/step - loss: 0.1224 - smart_square_abs_min_loss: 0.1224 - accuracy: 0.6212 - val_loss: 0.1122 - val_smart_square_abs_min_loss: 0.1122 - val_accuracy: 0.6502\n",
      "Epoch 55/300\n",
      "273/273 [==============================] - 78s 286ms/step - loss: 0.1062 - smart_square_abs_min_loss: 0.1062 - accuracy: 0.6898 - val_loss: 0.1156 - val_smart_square_abs_min_loss: 0.1156 - val_accuracy: 0.7379\n",
      "Epoch 56/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0927 - smart_square_abs_min_loss: 0.0927 - accuracy: 0.7224+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 280ms/step - loss: 0.1183 - smart_square_abs_min_loss: 0.1183 - accuracy: 0.5262\n",
      "Loss on test data:  0.11829688400030136\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[61.942142 41.394787 18.568653]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[11.641359  33.274853   4.1863933]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[15.553111 51.658257 45.732662]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 89s 324ms/step - loss: 0.0927 - smart_square_abs_min_loss: 0.0927 - accuracy: 0.7224 - val_loss: 0.1360 - val_smart_square_abs_min_loss: 0.1360 - val_accuracy: 0.5363\n",
      "Epoch 57/300\n",
      "273/273 [==============================] - 84s 309ms/step - loss: 0.1058 - smart_square_abs_min_loss: 0.1058 - accuracy: 0.7008 - val_loss: 0.1482 - val_smart_square_abs_min_loss: 0.1482 - val_accuracy: 0.6603\n",
      "Epoch 58/300\n",
      "273/273 [==============================] - 85s 313ms/step - loss: 0.1050 - smart_square_abs_min_loss: 0.1050 - accuracy: 0.6904 - val_loss: 0.1314 - val_smart_square_abs_min_loss: 0.1314 - val_accuracy: 0.5575\n",
      "Epoch 59/300\n",
      "273/273 [==============================] - 78s 286ms/step - loss: 0.1055 - smart_square_abs_min_loss: 0.1055 - accuracy: 0.6931 - val_loss: 0.1065 - val_smart_square_abs_min_loss: 0.1065 - val_accuracy: 0.5675\n",
      "Epoch 60/300\n",
      "273/273 [==============================] - 83s 303ms/step - loss: 0.1097 - smart_square_abs_min_loss: 0.1097 - accuracy: 0.6644 - val_loss: 0.1058 - val_smart_square_abs_min_loss: 0.1058 - val_accuracy: 0.6220\n",
      "Epoch 61/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0999 - smart_square_abs_min_loss: 0.0999 - accuracy: 0.6829+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 261ms/step - loss: 0.1246 - smart_square_abs_min_loss: 0.1246 - accuracy: 0.6643\n",
      "Loss on test data:  0.12461226433515549\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[62.516113 31.128304 29.826763]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[26.320475 43.558426 12.551481]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[13.22433  55.191803 49.709976]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 93s 340ms/step - loss: 0.0999 - smart_square_abs_min_loss: 0.0999 - accuracy: 0.6829 - val_loss: 0.1559 - val_smart_square_abs_min_loss: 0.1559 - val_accuracy: 0.6109\n",
      "Epoch 62/300\n",
      "273/273 [==============================] - 79s 287ms/step - loss: 0.0857 - smart_square_abs_min_loss: 0.0857 - accuracy: 0.7150 - val_loss: 0.1140 - val_smart_square_abs_min_loss: 0.1140 - val_accuracy: 0.5968\n",
      "Epoch 63/300\n",
      "273/273 [==============================] - 86s 314ms/step - loss: 0.1107 - smart_square_abs_min_loss: 0.1107 - accuracy: 0.6560 - val_loss: 0.1104 - val_smart_square_abs_min_loss: 0.1104 - val_accuracy: 0.6613\n",
      "Epoch 64/300\n",
      "273/273 [==============================] - 79s 288ms/step - loss: 0.0930 - smart_square_abs_min_loss: 0.0930 - accuracy: 0.6809 - val_loss: 0.1435 - val_smart_square_abs_min_loss: 0.1435 - val_accuracy: 0.5121\n",
      "Epoch 65/300\n",
      "273/273 [==============================] - 78s 287ms/step - loss: 0.1035 - smart_square_abs_min_loss: 0.1035 - accuracy: 0.7103 - val_loss: 0.1290 - val_smart_square_abs_min_loss: 0.1290 - val_accuracy: 0.6522\n",
      "Epoch 66/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0922 - smart_square_abs_min_loss: 0.0922 - accuracy: 0.7174+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 258ms/step - loss: 0.1441 - smart_square_abs_min_loss: 0.1441 - accuracy: 0.7389\n",
      "Loss on test data:  0.14406144618988037\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[61.480507 32.04367  21.15044 ]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[19.014423 45.2938    5.784134]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[16.104359 56.79866  43.19025 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 89s 325ms/step - loss: 0.0922 - smart_square_abs_min_loss: 0.0922 - accuracy: 0.7174 - val_loss: 0.1201 - val_smart_square_abs_min_loss: 0.1201 - val_accuracy: 0.7540\n",
      "Epoch 67/300\n",
      "273/273 [==============================] - 86s 314ms/step - loss: 0.1081 - smart_square_abs_min_loss: 0.1081 - accuracy: 0.6680 - val_loss: 0.1038 - val_smart_square_abs_min_loss: 0.1038 - val_accuracy: 0.6603\n",
      "Epoch 68/300\n",
      "273/273 [==============================] - 80s 291ms/step - loss: 0.0933 - smart_square_abs_min_loss: 0.0933 - accuracy: 0.7099 - val_loss: 0.1157 - val_smart_square_abs_min_loss: 0.1157 - val_accuracy: 0.6714\n",
      "Epoch 69/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0936 - smart_square_abs_min_loss: 0.0936 - accuracy: 0.7173 - val_loss: 0.1420 - val_smart_square_abs_min_loss: 0.1420 - val_accuracy: 0.4950\n",
      "Epoch 70/300\n",
      "273/273 [==============================] - 86s 314ms/step - loss: 0.0980 - smart_square_abs_min_loss: 0.0980 - accuracy: 0.6769 - val_loss: 0.1233 - val_smart_square_abs_min_loss: 0.1233 - val_accuracy: 0.4960\n",
      "Epoch 71/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.1016 - smart_square_abs_min_loss: 0.1016 - accuracy: 0.6730+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 252ms/step - loss: 0.1109 - smart_square_abs_min_loss: 0.1109 - accuracy: 0.5212\n",
      "Loss on test data:  0.11088117212057114\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[56.0455   35.181885 23.100328]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[26.498692  38.283752  -1.6785861]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "predicted values [[11.866483 60.360878 43.39235 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 93s 341ms/step - loss: 0.1016 - smart_square_abs_min_loss: 0.1016 - accuracy: 0.6730 - val_loss: 0.1284 - val_smart_square_abs_min_loss: 0.1284 - val_accuracy: 0.5595\n",
      "Epoch 72/300\n",
      "273/273 [==============================] - 80s 293ms/step - loss: 0.0851 - smart_square_abs_min_loss: 0.0851 - accuracy: 0.7294 - val_loss: 0.1399 - val_smart_square_abs_min_loss: 0.1399 - val_accuracy: 0.7389\n",
      "Epoch 73/300\n",
      "273/273 [==============================] - 79s 289ms/step - loss: 0.0891 - smart_square_abs_min_loss: 0.0891 - accuracy: 0.7126 - val_loss: 0.0984 - val_smart_square_abs_min_loss: 0.0984 - val_accuracy: 0.5474\n",
      "Epoch 74/300\n",
      "273/273 [==============================] - 80s 293ms/step - loss: 0.0954 - smart_square_abs_min_loss: 0.0954 - accuracy: 0.6896 - val_loss: 0.1214 - val_smart_square_abs_min_loss: 0.1214 - val_accuracy: 0.5907\n",
      "Epoch 75/300\n",
      "273/273 [==============================] - 79s 289ms/step - loss: 0.0923 - smart_square_abs_min_loss: 0.0923 - accuracy: 0.6769 - val_loss: 0.1268 - val_smart_square_abs_min_loss: 0.1268 - val_accuracy: 0.6179\n",
      "Epoch 76/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0839 - smart_square_abs_min_loss: 0.0839 - accuracy: 0.7334+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 261ms/step - loss: 0.1604 - smart_square_abs_min_loss: 0.1604 - accuracy: 0.6613\n",
      "Loss on test data:  0.16038788855075836\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[63.625732 43.910877 28.60872 ]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[25.674906  30.999352   3.5662987]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[12.167509 60.70465  52.771557]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 94s 344ms/step - loss: 0.0839 - smart_square_abs_min_loss: 0.0839 - accuracy: 0.7334 - val_loss: 0.1415 - val_smart_square_abs_min_loss: 0.1415 - val_accuracy: 0.6310\n",
      "Epoch 77/300\n",
      "273/273 [==============================] - 78s 284ms/step - loss: 0.0967 - smart_square_abs_min_loss: 0.0967 - accuracy: 0.6932 - val_loss: 0.1765 - val_smart_square_abs_min_loss: 0.1765 - val_accuracy: 0.5554\n",
      "Epoch 78/300\n",
      "273/273 [==============================] - 85s 310ms/step - loss: 0.1012 - smart_square_abs_min_loss: 0.1012 - accuracy: 0.7042 - val_loss: 0.1308 - val_smart_square_abs_min_loss: 0.1308 - val_accuracy: 0.6583\n",
      "Epoch 79/300\n",
      "273/273 [==============================] - 80s 293ms/step - loss: 0.0890 - smart_square_abs_min_loss: 0.0890 - accuracy: 0.7098 - val_loss: 0.0999 - val_smart_square_abs_min_loss: 0.0999 - val_accuracy: 0.6653\n",
      "Epoch 80/300\n",
      "273/273 [==============================] - 78s 287ms/step - loss: 0.0888 - smart_square_abs_min_loss: 0.0888 - accuracy: 0.7123 - val_loss: 0.0893 - val_smart_square_abs_min_loss: 0.0893 - val_accuracy: 0.7450\n",
      "Epoch 81/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0810 - smart_square_abs_min_loss: 0.0810 - accuracy: 0.7420+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 278ms/step - loss: 0.1143 - smart_square_abs_min_loss: 0.1143 - accuracy: 0.6845\n",
      "Loss on test data:  0.11433404684066772\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[63.235043 32.940018 26.869469]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[26.450094 29.193739 12.581255]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[16.882317 59.852207 52.46984 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 88s 323ms/step - loss: 0.0810 - smart_square_abs_min_loss: 0.0810 - accuracy: 0.7420 - val_loss: 0.1192 - val_smart_square_abs_min_loss: 0.1192 - val_accuracy: 0.7540\n",
      "Epoch 82/300\n",
      "273/273 [==============================] - 78s 284ms/step - loss: 0.0886 - smart_square_abs_min_loss: 0.0886 - accuracy: 0.6851 - val_loss: 0.1516 - val_smart_square_abs_min_loss: 0.1516 - val_accuracy: 0.5736\n",
      "Epoch 83/300\n",
      "273/273 [==============================] - 84s 309ms/step - loss: 0.0922 - smart_square_abs_min_loss: 0.0922 - accuracy: 0.7355 - val_loss: 0.1024 - val_smart_square_abs_min_loss: 0.1024 - val_accuracy: 0.5121\n",
      "Epoch 84/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273/273 [==============================] - 83s 305ms/step - loss: 0.1054 - smart_square_abs_min_loss: 0.1054 - accuracy: 0.6821 - val_loss: 0.0985 - val_smart_square_abs_min_loss: 0.0985 - val_accuracy: 0.7843\n",
      "Epoch 85/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0877 - smart_square_abs_min_loss: 0.0877 - accuracy: 0.7389 - val_loss: 0.0920 - val_smart_square_abs_min_loss: 0.0920 - val_accuracy: 0.6825\n",
      "Epoch 86/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0850 - smart_square_abs_min_loss: 0.0850 - accuracy: 0.7247+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 285ms/step - loss: 0.1144 - smart_square_abs_min_loss: 0.1144 - accuracy: 0.5968\n",
      "Loss on test data:  0.11437555402517319\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[57.76423  35.45217  32.249584]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[13.31535  24.910303 15.957618]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[12.3326   59.938236 52.27193 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 89s 325ms/step - loss: 0.0850 - smart_square_abs_min_loss: 0.0850 - accuracy: 0.7247 - val_loss: 0.1412 - val_smart_square_abs_min_loss: 0.1412 - val_accuracy: 0.7006\n",
      "Epoch 87/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0859 - smart_square_abs_min_loss: 0.0859 - accuracy: 0.6916 - val_loss: 0.1071 - val_smart_square_abs_min_loss: 0.1071 - val_accuracy: 0.7419\n",
      "Epoch 88/300\n",
      "273/273 [==============================] - 84s 307ms/step - loss: 0.0945 - smart_square_abs_min_loss: 0.0945 - accuracy: 0.6912 - val_loss: 0.1290 - val_smart_square_abs_min_loss: 0.1290 - val_accuracy: 0.7238\n",
      "Epoch 89/300\n",
      "273/273 [==============================] - 84s 309ms/step - loss: 0.0852 - smart_square_abs_min_loss: 0.0852 - accuracy: 0.7286 - val_loss: 0.0688 - val_smart_square_abs_min_loss: 0.0688 - val_accuracy: 0.6179\n",
      "Epoch 90/300\n",
      "273/273 [==============================] - 85s 312ms/step - loss: 0.0813 - smart_square_abs_min_loss: 0.0813 - accuracy: 0.7284 - val_loss: 0.0974 - val_smart_square_abs_min_loss: 0.0974 - val_accuracy: 0.7591\n",
      "Epoch 91/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0970 - smart_square_abs_min_loss: 0.0970 - accuracy: 0.6645+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 281ms/step - loss: 0.1343 - smart_square_abs_min_loss: 0.1343 - accuracy: 0.6290\n",
      "Loss on test data:  0.13426737487316132\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[56.572437 36.817394 33.589165]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[25.576258 33.228252 10.722061]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[ 7.47566  62.330902 52.57235 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 94s 343ms/step - loss: 0.0970 - smart_square_abs_min_loss: 0.0970 - accuracy: 0.6645 - val_loss: 0.1038 - val_smart_square_abs_min_loss: 0.1038 - val_accuracy: 0.6149\n",
      "Epoch 92/300\n",
      "273/273 [==============================] - 84s 309ms/step - loss: 0.0877 - smart_square_abs_min_loss: 0.0877 - accuracy: 0.6883 - val_loss: 0.0840 - val_smart_square_abs_min_loss: 0.0840 - val_accuracy: 0.6815\n",
      "Epoch 93/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0942 - smart_square_abs_min_loss: 0.0942 - accuracy: 0.6822 - val_loss: 0.1131 - val_smart_square_abs_min_loss: 0.1131 - val_accuracy: 0.8034\n",
      "Epoch 94/300\n",
      "273/273 [==============================] - 85s 310ms/step - loss: 0.0908 - smart_square_abs_min_loss: 0.0908 - accuracy: 0.6928 - val_loss: 0.0838 - val_smart_square_abs_min_loss: 0.0838 - val_accuracy: 0.5887\n",
      "Epoch 95/300\n",
      "273/273 [==============================] - 85s 310ms/step - loss: 0.0895 - smart_square_abs_min_loss: 0.0895 - accuracy: 0.7119 - val_loss: 0.1147 - val_smart_square_abs_min_loss: 0.1147 - val_accuracy: 0.6089\n",
      "Epoch 96/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0726 - smart_square_abs_min_loss: 0.0726 - accuracy: 0.7671+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 277ms/step - loss: 0.1085 - smart_square_abs_min_loss: 0.1085 - accuracy: 0.5111\n",
      "Loss on test data:  0.10846971720457077\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[53.999947 35.731453 25.784986]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "predicted values [[15.379268 34.944195  8.364706]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[13.53295  61.916885 52.564285]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 95s 347ms/step - loss: 0.0726 - smart_square_abs_min_loss: 0.0726 - accuracy: 0.7671 - val_loss: 0.1104 - val_smart_square_abs_min_loss: 0.1104 - val_accuracy: 0.6129\n",
      "Epoch 97/300\n",
      "273/273 [==============================] - 84s 309ms/step - loss: 0.0835 - smart_square_abs_min_loss: 0.0835 - accuracy: 0.7372 - val_loss: 0.1213 - val_smart_square_abs_min_loss: 0.1213 - val_accuracy: 0.5917\n",
      "Epoch 98/300\n",
      "273/273 [==============================] - 84s 307ms/step - loss: 0.0859 - smart_square_abs_min_loss: 0.0859 - accuracy: 0.7353 - val_loss: 0.1233 - val_smart_square_abs_min_loss: 0.1233 - val_accuracy: 0.6885\n",
      "Epoch 99/300\n",
      "273/273 [==============================] - 86s 313ms/step - loss: 0.0836 - smart_square_abs_min_loss: 0.0836 - accuracy: 0.7308 - val_loss: 0.1074 - val_smart_square_abs_min_loss: 0.1074 - val_accuracy: 0.5252\n",
      "Epoch 100/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0755 - smart_square_abs_min_loss: 0.0755 - accuracy: 0.7402 - val_loss: 0.1007 - val_smart_square_abs_min_loss: 0.1007 - val_accuracy: 0.5181\n",
      "Epoch 101/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0922 - smart_square_abs_min_loss: 0.0922 - accuracy: 0.6992+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 270ms/step - loss: 0.1271 - smart_square_abs_min_loss: 0.1271 - accuracy: 0.7188\n",
      "Loss on test data:  0.1270534098148346\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[54.32731  38.040226 22.894438]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[14.121872  32.989605   3.2537053]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[ 8.931437 62.651085 51.251415]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 94s 343ms/step - loss: 0.0922 - smart_square_abs_min_loss: 0.0922 - accuracy: 0.6992 - val_loss: 0.1288 - val_smart_square_abs_min_loss: 0.1288 - val_accuracy: 0.6421\n",
      "Epoch 102/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0931 - smart_square_abs_min_loss: 0.0931 - accuracy: 0.6811 - val_loss: 0.1180 - val_smart_square_abs_min_loss: 0.1180 - val_accuracy: 0.6371\n",
      "Epoch 103/300\n",
      "273/273 [==============================] - 85s 310ms/step - loss: 0.0795 - smart_square_abs_min_loss: 0.0795 - accuracy: 0.7448 - val_loss: 0.1213 - val_smart_square_abs_min_loss: 0.1213 - val_accuracy: 0.6935\n",
      "Epoch 104/300\n",
      "273/273 [==============================] - 83s 304ms/step - loss: 0.0911 - smart_square_abs_min_loss: 0.0911 - accuracy: 0.7230 - val_loss: 0.1107 - val_smart_square_abs_min_loss: 0.1107 - val_accuracy: 0.5958\n",
      "Epoch 105/300\n",
      "273/273 [==============================] - 84s 309ms/step - loss: 0.0857 - smart_square_abs_min_loss: 0.0857 - accuracy: 0.7086 - val_loss: 0.0781 - val_smart_square_abs_min_loss: 0.0781 - val_accuracy: 0.6946\n",
      "Epoch 106/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.1024 - smart_square_abs_min_loss: 0.1024 - accuracy: 0.6560+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 271ms/step - loss: 0.0807 - smart_square_abs_min_loss: 0.0807 - accuracy: 0.6835\n",
      "Loss on test data:  0.08067329227924347\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[58.404182 32.67841  27.920341]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[10.698951  29.378975   3.5056298]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[15.734714 61.61633  52.550404]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 93s 342ms/step - loss: 0.1024 - smart_square_abs_min_loss: 0.1024 - accuracy: 0.6560 - val_loss: 0.1683 - val_smart_square_abs_min_loss: 0.1683 - val_accuracy: 0.5877\n",
      "Epoch 107/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0883 - smart_square_abs_min_loss: 0.0883 - accuracy: 0.7288 - val_loss: 0.1157 - val_smart_square_abs_min_loss: 0.1157 - val_accuracy: 0.6784\n",
      "Epoch 108/300\n",
      "273/273 [==============================] - 84s 309ms/step - loss: 0.0802 - smart_square_abs_min_loss: 0.0802 - accuracy: 0.7394 - val_loss: 0.1127 - val_smart_square_abs_min_loss: 0.1127 - val_accuracy: 0.7248\n",
      "Epoch 109/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0941 - smart_square_abs_min_loss: 0.0941 - accuracy: 0.7004 - val_loss: 0.0879 - val_smart_square_abs_min_loss: 0.0879 - val_accuracy: 0.5988\n",
      "Epoch 110/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0815 - smart_square_abs_min_loss: 0.0815 - accuracy: 0.7303 - val_loss: 0.0817 - val_smart_square_abs_min_loss: 0.0817 - val_accuracy: 0.7571\n",
      "Epoch 111/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0825 - smart_square_abs_min_loss: 0.0825 - accuracy: 0.7376+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 281ms/step - loss: 0.1197 - smart_square_abs_min_loss: 0.1197 - accuracy: 0.5867\n",
      "Loss on test data:  0.11965936422348022\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[55.687016 32.579437 24.773495]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[19.526705  29.873291   6.7013283]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[13.559896 64.776924 47.8818  ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 92s 338ms/step - loss: 0.0825 - smart_square_abs_min_loss: 0.0825 - accuracy: 0.7376 - val_loss: 0.0988 - val_smart_square_abs_min_loss: 0.0988 - val_accuracy: 0.6683\n",
      "Epoch 112/300\n",
      "273/273 [==============================] - 83s 302ms/step - loss: 0.0960 - smart_square_abs_min_loss: 0.0960 - accuracy: 0.7091 - val_loss: 0.0822 - val_smart_square_abs_min_loss: 0.0822 - val_accuracy: 0.6149\n",
      "Epoch 113/300\n",
      "273/273 [==============================] - 85s 313ms/step - loss: 0.0720 - smart_square_abs_min_loss: 0.0720 - accuracy: 0.7426 - val_loss: 0.0794 - val_smart_square_abs_min_loss: 0.0794 - val_accuracy: 0.7450\n",
      "Epoch 114/300\n",
      "273/273 [==============================] - 85s 309ms/step - loss: 0.0849 - smart_square_abs_min_loss: 0.0849 - accuracy: 0.7289 - val_loss: 0.1319 - val_smart_square_abs_min_loss: 0.1319 - val_accuracy: 0.5837\n",
      "Epoch 115/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0812 - smart_square_abs_min_loss: 0.0812 - accuracy: 0.7285 - val_loss: 0.1318 - val_smart_square_abs_min_loss: 0.1318 - val_accuracy: 0.6542\n",
      "Epoch 116/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0826 - smart_square_abs_min_loss: 0.0826 - accuracy: 0.7084+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 273ms/step - loss: 0.1119 - smart_square_abs_min_loss: 0.1119 - accuracy: 0.6583\n",
      "Loss on test data:  0.11188255995512009\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[56.083923 37.66715  28.888306]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[19.512108  37.949368   1.8609394]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[15.380606 60.211098 43.282593]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 94s 346ms/step - loss: 0.0826 - smart_square_abs_min_loss: 0.0826 - accuracy: 0.7084 - val_loss: 0.1215 - val_smart_square_abs_min_loss: 0.1215 - val_accuracy: 0.6048\n",
      "Epoch 117/300\n",
      "273/273 [==============================] - 84s 306ms/step - loss: 0.0794 - smart_square_abs_min_loss: 0.0794 - accuracy: 0.7242 - val_loss: 0.0889 - val_smart_square_abs_min_loss: 0.0889 - val_accuracy: 0.6512\n",
      "Epoch 118/300\n",
      "273/273 [==============================] - 84s 306ms/step - loss: 0.0812 - smart_square_abs_min_loss: 0.0812 - accuracy: 0.7577 - val_loss: 0.0855 - val_smart_square_abs_min_loss: 0.0855 - val_accuracy: 0.7308\n",
      "Epoch 119/300\n",
      "273/273 [==============================] - 85s 313ms/step - loss: 0.0833 - smart_square_abs_min_loss: 0.0833 - accuracy: 0.7137 - val_loss: 0.0826 - val_smart_square_abs_min_loss: 0.0826 - val_accuracy: 0.6865\n",
      "Epoch 120/300\n",
      "273/273 [==============================] - 85s 312ms/step - loss: 0.0898 - smart_square_abs_min_loss: 0.0898 - accuracy: 0.6947 - val_loss: 0.1373 - val_smart_square_abs_min_loss: 0.1373 - val_accuracy: 0.6300\n",
      "Epoch 121/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0899 - smart_square_abs_min_loss: 0.0899 - accuracy: 0.7097+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 280ms/step - loss: 0.1643 - smart_square_abs_min_loss: 0.1643 - accuracy: 0.6411\n",
      "Loss on test data:  0.16425494849681854\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[56.907646 34.508465 21.196892]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[18.96956   29.517727   0.2793581]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[13.676849 62.18649  48.7274  ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 93s 342ms/step - loss: 0.0899 - smart_square_abs_min_loss: 0.0899 - accuracy: 0.7097 - val_loss: 0.0887 - val_smart_square_abs_min_loss: 0.0887 - val_accuracy: 0.7067\n",
      "Epoch 122/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0869 - smart_square_abs_min_loss: 0.0869 - accuracy: 0.7308 - val_loss: 0.1091 - val_smart_square_abs_min_loss: 0.1091 - val_accuracy: 0.6653\n",
      "Epoch 123/300\n",
      "273/273 [==============================] - 83s 305ms/step - loss: 0.0770 - smart_square_abs_min_loss: 0.0770 - accuracy: 0.7569 - val_loss: 0.1002 - val_smart_square_abs_min_loss: 0.1002 - val_accuracy: 0.6512\n",
      "Epoch 124/300\n",
      "273/273 [==============================] - 84s 306ms/step - loss: 0.0932 - smart_square_abs_min_loss: 0.0932 - accuracy: 0.6954 - val_loss: 0.0987 - val_smart_square_abs_min_loss: 0.0987 - val_accuracy: 0.5998\n",
      "Epoch 125/300\n",
      "273/273 [==============================] - 84s 306ms/step - loss: 0.0702 - smart_square_abs_min_loss: 0.0702 - accuracy: 0.7895 - val_loss: 0.1069 - val_smart_square_abs_min_loss: 0.1069 - val_accuracy: 0.8065\n",
      "Epoch 126/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273/273 [==============================] - ETA: 0s - loss: 0.0807 - smart_square_abs_min_loss: 0.0807 - accuracy: 0.7160+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 276ms/step - loss: 0.0855 - smart_square_abs_min_loss: 0.0855 - accuracy: 0.6562\n",
      "Loss on test data:  0.08550123870372772\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted values [[56.358356 36.077778 24.385668]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[25.3167    30.545702   5.7604833]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "predicted values [[15.584931 61.41826  45.463566]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 92s 336ms/step - loss: 0.0807 - smart_square_abs_min_loss: 0.0807 - accuracy: 0.7160 - val_loss: 0.1063 - val_smart_square_abs_min_loss: 0.1063 - val_accuracy: 0.6361\n",
      "Epoch 127/300\n",
      "273/273 [==============================] - 85s 310ms/step - loss: 0.0921 - smart_square_abs_min_loss: 0.0921 - accuracy: 0.7062 - val_loss: 0.0918 - val_smart_square_abs_min_loss: 0.0918 - val_accuracy: 0.6210\n",
      "Epoch 128/300\n",
      "273/273 [==============================] - 79s 290ms/step - loss: 0.0911 - smart_square_abs_min_loss: 0.0911 - accuracy: 0.6799 - val_loss: 0.1145 - val_smart_square_abs_min_loss: 0.1145 - val_accuracy: 0.7470\n",
      "Epoch 129/300\n",
      "273/273 [==============================] - 84s 307ms/step - loss: 0.0948 - smart_square_abs_min_loss: 0.0948 - accuracy: 0.7016 - val_loss: 0.0784 - val_smart_square_abs_min_loss: 0.0784 - val_accuracy: 0.6240\n",
      "Epoch 130/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0865 - smart_square_abs_min_loss: 0.0865 - accuracy: 0.7174 - val_loss: 0.1088 - val_smart_square_abs_min_loss: 0.1088 - val_accuracy: 0.6018\n",
      "Epoch 131/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0806 - smart_square_abs_min_loss: 0.0806 - accuracy: 0.6965+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 283ms/step - loss: 0.1032 - smart_square_abs_min_loss: 0.1032 - accuracy: 0.6179\n",
      "Loss on test data:  0.10318688303232193\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[58.319572 35.21838  21.975832]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[26.219479  36.14829    2.5905008]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[15.8303175 61.37349   47.430683 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 93s 339ms/step - loss: 0.0806 - smart_square_abs_min_loss: 0.0806 - accuracy: 0.6965 - val_loss: 0.0987 - val_smart_square_abs_min_loss: 0.0987 - val_accuracy: 0.6290\n",
      "Epoch 132/300\n",
      "273/273 [==============================] - 84s 306ms/step - loss: 0.0831 - smart_square_abs_min_loss: 0.0831 - accuracy: 0.7256 - val_loss: 0.0864 - val_smart_square_abs_min_loss: 0.0864 - val_accuracy: 0.6875\n",
      "Epoch 133/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0780 - smart_square_abs_min_loss: 0.0780 - accuracy: 0.7656 - val_loss: 0.0796 - val_smart_square_abs_min_loss: 0.0796 - val_accuracy: 0.8075\n",
      "Epoch 134/300\n",
      "273/273 [==============================] - 85s 310ms/step - loss: 0.0848 - smart_square_abs_min_loss: 0.0848 - accuracy: 0.7078 - val_loss: 0.0823 - val_smart_square_abs_min_loss: 0.0823 - val_accuracy: 0.6996\n",
      "Epoch 135/300\n",
      "273/273 [==============================] - 86s 315ms/step - loss: 0.0863 - smart_square_abs_min_loss: 0.0863 - accuracy: 0.7309 - val_loss: 0.0904 - val_smart_square_abs_min_loss: 0.0904 - val_accuracy: 0.6562\n",
      "Epoch 136/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0876 - smart_square_abs_min_loss: 0.0876 - accuracy: 0.6857+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 281ms/step - loss: 0.1089 - smart_square_abs_min_loss: 0.1089 - accuracy: 0.7440\n",
      "Loss on test data:  0.10890412330627441\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[56.74916  35.49244  20.303228]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[22.03611   35.433308   2.2371392]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[16.402218 61.75502  50.138435]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 94s 343ms/step - loss: 0.0876 - smart_square_abs_min_loss: 0.0876 - accuracy: 0.6857 - val_loss: 0.1048 - val_smart_square_abs_min_loss: 0.1048 - val_accuracy: 0.7490\n",
      "Epoch 137/300\n",
      "273/273 [==============================] - 83s 302ms/step - loss: 0.0788 - smart_square_abs_min_loss: 0.0788 - accuracy: 0.7465 - val_loss: 0.0833 - val_smart_square_abs_min_loss: 0.0833 - val_accuracy: 0.6704\n",
      "Epoch 138/300\n",
      "273/273 [==============================] - 85s 309ms/step - loss: 0.0912 - smart_square_abs_min_loss: 0.0912 - accuracy: 0.7071 - val_loss: 0.0952 - val_smart_square_abs_min_loss: 0.0952 - val_accuracy: 0.6179\n",
      "Epoch 139/300\n",
      "273/273 [==============================] - 85s 313ms/step - loss: 0.0762 - smart_square_abs_min_loss: 0.0762 - accuracy: 0.7418 - val_loss: 0.1094 - val_smart_square_abs_min_loss: 0.1094 - val_accuracy: 0.6714\n",
      "Epoch 140/300\n",
      "273/273 [==============================] - 84s 307ms/step - loss: 0.0830 - smart_square_abs_min_loss: 0.0830 - accuracy: 0.7068 - val_loss: 0.0990 - val_smart_square_abs_min_loss: 0.0990 - val_accuracy: 0.6774\n",
      "Epoch 141/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0740 - smart_square_abs_min_loss: 0.0740 - accuracy: 0.7469+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 277ms/step - loss: 0.1197 - smart_square_abs_min_loss: 0.1197 - accuracy: 0.6512\n",
      "Loss on test data:  0.11974730342626572\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[58.29909  39.05127  22.317883]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[21.824951 33.042614  5.786098]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[14.853863 61.450893 52.193745]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 93s 340ms/step - loss: 0.0740 - smart_square_abs_min_loss: 0.0740 - accuracy: 0.7469 - val_loss: 0.0774 - val_smart_square_abs_min_loss: 0.0774 - val_accuracy: 0.7056\n",
      "Epoch 142/300\n",
      "273/273 [==============================] - 85s 311ms/step - loss: 0.0891 - smart_square_abs_min_loss: 0.0891 - accuracy: 0.6785 - val_loss: 0.0816 - val_smart_square_abs_min_loss: 0.0816 - val_accuracy: 0.7056\n",
      "Epoch 143/300\n",
      "273/273 [==============================] - 84s 306ms/step - loss: 0.0826 - smart_square_abs_min_loss: 0.0826 - accuracy: 0.7366 - val_loss: 0.0942 - val_smart_square_abs_min_loss: 0.0942 - val_accuracy: 0.6361\n",
      "Epoch 144/300\n",
      "273/273 [==============================] - 85s 312ms/step - loss: 0.0870 - smart_square_abs_min_loss: 0.0870 - accuracy: 0.6935 - val_loss: 0.1175 - val_smart_square_abs_min_loss: 0.1175 - val_accuracy: 0.5433\n",
      "Epoch 145/300\n",
      "273/273 [==============================] - 85s 311ms/step - loss: 0.0711 - smart_square_abs_min_loss: 0.0711 - accuracy: 0.7582 - val_loss: 0.1075 - val_smart_square_abs_min_loss: 0.1075 - val_accuracy: 0.6512\n",
      "Epoch 146/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0795 - smart_square_abs_min_loss: 0.0795 - accuracy: 0.7244+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 268ms/step - loss: 0.0857 - smart_square_abs_min_loss: 0.0857 - accuracy: 0.6159\n",
      "Loss on test data:  0.08567019551992416\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[58.236217 37.51773  21.65714 ]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[21.55806  39.598396  5.156741]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[19.038902 61.85546  46.942688]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 92s 338ms/step - loss: 0.0795 - smart_square_abs_min_loss: 0.0795 - accuracy: 0.7244 - val_loss: 0.0961 - val_smart_square_abs_min_loss: 0.0961 - val_accuracy: 0.8024\n",
      "Epoch 147/300\n",
      "273/273 [==============================] - 84s 307ms/step - loss: 0.0711 - smart_square_abs_min_loss: 0.0711 - accuracy: 0.7891 - val_loss: 0.1020 - val_smart_square_abs_min_loss: 0.1020 - val_accuracy: 0.7510\n",
      "Epoch 148/300\n",
      "273/273 [==============================] - 84s 306ms/step - loss: 0.0822 - smart_square_abs_min_loss: 0.0822 - accuracy: 0.7313 - val_loss: 0.1233 - val_smart_square_abs_min_loss: 0.1233 - val_accuracy: 0.6300\n",
      "Epoch 149/300\n",
      "273/273 [==============================] - 84s 306ms/step - loss: 0.0794 - smart_square_abs_min_loss: 0.0794 - accuracy: 0.7576 - val_loss: 0.1154 - val_smart_square_abs_min_loss: 0.1154 - val_accuracy: 0.5524\n",
      "Epoch 150/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0713 - smart_square_abs_min_loss: 0.0713 - accuracy: 0.7327 - val_loss: 0.0971 - val_smart_square_abs_min_loss: 0.0971 - val_accuracy: 0.6956\n",
      "Epoch 151/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0859 - smart_square_abs_min_loss: 0.0859 - accuracy: 0.7295+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 272ms/step - loss: 0.0999 - smart_square_abs_min_loss: 0.0999 - accuracy: 0.5665\n",
      "Loss on test data:  0.09994540363550186\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[57.579792 34.65114  21.262745]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[17.148487 40.908745  4.313459]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[18.716955 61.329277 44.896618]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 94s 344ms/step - loss: 0.0859 - smart_square_abs_min_loss: 0.0859 - accuracy: 0.7295 - val_loss: 0.0825 - val_smart_square_abs_min_loss: 0.0825 - val_accuracy: 0.7732\n",
      "Epoch 152/300\n",
      "273/273 [==============================] - 84s 307ms/step - loss: 0.0860 - smart_square_abs_min_loss: 0.0860 - accuracy: 0.6866 - val_loss: 0.0727 - val_smart_square_abs_min_loss: 0.0727 - val_accuracy: 0.7218\n",
      "Epoch 153/300\n",
      "273/273 [==============================] - 83s 305ms/step - loss: 0.0654 - smart_square_abs_min_loss: 0.0654 - accuracy: 0.7752 - val_loss: 0.1065 - val_smart_square_abs_min_loss: 0.1065 - val_accuracy: 0.5675\n",
      "Epoch 154/300\n",
      "273/273 [==============================] - 84s 307ms/step - loss: 0.0688 - smart_square_abs_min_loss: 0.0688 - accuracy: 0.7737 - val_loss: 0.1135 - val_smart_square_abs_min_loss: 0.1135 - val_accuracy: 0.6079\n",
      "Epoch 155/300\n",
      "273/273 [==============================] - 85s 313ms/step - loss: 0.0781 - smart_square_abs_min_loss: 0.0781 - accuracy: 0.7474 - val_loss: 0.1258 - val_smart_square_abs_min_loss: 0.1258 - val_accuracy: 0.6714\n",
      "Epoch 156/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0806 - smart_square_abs_min_loss: 0.0806 - accuracy: 0.7245+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 268ms/step - loss: 0.0721 - smart_square_abs_min_loss: 0.0721 - accuracy: 0.6411\n",
      "Loss on test data:  0.07213596999645233\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[57.126904 36.165985 21.723206]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[20.541306  40.76323    2.0692606]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[18.26495  59.708466 49.98359 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 93s 339ms/step - loss: 0.0806 - smart_square_abs_min_loss: 0.0806 - accuracy: 0.7245 - val_loss: 0.1191 - val_smart_square_abs_min_loss: 0.1191 - val_accuracy: 0.5464\n",
      "Epoch 157/300\n",
      "273/273 [==============================] - 83s 304ms/step - loss: 0.0670 - smart_square_abs_min_loss: 0.0670 - accuracy: 0.7605 - val_loss: 0.1312 - val_smart_square_abs_min_loss: 0.1312 - val_accuracy: 0.5181\n",
      "Epoch 158/300\n",
      "273/273 [==============================] - 82s 302ms/step - loss: 0.0837 - smart_square_abs_min_loss: 0.0837 - accuracy: 0.7210 - val_loss: 0.0785 - val_smart_square_abs_min_loss: 0.0785 - val_accuracy: 0.7641\n",
      "Epoch 159/300\n",
      "273/273 [==============================] - 84s 307ms/step - loss: 0.0898 - smart_square_abs_min_loss: 0.0898 - accuracy: 0.6890 - val_loss: 0.0622 - val_smart_square_abs_min_loss: 0.0622 - val_accuracy: 0.7571\n",
      "Epoch 160/300\n",
      "273/273 [==============================] - 85s 309ms/step - loss: 0.0819 - smart_square_abs_min_loss: 0.0819 - accuracy: 0.7191 - val_loss: 0.0702 - val_smart_square_abs_min_loss: 0.0702 - val_accuracy: 0.7450\n",
      "Epoch 161/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0853 - smart_square_abs_min_loss: 0.0853 - accuracy: 0.7382+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 271ms/step - loss: 0.0876 - smart_square_abs_min_loss: 0.0876 - accuracy: 0.6431\n",
      "Loss on test data:  0.08758332580327988\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[60.0966   41.64781  25.417175]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[22.296272 36.52376   1.341749]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[17.61717  60.473213 49.91428 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 94s 345ms/step - loss: 0.0853 - smart_square_abs_min_loss: 0.0853 - accuracy: 0.7382 - val_loss: 0.1259 - val_smart_square_abs_min_loss: 0.1259 - val_accuracy: 0.6815\n",
      "Epoch 162/300\n",
      "273/273 [==============================] - 83s 303ms/step - loss: 0.0885 - smart_square_abs_min_loss: 0.0885 - accuracy: 0.7110 - val_loss: 0.1065 - val_smart_square_abs_min_loss: 0.1065 - val_accuracy: 0.6966\n",
      "Epoch 163/300\n",
      "273/273 [==============================] - 84s 306ms/step - loss: 0.0813 - smart_square_abs_min_loss: 0.0813 - accuracy: 0.7198 - val_loss: 0.0805 - val_smart_square_abs_min_loss: 0.0805 - val_accuracy: 0.7046\n",
      "Epoch 164/300\n",
      "273/273 [==============================] - 85s 312ms/step - loss: 0.0957 - smart_square_abs_min_loss: 0.0957 - accuracy: 0.6944 - val_loss: 0.0811 - val_smart_square_abs_min_loss: 0.0811 - val_accuracy: 0.6683\n",
      "Epoch 165/300\n",
      "273/273 [==============================] - 83s 304ms/step - loss: 0.0726 - smart_square_abs_min_loss: 0.0726 - accuracy: 0.7463 - val_loss: 0.0958 - val_smart_square_abs_min_loss: 0.0958 - val_accuracy: 0.7026\n",
      "Epoch 166/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0756 - smart_square_abs_min_loss: 0.0756 - accuracy: 0.7400+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 274ms/step - loss: 0.1312 - smart_square_abs_min_loss: 0.1312 - accuracy: 0.7399\n",
      "Loss on test data:  0.13123036921024323\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[58.531475 39.08694  19.530973]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "predicted values [[14.894985  29.241      0.1469247]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[17.460787 60.261993 47.29717 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 93s 340ms/step - loss: 0.0756 - smart_square_abs_min_loss: 0.0756 - accuracy: 0.7400 - val_loss: 0.1005 - val_smart_square_abs_min_loss: 0.1005 - val_accuracy: 0.6512\n",
      "Epoch 167/300\n",
      "273/273 [==============================] - 86s 314ms/step - loss: 0.0838 - smart_square_abs_min_loss: 0.0838 - accuracy: 0.7075 - val_loss: 0.0666 - val_smart_square_abs_min_loss: 0.0666 - val_accuracy: 0.8508\n",
      "Epoch 168/300\n",
      "273/273 [==============================] - 85s 312ms/step - loss: 0.0790 - smart_square_abs_min_loss: 0.0790 - accuracy: 0.7307 - val_loss: 0.1075 - val_smart_square_abs_min_loss: 0.1075 - val_accuracy: 0.6744\n",
      "Epoch 169/300\n",
      "273/273 [==============================] - 85s 310ms/step - loss: 0.0651 - smart_square_abs_min_loss: 0.0651 - accuracy: 0.7547 - val_loss: 0.1361 - val_smart_square_abs_min_loss: 0.1361 - val_accuracy: 0.6532\n",
      "Epoch 170/300\n",
      "273/273 [==============================] - 87s 319ms/step - loss: 0.0848 - smart_square_abs_min_loss: 0.0848 - accuracy: 0.6806 - val_loss: 0.1207 - val_smart_square_abs_min_loss: 0.1207 - val_accuracy: 0.5867\n",
      "Epoch 171/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0726 - smart_square_abs_min_loss: 0.0726 - accuracy: 0.7316+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 285ms/step - loss: 0.1120 - smart_square_abs_min_loss: 0.1120 - accuracy: 0.6028\n",
      "Loss on test data:  0.11200504004955292\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[56.767727 36.98662  18.44575 ]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[28.609627  37.113293  -1.3215297]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[17.00209  60.12972  46.424595]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 94s 345ms/step - loss: 0.0726 - smart_square_abs_min_loss: 0.0726 - accuracy: 0.7316 - val_loss: 0.0722 - val_smart_square_abs_min_loss: 0.0722 - val_accuracy: 0.7500\n",
      "Epoch 172/300\n",
      "273/273 [==============================] - 77s 282ms/step - loss: 0.0763 - smart_square_abs_min_loss: 0.0763 - accuracy: 0.7395 - val_loss: 0.1289 - val_smart_square_abs_min_loss: 0.1289 - val_accuracy: 0.6865\n",
      "Epoch 173/300\n",
      "273/273 [==============================] - 72s 264ms/step - loss: 0.0821 - smart_square_abs_min_loss: 0.0821 - accuracy: 0.7214 - val_loss: 0.1450 - val_smart_square_abs_min_loss: 0.1450 - val_accuracy: 0.6573\n",
      "Epoch 174/300\n",
      "273/273 [==============================] - 78s 285ms/step - loss: 0.0782 - smart_square_abs_min_loss: 0.0782 - accuracy: 0.7320 - val_loss: 0.1074 - val_smart_square_abs_min_loss: 0.1074 - val_accuracy: 0.6794\n",
      "Epoch 175/300\n",
      "273/273 [==============================] - 77s 282ms/step - loss: 0.0782 - smart_square_abs_min_loss: 0.0782 - accuracy: 0.7444 - val_loss: 0.1176 - val_smart_square_abs_min_loss: 0.1176 - val_accuracy: 0.6351\n",
      "Epoch 176/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0748 - smart_square_abs_min_loss: 0.0748 - accuracy: 0.7284+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 258ms/step - loss: 0.1264 - smart_square_abs_min_loss: 0.1264 - accuracy: 0.5817\n",
      "Loss on test data:  0.12640789151191711\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[57.199654 38.300114 20.658585]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[21.057892 37.550774  4.344793]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[17.212353 60.979248 49.667553]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 89s 325ms/step - loss: 0.0748 - smart_square_abs_min_loss: 0.0748 - accuracy: 0.7284 - val_loss: 0.0771 - val_smart_square_abs_min_loss: 0.0771 - val_accuracy: 0.7389\n",
      "Epoch 177/300\n",
      "273/273 [==============================] - 86s 314ms/step - loss: 0.0721 - smart_square_abs_min_loss: 0.0721 - accuracy: 0.7602 - val_loss: 0.0825 - val_smart_square_abs_min_loss: 0.0825 - val_accuracy: 0.7530\n",
      "Epoch 178/300\n",
      "273/273 [==============================] - 86s 314ms/step - loss: 0.0688 - smart_square_abs_min_loss: 0.0688 - accuracy: 0.7475 - val_loss: 0.1009 - val_smart_square_abs_min_loss: 0.1009 - val_accuracy: 0.5444\n",
      "Epoch 179/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0870 - smart_square_abs_min_loss: 0.0870 - accuracy: 0.6894 - val_loss: 0.1082 - val_smart_square_abs_min_loss: 0.1082 - val_accuracy: 0.5403\n",
      "Epoch 180/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0790 - smart_square_abs_min_loss: 0.0790 - accuracy: 0.7168 - val_loss: 0.0913 - val_smart_square_abs_min_loss: 0.0913 - val_accuracy: 0.6925\n",
      "Epoch 181/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0716 - smart_square_abs_min_loss: 0.0716 - accuracy: 0.7639+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 282ms/step - loss: 0.0833 - smart_square_abs_min_loss: 0.0833 - accuracy: 0.7974\n",
      "Loss on test data:  0.08328066766262054\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "predicted values [[56.919533 37.42588  26.405104]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[21.535648  37.518845   3.1619182]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[19.474146 63.29249  50.766533]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 94s 346ms/step - loss: 0.0716 - smart_square_abs_min_loss: 0.0716 - accuracy: 0.7639 - val_loss: 0.0865 - val_smart_square_abs_min_loss: 0.0865 - val_accuracy: 0.8407\n",
      "Epoch 182/300\n",
      "273/273 [==============================] - 78s 284ms/step - loss: 0.0658 - smart_square_abs_min_loss: 0.0658 - accuracy: 0.7721 - val_loss: 0.0996 - val_smart_square_abs_min_loss: 0.0996 - val_accuracy: 0.6522\n",
      "Epoch 183/300\n",
      "273/273 [==============================] - 76s 280ms/step - loss: 0.0850 - smart_square_abs_min_loss: 0.0850 - accuracy: 0.7201 - val_loss: 0.0890 - val_smart_square_abs_min_loss: 0.0890 - val_accuracy: 0.6774\n",
      "Epoch 184/300\n",
      "273/273 [==============================] - 85s 310ms/step - loss: 0.0871 - smart_square_abs_min_loss: 0.0871 - accuracy: 0.7015 - val_loss: 0.1220 - val_smart_square_abs_min_loss: 0.1220 - val_accuracy: 0.6250\n",
      "Epoch 185/300\n",
      "273/273 [==============================] - 82s 299ms/step - loss: 0.0766 - smart_square_abs_min_loss: 0.0766 - accuracy: 0.7238 - val_loss: 0.0739 - val_smart_square_abs_min_loss: 0.0739 - val_accuracy: 0.6129\n",
      "Epoch 186/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0900 - smart_square_abs_min_loss: 0.0900 - accuracy: 0.6968+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 274ms/step - loss: 0.1570 - smart_square_abs_min_loss: 0.1570 - accuracy: 0.6784\n",
      "Loss on test data:  0.15697833895683289\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[57.27084  34.329327 16.792992]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[22.699654  40.383488   3.2278214]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[18.07507  61.27293  51.560913]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 94s 345ms/step - loss: 0.0900 - smart_square_abs_min_loss: 0.0900 - accuracy: 0.6968 - val_loss: 0.0870 - val_smart_square_abs_min_loss: 0.0870 - val_accuracy: 0.5847\n",
      "Epoch 187/300\n",
      "273/273 [==============================] - 85s 310ms/step - loss: 0.0720 - smart_square_abs_min_loss: 0.0720 - accuracy: 0.7705 - val_loss: 0.1169 - val_smart_square_abs_min_loss: 0.1169 - val_accuracy: 0.7127\n",
      "Epoch 188/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0734 - smart_square_abs_min_loss: 0.0734 - accuracy: 0.7345 - val_loss: 0.1112 - val_smart_square_abs_min_loss: 0.1112 - val_accuracy: 0.6250\n",
      "Epoch 189/300\n",
      "273/273 [==============================] - 86s 313ms/step - loss: 0.0787 - smart_square_abs_min_loss: 0.0787 - accuracy: 0.7316 - val_loss: 0.0948 - val_smart_square_abs_min_loss: 0.0948 - val_accuracy: 0.6250\n",
      "Epoch 190/300\n",
      "273/273 [==============================] - 85s 312ms/step - loss: 0.0910 - smart_square_abs_min_loss: 0.0910 - accuracy: 0.6993 - val_loss: 0.0760 - val_smart_square_abs_min_loss: 0.0760 - val_accuracy: 0.6714\n",
      "Epoch 191/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0808 - smart_square_abs_min_loss: 0.0808 - accuracy: 0.6833+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 285ms/step - loss: 0.0661 - smart_square_abs_min_loss: 0.0661 - accuracy: 0.7248\n",
      "Loss on test data:  0.06611368805170059\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "predicted values [[59.2988   38.332355 24.988451]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[26.46193   42.375095   3.9382963]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[17.051662 62.137756 51.523975]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 95s 350ms/step - loss: 0.0808 - smart_square_abs_min_loss: 0.0808 - accuracy: 0.6833 - val_loss: 0.0769 - val_smart_square_abs_min_loss: 0.0769 - val_accuracy: 0.7651\n",
      "Epoch 192/300\n",
      "273/273 [==============================] - 71s 259ms/step - loss: 0.0746 - smart_square_abs_min_loss: 0.0746 - accuracy: 0.7596 - val_loss: 0.0982 - val_smart_square_abs_min_loss: 0.0982 - val_accuracy: 0.7137\n",
      "Epoch 193/300\n",
      "273/273 [==============================] - 73s 266ms/step - loss: 0.0748 - smart_square_abs_min_loss: 0.0748 - accuracy: 0.7258 - val_loss: 0.0950 - val_smart_square_abs_min_loss: 0.0950 - val_accuracy: 0.6905\n",
      "Epoch 194/300\n",
      "273/273 [==============================] - 78s 285ms/step - loss: 0.0755 - smart_square_abs_min_loss: 0.0755 - accuracy: 0.7416 - val_loss: 0.1150 - val_smart_square_abs_min_loss: 0.1150 - val_accuracy: 0.5847\n",
      "Epoch 195/300\n",
      "273/273 [==============================] - 78s 285ms/step - loss: 0.0671 - smart_square_abs_min_loss: 0.0671 - accuracy: 0.7566 - val_loss: 0.0696 - val_smart_square_abs_min_loss: 0.0696 - val_accuracy: 0.7046\n",
      "Epoch 196/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0735 - smart_square_abs_min_loss: 0.0735 - accuracy: 0.7090+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 282ms/step - loss: 0.1277 - smart_square_abs_min_loss: 0.1277 - accuracy: 0.6694\n",
      "Loss on test data:  0.12771089375019073\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[58.32846  34.79657  18.510378]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[23.608578  42.141834  -1.4804848]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[17.877209 61.83076  50.72042 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 89s 326ms/step - loss: 0.0735 - smart_square_abs_min_loss: 0.0735 - accuracy: 0.7090 - val_loss: 0.0830 - val_smart_square_abs_min_loss: 0.0830 - val_accuracy: 0.6532\n",
      "Epoch 197/300\n",
      "273/273 [==============================] - 72s 264ms/step - loss: 0.0860 - smart_square_abs_min_loss: 0.0860 - accuracy: 0.6937 - val_loss: 0.0843 - val_smart_square_abs_min_loss: 0.0843 - val_accuracy: 0.5302\n",
      "Epoch 198/300\n",
      "273/273 [==============================] - 72s 265ms/step - loss: 0.0857 - smart_square_abs_min_loss: 0.0857 - accuracy: 0.7089 - val_loss: 0.0777 - val_smart_square_abs_min_loss: 0.0777 - val_accuracy: 0.7984\n",
      "Epoch 199/300\n",
      "273/273 [==============================] - 78s 284ms/step - loss: 0.0826 - smart_square_abs_min_loss: 0.0826 - accuracy: 0.7129 - val_loss: 0.0799 - val_smart_square_abs_min_loss: 0.0799 - val_accuracy: 0.7409\n",
      "Epoch 200/300\n",
      "273/273 [==============================] - 80s 291ms/step - loss: 0.0782 - smart_square_abs_min_loss: 0.0782 - accuracy: 0.7099 - val_loss: 0.1208 - val_smart_square_abs_min_loss: 0.1208 - val_accuracy: 0.5575\n",
      "Epoch 201/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0893 - smart_square_abs_min_loss: 0.0893 - accuracy: 0.7157+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 257ms/step - loss: 0.0915 - smart_square_abs_min_loss: 0.0915 - accuracy: 0.7480\n",
      "Loss on test data:  0.09146210551261902\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted values [[52.933964 36.49723  17.117426]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[14.708339  31.735779   1.9906349]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[19.282755 62.020992 50.23377 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 81s 295ms/step - loss: 0.0893 - smart_square_abs_min_loss: 0.0893 - accuracy: 0.7157 - val_loss: 0.1244 - val_smart_square_abs_min_loss: 0.1244 - val_accuracy: 0.6794\n",
      "Epoch 202/300\n",
      "273/273 [==============================] - 71s 259ms/step - loss: 0.0733 - smart_square_abs_min_loss: 0.0733 - accuracy: 0.7499 - val_loss: 0.0950 - val_smart_square_abs_min_loss: 0.0950 - val_accuracy: 0.7188\n",
      "Epoch 203/300\n",
      "273/273 [==============================] - 78s 285ms/step - loss: 0.0849 - smart_square_abs_min_loss: 0.0849 - accuracy: 0.7198 - val_loss: 0.0925 - val_smart_square_abs_min_loss: 0.0925 - val_accuracy: 0.5907\n",
      "Epoch 204/300\n",
      "273/273 [==============================] - 79s 289ms/step - loss: 0.0868 - smart_square_abs_min_loss: 0.0868 - accuracy: 0.7106 - val_loss: 0.0626 - val_smart_square_abs_min_loss: 0.0626 - val_accuracy: 0.6411\n",
      "Epoch 205/300\n",
      "273/273 [==============================] - 85s 310ms/step - loss: 0.0746 - smart_square_abs_min_loss: 0.0746 - accuracy: 0.7467 - val_loss: 0.0789 - val_smart_square_abs_min_loss: 0.0789 - val_accuracy: 0.6784\n",
      "Epoch 206/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0706 - smart_square_abs_min_loss: 0.0706 - accuracy: 0.7539+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 273ms/step - loss: 0.0949 - smart_square_abs_min_loss: 0.0949 - accuracy: 0.6421\n",
      "Loss on test data:  0.0948500782251358\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[56.671127 36.06594  20.143543]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[22.767143  48.406708   2.1019633]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[16.342443 63.5818   51.58341 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 93s 340ms/step - loss: 0.0706 - smart_square_abs_min_loss: 0.0706 - accuracy: 0.7539 - val_loss: 0.1002 - val_smart_square_abs_min_loss: 0.1002 - val_accuracy: 0.6956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 207/300\n",
      "273/273 [==============================] - 85s 310ms/step - loss: 0.0864 - smart_square_abs_min_loss: 0.0864 - accuracy: 0.6746 - val_loss: 0.0739 - val_smart_square_abs_min_loss: 0.0739 - val_accuracy: 0.7954\n",
      "Epoch 208/300\n",
      "273/273 [==============================] - 84s 309ms/step - loss: 0.0784 - smart_square_abs_min_loss: 0.0784 - accuracy: 0.7429 - val_loss: 0.1092 - val_smart_square_abs_min_loss: 0.1092 - val_accuracy: 0.6815\n",
      "Epoch 209/300\n",
      "273/273 [==============================] - 85s 312ms/step - loss: 0.0819 - smart_square_abs_min_loss: 0.0819 - accuracy: 0.7123 - val_loss: 0.1163 - val_smart_square_abs_min_loss: 0.1163 - val_accuracy: 0.6673\n",
      "Epoch 210/300\n",
      "273/273 [==============================] - 86s 314ms/step - loss: 0.0763 - smart_square_abs_min_loss: 0.0763 - accuracy: 0.7427 - val_loss: 0.0822 - val_smart_square_abs_min_loss: 0.0822 - val_accuracy: 0.7046\n",
      "Epoch 211/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0766 - smart_square_abs_min_loss: 0.0766 - accuracy: 0.7315+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 278ms/step - loss: 0.0985 - smart_square_abs_min_loss: 0.0985 - accuracy: 0.6925\n",
      "Loss on test data:  0.09850206971168518\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted values [[59.718258 37.031773 21.803192]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[19.750788 35.64344   0.696573]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[16.071108 62.667774 51.908226]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 94s 345ms/step - loss: 0.0766 - smart_square_abs_min_loss: 0.0766 - accuracy: 0.7315 - val_loss: 0.0918 - val_smart_square_abs_min_loss: 0.0918 - val_accuracy: 0.6663\n",
      "Epoch 212/300\n",
      "273/273 [==============================] - 77s 281ms/step - loss: 0.0915 - smart_square_abs_min_loss: 0.0915 - accuracy: 0.7048 - val_loss: 0.0806 - val_smart_square_abs_min_loss: 0.0806 - val_accuracy: 0.6875\n",
      "Epoch 213/300\n",
      "273/273 [==============================] - 78s 287ms/step - loss: 0.0714 - smart_square_abs_min_loss: 0.0714 - accuracy: 0.7426 - val_loss: 0.0875 - val_smart_square_abs_min_loss: 0.0875 - val_accuracy: 0.7389\n",
      "Epoch 214/300\n",
      "273/273 [==============================] - 79s 290ms/step - loss: 0.0836 - smart_square_abs_min_loss: 0.0836 - accuracy: 0.7131 - val_loss: 0.1179 - val_smart_square_abs_min_loss: 0.1179 - val_accuracy: 0.6774\n",
      "Epoch 215/300\n",
      "273/273 [==============================] - 86s 317ms/step - loss: 0.0756 - smart_square_abs_min_loss: 0.0756 - accuracy: 0.7403 - val_loss: 0.1106 - val_smart_square_abs_min_loss: 0.1106 - val_accuracy: 0.6562\n",
      "Epoch 216/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0792 - smart_square_abs_min_loss: 0.0792 - accuracy: 0.7286+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 280ms/step - loss: 0.1043 - smart_square_abs_min_loss: 0.1043 - accuracy: 0.7560\n",
      "Loss on test data:  0.10427689552307129\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[57.18144  36.037643 25.30788 ]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[17.832369  31.039005   0.5989098]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[16.467083 61.76623  51.382492]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 95s 347ms/step - loss: 0.0792 - smart_square_abs_min_loss: 0.0792 - accuracy: 0.7286 - val_loss: 0.0909 - val_smart_square_abs_min_loss: 0.0909 - val_accuracy: 0.6593\n",
      "Epoch 217/300\n",
      "273/273 [==============================] - 73s 266ms/step - loss: 0.0630 - smart_square_abs_min_loss: 0.0630 - accuracy: 0.7537 - val_loss: 0.1035 - val_smart_square_abs_min_loss: 0.1035 - val_accuracy: 0.5625\n",
      "Epoch 218/300\n",
      "273/273 [==============================] - 85s 311ms/step - loss: 0.0780 - smart_square_abs_min_loss: 0.0780 - accuracy: 0.7286 - val_loss: 0.0734 - val_smart_square_abs_min_loss: 0.0734 - val_accuracy: 0.6099\n",
      "Epoch 219/300\n",
      "273/273 [==============================] - 77s 280ms/step - loss: 0.0760 - smart_square_abs_min_loss: 0.0760 - accuracy: 0.7072 - val_loss: 0.1029 - val_smart_square_abs_min_loss: 0.1029 - val_accuracy: 0.6562\n",
      "Epoch 220/300\n",
      "273/273 [==============================] - 79s 288ms/step - loss: 0.0654 - smart_square_abs_min_loss: 0.0654 - accuracy: 0.7755 - val_loss: 0.1055 - val_smart_square_abs_min_loss: 0.1055 - val_accuracy: 0.5968\n",
      "Epoch 221/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0670 - smart_square_abs_min_loss: 0.0670 - accuracy: 0.7753+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 255ms/step - loss: 0.1059 - smart_square_abs_min_loss: 0.1059 - accuracy: 0.7238\n",
      "Loss on test data:  0.10593201965093613\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted values [[57.17866  35.29716  21.939283]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[16.637068 36.75261  -0.747875]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[18.74486  62.755253 51.986736]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 80s 293ms/step - loss: 0.0670 - smart_square_abs_min_loss: 0.0670 - accuracy: 0.7753 - val_loss: 0.1030 - val_smart_square_abs_min_loss: 0.1030 - val_accuracy: 0.6895\n",
      "Epoch 222/300\n",
      "273/273 [==============================] - 79s 291ms/step - loss: 0.0754 - smart_square_abs_min_loss: 0.0754 - accuracy: 0.7392 - val_loss: 0.0972 - val_smart_square_abs_min_loss: 0.0972 - val_accuracy: 0.7409\n",
      "Epoch 223/300\n",
      "273/273 [==============================] - 79s 290ms/step - loss: 0.0729 - smart_square_abs_min_loss: 0.0729 - accuracy: 0.7408 - val_loss: 0.0818 - val_smart_square_abs_min_loss: 0.0818 - val_accuracy: 0.7661\n",
      "Epoch 224/300\n",
      "273/273 [==============================] - 72s 262ms/step - loss: 0.0741 - smart_square_abs_min_loss: 0.0741 - accuracy: 0.7529 - val_loss: 0.0693 - val_smart_square_abs_min_loss: 0.0693 - val_accuracy: 0.7460\n",
      "Epoch 225/300\n",
      "273/273 [==============================] - 85s 310ms/step - loss: 0.0797 - smart_square_abs_min_loss: 0.0797 - accuracy: 0.7078 - val_loss: 0.0898 - val_smart_square_abs_min_loss: 0.0898 - val_accuracy: 0.6956\n",
      "Epoch 226/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0807 - smart_square_abs_min_loss: 0.0807 - accuracy: 0.7421+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 7s 231ms/step - loss: 0.1348 - smart_square_abs_min_loss: 0.1348 - accuracy: 0.5806\n",
      "Loss on test data:  0.13482238352298737\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "predicted values [[57.12487  36.93872  22.853703]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[17.49131   40.013508  -0.4357443]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[18.83705  61.647636 50.461975]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 92s 339ms/step - loss: 0.0807 - smart_square_abs_min_loss: 0.0807 - accuracy: 0.7421 - val_loss: 0.1328 - val_smart_square_abs_min_loss: 0.1328 - val_accuracy: 0.4748\n",
      "Epoch 227/300\n",
      "273/273 [==============================] - 77s 283ms/step - loss: 0.0795 - smart_square_abs_min_loss: 0.0795 - accuracy: 0.7299 - val_loss: 0.0997 - val_smart_square_abs_min_loss: 0.0997 - val_accuracy: 0.6804\n",
      "Epoch 228/300\n",
      "273/273 [==============================] - 85s 311ms/step - loss: 0.0845 - smart_square_abs_min_loss: 0.0845 - accuracy: 0.7168 - val_loss: 0.1209 - val_smart_square_abs_min_loss: 0.1209 - val_accuracy: 0.6734\n",
      "Epoch 229/300\n",
      "273/273 [==============================] - 78s 287ms/step - loss: 0.0814 - smart_square_abs_min_loss: 0.0814 - accuracy: 0.7347 - val_loss: 0.0971 - val_smart_square_abs_min_loss: 0.0971 - val_accuracy: 0.7228\n",
      "Epoch 230/300\n",
      "273/273 [==============================] - 71s 260ms/step - loss: 0.0758 - smart_square_abs_min_loss: 0.0758 - accuracy: 0.7428 - val_loss: 0.0572 - val_smart_square_abs_min_loss: 0.0572 - val_accuracy: 0.7228\n",
      "Epoch 231/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0888 - smart_square_abs_min_loss: 0.0888 - accuracy: 0.7020+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 281ms/step - loss: 0.0879 - smart_square_abs_min_loss: 0.0879 - accuracy: 0.7016\n",
      "Loss on test data:  0.08788804709911346\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[59.511158 36.943798 21.907402]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[15.9617405  35.20371    -0.03530324]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[18.574024 61.2846   50.35201 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 88s 322ms/step - loss: 0.0888 - smart_square_abs_min_loss: 0.0888 - accuracy: 0.7020 - val_loss: 0.0596 - val_smart_square_abs_min_loss: 0.0596 - val_accuracy: 0.7278\n",
      "Epoch 232/300\n",
      "273/273 [==============================] - 77s 282ms/step - loss: 0.0793 - smart_square_abs_min_loss: 0.0793 - accuracy: 0.7438 - val_loss: 0.1313 - val_smart_square_abs_min_loss: 0.1313 - val_accuracy: 0.5625\n",
      "Epoch 233/300\n",
      "273/273 [==============================] - 78s 287ms/step - loss: 0.0808 - smart_square_abs_min_loss: 0.0808 - accuracy: 0.7318 - val_loss: 0.1038 - val_smart_square_abs_min_loss: 0.1038 - val_accuracy: 0.5393\n",
      "Epoch 234/300\n",
      "273/273 [==============================] - 72s 264ms/step - loss: 0.0767 - smart_square_abs_min_loss: 0.0767 - accuracy: 0.7489 - val_loss: 0.0866 - val_smart_square_abs_min_loss: 0.0866 - val_accuracy: 0.6522\n",
      "Epoch 235/300\n",
      "273/273 [==============================] - 71s 260ms/step - loss: 0.0719 - smart_square_abs_min_loss: 0.0719 - accuracy: 0.7388 - val_loss: 0.1203 - val_smart_square_abs_min_loss: 0.1203 - val_accuracy: 0.7520\n",
      "Epoch 236/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0741 - smart_square_abs_min_loss: 0.0741 - accuracy: 0.7620+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 241ms/step - loss: 0.0970 - smart_square_abs_min_loss: 0.0970 - accuracy: 0.5847\n",
      "Loss on test data:  0.0970216616988182\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[60.00133  36.033638 24.281693]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[18.89293    44.285896    0.62103736]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "predicted values [[17.64181  61.484352 50.447727]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 86s 314ms/step - loss: 0.0741 - smart_square_abs_min_loss: 0.0741 - accuracy: 0.7620 - val_loss: 0.0711 - val_smart_square_abs_min_loss: 0.0711 - val_accuracy: 0.7137\n",
      "Epoch 237/300\n",
      "273/273 [==============================] - 79s 290ms/step - loss: 0.0886 - smart_square_abs_min_loss: 0.0886 - accuracy: 0.6989 - val_loss: 0.0644 - val_smart_square_abs_min_loss: 0.0644 - val_accuracy: 0.8347\n",
      "Epoch 238/300\n",
      "273/273 [==============================] - 78s 285ms/step - loss: 0.0940 - smart_square_abs_min_loss: 0.0940 - accuracy: 0.6860 - val_loss: 0.0991 - val_smart_square_abs_min_loss: 0.0991 - val_accuracy: 0.6694\n",
      "Epoch 239/300\n",
      "273/273 [==============================] - 77s 282ms/step - loss: 0.0845 - smart_square_abs_min_loss: 0.0845 - accuracy: 0.6936 - val_loss: 0.0532 - val_smart_square_abs_min_loss: 0.0532 - val_accuracy: 0.6865\n",
      "Epoch 240/300\n",
      "273/273 [==============================] - 72s 262ms/step - loss: 0.0850 - smart_square_abs_min_loss: 0.0850 - accuracy: 0.6905 - val_loss: 0.0719 - val_smart_square_abs_min_loss: 0.0719 - val_accuracy: 0.7379\n",
      "Epoch 241/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0754 - smart_square_abs_min_loss: 0.0754 - accuracy: 0.7610+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 277ms/step - loss: 0.1202 - smart_square_abs_min_loss: 0.1202 - accuracy: 0.7238\n",
      "Loss on test data:  0.12022566795349121\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted values [[60.521507 37.760784 21.85724 ]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[18.390646  37.385586   1.3073603]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[17.69071  62.166214 48.618935]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 95s 346ms/step - loss: 0.0754 - smart_square_abs_min_loss: 0.0754 - accuracy: 0.7610 - val_loss: 0.0858 - val_smart_square_abs_min_loss: 0.0858 - val_accuracy: 0.7157\n",
      "Epoch 242/300\n",
      "273/273 [==============================] - 85s 310ms/step - loss: 0.0674 - smart_square_abs_min_loss: 0.0674 - accuracy: 0.7790 - val_loss: 0.0786 - val_smart_square_abs_min_loss: 0.0786 - val_accuracy: 0.6694\n",
      "Epoch 243/300\n",
      "273/273 [==============================] - 79s 288ms/step - loss: 0.0810 - smart_square_abs_min_loss: 0.0810 - accuracy: 0.7489 - val_loss: 0.1281 - val_smart_square_abs_min_loss: 0.1281 - val_accuracy: 0.5494\n",
      "Epoch 244/300\n",
      "273/273 [==============================] - 85s 310ms/step - loss: 0.0744 - smart_square_abs_min_loss: 0.0744 - accuracy: 0.7437 - val_loss: 0.1267 - val_smart_square_abs_min_loss: 0.1267 - val_accuracy: 0.6290\n",
      "Epoch 245/300\n",
      "273/273 [==============================] - 78s 287ms/step - loss: 0.0762 - smart_square_abs_min_loss: 0.0762 - accuracy: 0.7509 - val_loss: 0.0943 - val_smart_square_abs_min_loss: 0.0943 - val_accuracy: 0.6956\n",
      "Epoch 246/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0808 - smart_square_abs_min_loss: 0.0808 - accuracy: 0.7356+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 276ms/step - loss: 0.0977 - smart_square_abs_min_loss: 0.0977 - accuracy: 0.6220\n",
      "Loss on test data:  0.09766996651887894\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[57.258255 38.701416 22.003431]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[20.450447  40.27438    0.3439544]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[15.836247 62.211945 50.6253  ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 88s 323ms/step - loss: 0.0808 - smart_square_abs_min_loss: 0.0808 - accuracy: 0.7356 - val_loss: 0.0811 - val_smart_square_abs_min_loss: 0.0811 - val_accuracy: 0.7772\n",
      "Epoch 247/300\n",
      "273/273 [==============================] - 85s 311ms/step - loss: 0.0846 - smart_square_abs_min_loss: 0.0846 - accuracy: 0.7194 - val_loss: 0.0755 - val_smart_square_abs_min_loss: 0.0755 - val_accuracy: 0.6663\n",
      "Epoch 248/300\n",
      "273/273 [==============================] - 80s 292ms/step - loss: 0.0809 - smart_square_abs_min_loss: 0.0809 - accuracy: 0.7224 - val_loss: 0.0840 - val_smart_square_abs_min_loss: 0.0840 - val_accuracy: 0.5837\n",
      "Epoch 249/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273/273 [==============================] - 85s 312ms/step - loss: 0.0799 - smart_square_abs_min_loss: 0.0799 - accuracy: 0.7038 - val_loss: 0.0577 - val_smart_square_abs_min_loss: 0.0577 - val_accuracy: 0.7026\n",
      "Epoch 250/300\n",
      "273/273 [==============================] - 82s 300ms/step - loss: 0.0692 - smart_square_abs_min_loss: 0.0692 - accuracy: 0.7754 - val_loss: 0.1073 - val_smart_square_abs_min_loss: 0.1073 - val_accuracy: 0.6542\n",
      "Epoch 251/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0668 - smart_square_abs_min_loss: 0.0668 - accuracy: 0.7518+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 252ms/step - loss: 0.0893 - smart_square_abs_min_loss: 0.0893 - accuracy: 0.6562\n",
      "Loss on test data:  0.08932576328516006\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[56.389214 35.737972 20.295755]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[20.923004   46.735527    0.10849267]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[15.583267 61.97579  50.677288]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 86s 316ms/step - loss: 0.0668 - smart_square_abs_min_loss: 0.0668 - accuracy: 0.7518 - val_loss: 0.0901 - val_smart_square_abs_min_loss: 0.0901 - val_accuracy: 0.7742\n",
      "Epoch 252/300\n",
      "273/273 [==============================] - 85s 311ms/step - loss: 0.0855 - smart_square_abs_min_loss: 0.0855 - accuracy: 0.6930 - val_loss: 0.0794 - val_smart_square_abs_min_loss: 0.0794 - val_accuracy: 0.6845\n",
      "Epoch 253/300\n",
      "273/273 [==============================] - 81s 295ms/step - loss: 0.0852 - smart_square_abs_min_loss: 0.0852 - accuracy: 0.6902 - val_loss: 0.1281 - val_smart_square_abs_min_loss: 0.1281 - val_accuracy: 0.5716\n",
      "Epoch 254/300\n",
      "273/273 [==============================] - 74s 269ms/step - loss: 0.0840 - smart_square_abs_min_loss: 0.0840 - accuracy: 0.6748 - val_loss: 0.0971 - val_smart_square_abs_min_loss: 0.0971 - val_accuracy: 0.6522\n",
      "Epoch 255/300\n",
      "273/273 [==============================] - 78s 287ms/step - loss: 0.0698 - smart_square_abs_min_loss: 0.0698 - accuracy: 0.7303 - val_loss: 0.0954 - val_smart_square_abs_min_loss: 0.0954 - val_accuracy: 0.6966\n",
      "Epoch 256/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0698 - smart_square_abs_min_loss: 0.0698 - accuracy: 0.7342+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 275ms/step - loss: 0.1124 - smart_square_abs_min_loss: 0.1124 - accuracy: 0.6875\n",
      "Loss on test data:  0.1124473586678505\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "predicted values [[57.87941  37.13997  20.943396]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[22.574444   43.139328   -0.30443275]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[17.719698 61.931038 51.721832]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 93s 341ms/step - loss: 0.0698 - smart_square_abs_min_loss: 0.0698 - accuracy: 0.7342 - val_loss: 0.0655 - val_smart_square_abs_min_loss: 0.0655 - val_accuracy: 0.6714\n",
      "Epoch 257/300\n",
      "273/273 [==============================] - 76s 278ms/step - loss: 0.0640 - smart_square_abs_min_loss: 0.0640 - accuracy: 0.7661 - val_loss: 0.1017 - val_smart_square_abs_min_loss: 0.1017 - val_accuracy: 0.6895\n",
      "Epoch 258/300\n",
      "273/273 [==============================] - 85s 311ms/step - loss: 0.0717 - smart_square_abs_min_loss: 0.0717 - accuracy: 0.7410 - val_loss: 0.0617 - val_smart_square_abs_min_loss: 0.0617 - val_accuracy: 0.7006\n",
      "Epoch 259/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0746 - smart_square_abs_min_loss: 0.0746 - accuracy: 0.7226 - val_loss: 0.0844 - val_smart_square_abs_min_loss: 0.0844 - val_accuracy: 0.6623\n",
      "Epoch 260/300\n",
      "273/273 [==============================] - 84s 309ms/step - loss: 0.0708 - smart_square_abs_min_loss: 0.0708 - accuracy: 0.7415 - val_loss: 0.0852 - val_smart_square_abs_min_loss: 0.0852 - val_accuracy: 0.6976\n",
      "Epoch 261/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0800 - smart_square_abs_min_loss: 0.0800 - accuracy: 0.7014+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 259ms/step - loss: 0.0858 - smart_square_abs_min_loss: 0.0858 - accuracy: 0.7137\n",
      "Loss on test data:  0.08584820479154587\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "predicted values [[59.15716  34.095966 17.569567]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[25.898643  45.435528   1.4649374]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[17.011166 63.76834  53.765713]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 94s 343ms/step - loss: 0.0800 - smart_square_abs_min_loss: 0.0800 - accuracy: 0.7014 - val_loss: 0.0807 - val_smart_square_abs_min_loss: 0.0807 - val_accuracy: 0.6704\n",
      "Epoch 262/300\n",
      "273/273 [==============================] - 83s 303ms/step - loss: 0.0675 - smart_square_abs_min_loss: 0.0675 - accuracy: 0.7668 - val_loss: 0.0721 - val_smart_square_abs_min_loss: 0.0721 - val_accuracy: 0.7490\n",
      "Epoch 263/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0792 - smart_square_abs_min_loss: 0.0792 - accuracy: 0.7173 - val_loss: 0.0836 - val_smart_square_abs_min_loss: 0.0836 - val_accuracy: 0.7198\n",
      "Epoch 264/300\n",
      "273/273 [==============================] - 84s 309ms/step - loss: 0.0723 - smart_square_abs_min_loss: 0.0723 - accuracy: 0.7430 - val_loss: 0.0605 - val_smart_square_abs_min_loss: 0.0605 - val_accuracy: 0.7581\n",
      "Epoch 265/300\n",
      "273/273 [==============================] - 81s 298ms/step - loss: 0.0690 - smart_square_abs_min_loss: 0.0690 - accuracy: 0.7684 - val_loss: 0.0984 - val_smart_square_abs_min_loss: 0.0984 - val_accuracy: 0.6280\n",
      "Epoch 266/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0751 - smart_square_abs_min_loss: 0.0751 - accuracy: 0.7168+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 262ms/step - loss: 0.0762 - smart_square_abs_min_loss: 0.0762 - accuracy: 0.6008\n",
      "Loss on test data:  0.07615235447883606\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[58.295765 34.279728 22.948748]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "predicted values [[25.145699   52.85442    -0.20336576]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[16.292307 62.348175 50.667507]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 93s 342ms/step - loss: 0.0751 - smart_square_abs_min_loss: 0.0751 - accuracy: 0.7168 - val_loss: 0.1077 - val_smart_square_abs_min_loss: 0.1077 - val_accuracy: 0.4698\n",
      "Epoch 267/300\n",
      "273/273 [==============================] - 79s 288ms/step - loss: 0.0697 - smart_square_abs_min_loss: 0.0697 - accuracy: 0.7616 - val_loss: 0.0635 - val_smart_square_abs_min_loss: 0.0635 - val_accuracy: 0.7843\n",
      "Epoch 268/300\n",
      "273/273 [==============================] - 84s 309ms/step - loss: 0.0818 - smart_square_abs_min_loss: 0.0818 - accuracy: 0.7302 - val_loss: 0.0748 - val_smart_square_abs_min_loss: 0.0748 - val_accuracy: 0.7560\n",
      "Epoch 269/300\n",
      "273/273 [==============================] - 78s 285ms/step - loss: 0.0841 - smart_square_abs_min_loss: 0.0841 - accuracy: 0.7086 - val_loss: 0.0816 - val_smart_square_abs_min_loss: 0.0816 - val_accuracy: 0.6845\n",
      "Epoch 270/300\n",
      "273/273 [==============================] - 76s 278ms/step - loss: 0.0734 - smart_square_abs_min_loss: 0.0734 - accuracy: 0.7680 - val_loss: 0.1293 - val_smart_square_abs_min_loss: 0.1293 - val_accuracy: 0.6603\n",
      "Epoch 271/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0578 - smart_square_abs_min_loss: 0.0578 - accuracy: 0.7664+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 274ms/step - loss: 0.0879 - smart_square_abs_min_loss: 0.0879 - accuracy: 0.6653\n",
      "Loss on test data:  0.08787421137094498\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "predicted values [[58.801327 37.944668 17.051054]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[23.88571   43.2644    -2.7359731]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[16.526426 62.035374 50.49974 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 88s 324ms/step - loss: 0.0578 - smart_square_abs_min_loss: 0.0578 - accuracy: 0.7664 - val_loss: 0.1112 - val_smart_square_abs_min_loss: 0.1112 - val_accuracy: 0.6129\n",
      "Epoch 272/300\n",
      "273/273 [==============================] - 82s 300ms/step - loss: 0.0863 - smart_square_abs_min_loss: 0.0863 - accuracy: 0.7188 - val_loss: 0.1297 - val_smart_square_abs_min_loss: 0.1297 - val_accuracy: 0.7097\n",
      "Epoch 273/300\n",
      "273/273 [==============================] - 80s 292ms/step - loss: 0.0768 - smart_square_abs_min_loss: 0.0768 - accuracy: 0.7360 - val_loss: 0.0705 - val_smart_square_abs_min_loss: 0.0705 - val_accuracy: 0.5504\n",
      "Epoch 274/300\n",
      "273/273 [==============================] - 76s 278ms/step - loss: 0.0770 - smart_square_abs_min_loss: 0.0770 - accuracy: 0.7223 - val_loss: 0.1405 - val_smart_square_abs_min_loss: 0.1405 - val_accuracy: 0.6462\n",
      "Epoch 275/300\n",
      "273/273 [==============================] - 84s 307ms/step - loss: 0.0802 - smart_square_abs_min_loss: 0.0802 - accuracy: 0.7138 - val_loss: 0.0858 - val_smart_square_abs_min_loss: 0.0858 - val_accuracy: 0.5897\n",
      "Epoch 276/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0664 - smart_square_abs_min_loss: 0.0664 - accuracy: 0.7671+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 272ms/step - loss: 0.0928 - smart_square_abs_min_loss: 0.0928 - accuracy: 0.5403\n",
      "Loss on test data:  0.09282714128494263\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[59.16422  37.918003 18.08932 ]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[25.11649   51.64384    1.4188235]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[17.95838  61.989765 51.83841 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 93s 339ms/step - loss: 0.0664 - smart_square_abs_min_loss: 0.0664 - accuracy: 0.7671 - val_loss: 0.0607 - val_smart_square_abs_min_loss: 0.0607 - val_accuracy: 0.6502\n",
      "Epoch 277/300\n",
      "273/273 [==============================] - 86s 314ms/step - loss: 0.0757 - smart_square_abs_min_loss: 0.0757 - accuracy: 0.7286 - val_loss: 0.0738 - val_smart_square_abs_min_loss: 0.0738 - val_accuracy: 0.7530\n",
      "Epoch 278/300\n",
      "273/273 [==============================] - 84s 309ms/step - loss: 0.0750 - smart_square_abs_min_loss: 0.0750 - accuracy: 0.7109 - val_loss: 0.1024 - val_smart_square_abs_min_loss: 0.1024 - val_accuracy: 0.7460\n",
      "Epoch 279/300\n",
      "273/273 [==============================] - 79s 288ms/step - loss: 0.0832 - smart_square_abs_min_loss: 0.0832 - accuracy: 0.7260 - val_loss: 0.0665 - val_smart_square_abs_min_loss: 0.0665 - val_accuracy: 0.6452\n",
      "Epoch 280/300\n",
      "273/273 [==============================] - 83s 304ms/step - loss: 0.0702 - smart_square_abs_min_loss: 0.0702 - accuracy: 0.7587 - val_loss: 0.0873 - val_smart_square_abs_min_loss: 0.0873 - val_accuracy: 0.5948\n",
      "Epoch 281/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0797 - smart_square_abs_min_loss: 0.0797 - accuracy: 0.7051+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 252ms/step - loss: 0.1109 - smart_square_abs_min_loss: 0.1109 - accuracy: 0.7369\n",
      "Loss on test data:  0.11085957288742065\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "predicted values [[59.852688 38.466038 20.98843 ]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "predicted values [[22.330803  52.121105   1.0503122]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[16.48048  61.966057 53.337128]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 91s 333ms/step - loss: 0.0797 - smart_square_abs_min_loss: 0.0797 - accuracy: 0.7051 - val_loss: 0.1291 - val_smart_square_abs_min_loss: 0.1291 - val_accuracy: 0.6411\n",
      "Epoch 282/300\n",
      "273/273 [==============================] - 78s 284ms/step - loss: 0.0750 - smart_square_abs_min_loss: 0.0750 - accuracy: 0.7445 - val_loss: 0.0952 - val_smart_square_abs_min_loss: 0.0952 - val_accuracy: 0.5464\n",
      "Epoch 283/300\n",
      "273/273 [==============================] - 78s 285ms/step - loss: 0.0751 - smart_square_abs_min_loss: 0.0751 - accuracy: 0.7268 - val_loss: 0.0962 - val_smart_square_abs_min_loss: 0.0962 - val_accuracy: 0.6966\n",
      "Epoch 284/300\n",
      "273/273 [==============================] - 85s 310ms/step - loss: 0.0730 - smart_square_abs_min_loss: 0.0730 - accuracy: 0.7399 - val_loss: 0.0700 - val_smart_square_abs_min_loss: 0.0700 - val_accuracy: 0.7268\n",
      "Epoch 285/300\n",
      "273/273 [==============================] - 77s 283ms/step - loss: 0.0823 - smart_square_abs_min_loss: 0.0823 - accuracy: 0.7429 - val_loss: 0.0649 - val_smart_square_abs_min_loss: 0.0649 - val_accuracy: 0.6552\n",
      "Epoch 286/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0668 - smart_square_abs_min_loss: 0.0668 - accuracy: 0.7708+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 263ms/step - loss: 0.1039 - smart_square_abs_min_loss: 0.1039 - accuracy: 0.6885\n",
      "Loss on test data:  0.10392377525568008\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted values [[58.56561  37.542156 17.561209]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[21.884407 49.86119   2.502888]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "predicted values [[16.83634  62.557278 49.720222]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 86s 315ms/step - loss: 0.0668 - smart_square_abs_min_loss: 0.0668 - accuracy: 0.7708 - val_loss: 0.0883 - val_smart_square_abs_min_loss: 0.0883 - val_accuracy: 0.7409\n",
      "Epoch 287/300\n",
      "273/273 [==============================] - 82s 299ms/step - loss: 0.0652 - smart_square_abs_min_loss: 0.0652 - accuracy: 0.7438 - val_loss: 0.0909 - val_smart_square_abs_min_loss: 0.0909 - val_accuracy: 0.7026\n",
      "Epoch 288/300\n",
      "273/273 [==============================] - 85s 311ms/step - loss: 0.0722 - smart_square_abs_min_loss: 0.0722 - accuracy: 0.7332 - val_loss: 0.0943 - val_smart_square_abs_min_loss: 0.0943 - val_accuracy: 0.5192\n",
      "Epoch 289/300\n",
      "273/273 [==============================] - 85s 311ms/step - loss: 0.0872 - smart_square_abs_min_loss: 0.0872 - accuracy: 0.6708 - val_loss: 0.1290 - val_smart_square_abs_min_loss: 0.1290 - val_accuracy: 0.7067\n",
      "Epoch 290/300\n",
      "273/273 [==============================] - 84s 309ms/step - loss: 0.0764 - smart_square_abs_min_loss: 0.0764 - accuracy: 0.7492 - val_loss: 0.1099 - val_smart_square_abs_min_loss: 0.1099 - val_accuracy: 0.6492\n",
      "Epoch 291/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273/273 [==============================] - ETA: 0s - loss: 0.0790 - smart_square_abs_min_loss: 0.0790 - accuracy: 0.7558+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 279ms/step - loss: 0.0869 - smart_square_abs_min_loss: 0.0869 - accuracy: 0.7752\n",
      "Loss on test data:  0.08688931167125702\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "predicted values [[57.609135 37.620407 20.482655]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[24.456833 51.392647  0.56443 ]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[15.728523 62.757725 51.511368]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 89s 325ms/step - loss: 0.0790 - smart_square_abs_min_loss: 0.0790 - accuracy: 0.7558 - val_loss: 0.0848 - val_smart_square_abs_min_loss: 0.0848 - val_accuracy: 0.8105\n",
      "Epoch 292/300\n",
      "273/273 [==============================] - 84s 309ms/step - loss: 0.0920 - smart_square_abs_min_loss: 0.0920 - accuracy: 0.7184 - val_loss: 0.0717 - val_smart_square_abs_min_loss: 0.0717 - val_accuracy: 0.7087\n",
      "Epoch 293/300\n",
      "273/273 [==============================] - 78s 284ms/step - loss: 0.0816 - smart_square_abs_min_loss: 0.0816 - accuracy: 0.7345 - val_loss: 0.1139 - val_smart_square_abs_min_loss: 0.1139 - val_accuracy: 0.6048\n",
      "Epoch 294/300\n",
      "273/273 [==============================] - 75s 276ms/step - loss: 0.0730 - smart_square_abs_min_loss: 0.0730 - accuracy: 0.7355 - val_loss: 0.0832 - val_smart_square_abs_min_loss: 0.0832 - val_accuracy: 0.8105\n",
      "Epoch 295/300\n",
      "273/273 [==============================] - 78s 285ms/step - loss: 0.0665 - smart_square_abs_min_loss: 0.0665 - accuracy: 0.7592 - val_loss: 0.0899 - val_smart_square_abs_min_loss: 0.0899 - val_accuracy: 0.5696\n",
      "Epoch 296/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0764 - smart_square_abs_min_loss: 0.0764 - accuracy: 0.7373+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 256ms/step - loss: 0.0994 - smart_square_abs_min_loss: 0.0994 - accuracy: 0.6119\n",
      "Loss on test data:  0.09935347735881805\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[61.552914 38.468006 22.77435 ]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[19.30653    39.58048    -0.35684377]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[15.55045 61.67342 51.67286]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 88s 323ms/step - loss: 0.0764 - smart_square_abs_min_loss: 0.0764 - accuracy: 0.7373 - val_loss: 0.1115 - val_smart_square_abs_min_loss: 0.1115 - val_accuracy: 0.6462\n",
      "Epoch 297/300\n",
      "273/273 [==============================] - 83s 304ms/step - loss: 0.0720 - smart_square_abs_min_loss: 0.0720 - accuracy: 0.7521 - val_loss: 0.0850 - val_smart_square_abs_min_loss: 0.0850 - val_accuracy: 0.6754\n",
      "Epoch 298/300\n",
      "273/273 [==============================] - 85s 312ms/step - loss: 0.0714 - smart_square_abs_min_loss: 0.0714 - accuracy: 0.7477 - val_loss: 0.0874 - val_smart_square_abs_min_loss: 0.0874 - val_accuracy: 0.7097\n",
      "Epoch 299/300\n",
      "273/273 [==============================] - 78s 284ms/step - loss: 0.0797 - smart_square_abs_min_loss: 0.0797 - accuracy: 0.7168 - val_loss: 0.0773 - val_smart_square_abs_min_loss: 0.0773 - val_accuracy: 0.7056\n",
      "Epoch 300/300\n",
      "273/273 [==============================] - 84s 309ms/step - loss: 0.0800 - smart_square_abs_min_loss: 0.0800 - accuracy: 0.6993 - val_loss: 0.1030 - val_smart_square_abs_min_loss: 0.1030 - val_accuracy: 0.6613\n"
     ]
    }
   ],
   "source": [
    "######################################################################    \n",
    "##################### Compile and run the model ######################    \n",
    "###################################################################### \n",
    "model.compile(optimizer = RMSprop(learning_rate=0.0005),\n",
    "              loss = smart_square_abs_min_loss, \n",
    "              metrics = [smart_square_abs_min_loss, \"accuracy\"])  # Add run_eagerly=True to enable the numpy debugging\n",
    "\n",
    "tg = datagenerator(32, (input_size,input_size), train_df, 1, 3)\n",
    "vg = datagenerator(32, (input_size,input_size), valid_df, 1, 3)\n",
    "history = model.fit(x=tg,\n",
    "                    batch_size=32,\n",
    "                    epochs=300,\n",
    "                    validation_data=vg,\n",
    "                    callbacks=[LossHistory()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629ab4d4",
   "metadata": {},
   "source": [
    "# Working with results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80de1989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### PREDICTIONS ###############\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted values [[59.638927 39.53463  18.651701]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[24.140837  52.33951    1.8040062]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[15.847041 62.319023 52.42989 ]]\n",
      "----------3----------\n",
      "phi1 17.5\n",
      "PHI 15.5\n",
      "phi2 50.4\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[13.113621 19.107594 51.722668]]\n",
      "----------4----------\n",
      "phi1 47.5\n",
      "PHI 32.6\n",
      "phi2 29.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[46.656322 34.714622 31.907097]]\n",
      "----------5----------\n",
      "phi1 33.3\n",
      "PHI 39.6\n",
      "phi2 28.5\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[35.325314 42.7002   29.59262 ]]\n",
      "----------6----------\n",
      "phi1 60.8\n",
      "PHI 28.2\n",
      "phi2 9.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[58.71791  28.91733  11.064791]]\n",
      "----------7----------\n",
      "phi1 26.6\n",
      "PHI 6.8\n",
      "phi2 75.8\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[26.802258   4.3823185 79.281105 ]]\n",
      "----------8----------\n",
      "phi1 39.3\n",
      "PHI 40.9\n",
      "phi2 7.6\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[40.255993  42.561485   3.1467261]]\n",
      "----------9----------\n",
      "phi1 3.9\n",
      "PHI 87.4\n",
      "phi2 25.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[ 2.6693506 82.27547   30.712479 ]]\n",
      "############### PREDICTIONS ###############\n",
      "31/31 [==============================] - 9s 276ms/step - loss: 0.0989 - smart_square_abs_min_loss: 0.0989 - accuracy: 0.6623\n"
     ]
    }
   ],
   "source": [
    "######################################################################    \n",
    "################# Predict few values for visibility ##################    \n",
    "######################################################################\n",
    "def prdict_and_print(nr):\n",
    "    t = test_df.values[nr][1]\n",
    "    data = load_img(path = t, grayscale = True)\n",
    "    data = tf.keras.utils.img_to_array(data, data_format=\"channels_last\", dtype=\"float32\")\n",
    "    data /= 255\n",
    "    data.shape = (1,) + data.shape\n",
    "    X = np.asarray(data)\n",
    "    print(\"----------{}----------\".format(nr))\n",
    "    euler = t.split(\"_\")\n",
    "    print(\"phi1\", float(euler[3]))\n",
    "    print(\"PHI\",   float(euler[4]))\n",
    "    print(\"phi2\",  float(euler[5][:-4]))\n",
    "    yhat = model.predict(data)\n",
    "    print(\"predicted values\", yhat*90)\n",
    "    \n",
    "print(\"############### PREDICTIONS ###############\")\n",
    "for i in range(10):\n",
    "    prdict_and_print(i)\n",
    "print(\"############### PREDICTIONS ###############\")\n",
    "\n",
    "######################################################################    \n",
    "########################## Evaluate the mode #########################    \n",
    "######################################################################\n",
    "model_e = model.evaluate(test_g, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16593473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "######################################################################    \n",
    "################## Plotting accuracy and loss graph ##################    \n",
    "###################################################################### \n",
    "def plot_accuracy_loss(history, name):\n",
    "    \"\"\"\n",
    "        Plot the accuracy and the loss during the training of the nn.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(12,5))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(221)\n",
    "    plt.plot(history.history['accuracy'],'bo--', label = \"acc\")\n",
    "    plt.plot(history.history['val_accuracy'],'ro--', label = \"val_accuracy\")\n",
    "    plt.title(\"train_acc vs val_acc\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot loss function\n",
    "    plt.subplot(222)\n",
    "    plt.plot(history.history['loss'],'bo--', label = \"loss\")\n",
    "    plt.plot(history.history['val_loss'],'ro--', label = \"val_loss\")\n",
    "    plt.title(\"train_loss vs val_loss\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "\n",
    "    plt.legend()\n",
    "    \n",
    "plot_accuracy_loss(history, \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de24180",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################    \n",
    "############################ Saving model ############################    \n",
    "######################################################################\n",
    "model_name = \"Best_model_so_far_abs_loss_function_RMSprop\"\n",
    "model.save(\"Models/{}.h5\".format(model_name), save_format = 'h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353e7440",
   "metadata": {},
   "source": [
    "# Experiments with automating the load of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e80705",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################    \n",
    "##################### Loading a model from a file ####################    \n",
    "###################################################################### \n",
    "with CustomObjectScope({'abs_loss_function': square_abs_min_loss}):\n",
    "    model = keras.models.load_model('Models/3db071e0968f11ed81960894ef90a55a_model_adam_001.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348f3e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################    \n",
    "###################### Define models as functions ####################    \n",
    "###################################################################### \n",
    "def load_model_a():\n",
    "    inputs = keras.Input(shape=(input_size, input_size, 1))\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=4)(x)\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=4)(x)\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=4)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dense(16, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(3)(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_model_b():\n",
    "    inputs = keras.Input(shape=(input_size, input_size, 1))\n",
    "    x = layers.Conv2D(filters=16, kernel_size=11, activation=\"relu\")(inputs)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=7, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=5, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dense(16, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(3)(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "def load_model_c():\n",
    "    inputs = keras.Input(shape=(input_size, input_size, 1))\n",
    "    x = layers.Conv2D(filters=16, kernel_size=11, activation=\"relu\")(inputs)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=7, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=5, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.01))(x)\n",
    "    x = layers.Dense(16, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.01))(x) \n",
    "    outputs = layers.Dense(3)(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def plot_accuracy_loss(history):\n",
    "    \"\"\"\n",
    "        Plot the accuracy and the loss during the training of the nn.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(12,5))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(221)\n",
    "    plt.plot(history.history['accuracy'],'bo--', label = \"acc\")\n",
    "    plt.plot(history.history['val_accuracy'],'ro--', label = \"val_accuracy\")\n",
    "    plt.title(\"train_acc vs val_acc\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot loss function\n",
    "    plt.subplot(222)\n",
    "    plt.plot(history.history['loss'],'bo--', label = \"loss\")\n",
    "    plt.plot(history.history['val_loss'],'ro--', label = \"val_loss\")\n",
    "    plt.title(\"train_loss vs val_loss\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "def load_and_train_model(model, epochs = 100, loss_func = abs_loss_function):\n",
    "    tg = datagenerator(32, (input_size,input_size), train_df, 1, 3)\n",
    "    vg = datagenerator(32, (input_size,input_size), valid_df, 1, 3)\n",
    "    model.compile(optimizer = RMSprop(learning_rate=0.001),\n",
    "                  loss = loss_func, \n",
    "                  metrics = [\"accuracy\", loss_func])  # Add run_eagerly=True to enable the numpy debugging\n",
    "    \n",
    "    history = model.fit(x=tg,\n",
    "                        batch_size=32,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=vg)\n",
    "    \n",
    "    \n",
    "    plot_accuracy_loss(history)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d98e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################    \n",
    "################# Loading models and tunning them ####################    \n",
    "######################################################################\n",
    "model_a = load_model_a()\n",
    "model_a.summary()\n",
    "history_a = load_and_train_model(model_a, 100, abs_loss_function)\n",
    "model_b = load_model_b()\n",
    "model_b.summary()\n",
    "history_b = load_and_train_model(model_a, 100, abs_loss_function)\n",
    "model_c = load_model_c()\n",
    "model_c.summary()\n",
    "history_c = load_and_train_model(model_c, 100, abs_loss_function)\n",
    "plot_accuracy_loss(history_a)\n",
    "plot_accuracy_loss(history_b)\n",
    "plot_accuracy_loss(history_c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
