/zhome/ab/7/153983/.lsbatch/1673718142.15187396.shell: line 21: cd: project: No such file or directory
Loaded dependency [python3/3.10.7]: gcc/11.3.0-binutils-2.38
Loaded module: python3/3.10.7

Loading python3/3.10.7
  Loading requirement: gcc/11.3.0-binutils-2.38
Loaded module: cuda/12.0
Loaded module: cudnn/v8.3.2.44-prod-cuda-11.X
Loaded module: cuda/12.0
2023-01-14 21:03:01.529498: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-01-14 21:03:01.723351: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /appl/cuda/12.0.0/lib64:/appl/cudnn/v8.3.2.44-prod-cuda-11.5/lib:/appl/python/3.10.7/lib:/appl/gcc/11.3.0-binutils-2.38/lib64:/appl/gcc/11.3.0-binutils-2.38/lib:/lsf/10.1/linux3.10-glibc2.17-x86_64/lib
2023-01-14 21:03:01.723384: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2023-01-14 21:03:03.156826: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /appl/cuda/12.0.0/lib64:/appl/cudnn/v8.3.2.44-prod-cuda-11.5/lib:/appl/python/3.10.7/lib:/appl/gcc/11.3.0-binutils-2.38/lib64:/appl/gcc/11.3.0-binutils-2.38/lib:/lsf/10.1/linux3.10-glibc2.17-x86_64/lib
2023-01-14 21:03:03.157557: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /appl/cuda/12.0.0/lib64:/appl/cudnn/v8.3.2.44-prod-cuda-11.5/lib:/appl/python/3.10.7/lib:/appl/gcc/11.3.0-binutils-2.38/lib64:/appl/gcc/11.3.0-binutils-2.38/lib:/lsf/10.1/linux3.10-glibc2.17-x86_64/lib
2023-01-14 21:03:03.157571: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-01-14 21:03:06.466222: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /appl/cuda/12.0.0/lib64:/appl/cudnn/v8.3.2.44-prod-cuda-11.5/lib:/appl/python/3.10.7/lib:/appl/gcc/11.3.0-binutils-2.38/lib64:/appl/gcc/11.3.0-binutils-2.38/lib:/lsf/10.1/linux3.10-glibc2.17-x86_64/lib
2023-01-14 21:03:06.466922: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /appl/cuda/12.0.0/lib64:/appl/cudnn/v8.3.2.44-prod-cuda-11.5/lib:/appl/python/3.10.7/lib:/appl/gcc/11.3.0-binutils-2.38/lib64:/appl/gcc/11.3.0-binutils-2.38/lib:/lsf/10.1/linux3.10-glibc2.17-x86_64/lib
2023-01-14 21:03:06.467387: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /appl/cuda/12.0.0/lib64:/appl/cudnn/v8.3.2.44-prod-cuda-11.5/lib:/appl/python/3.10.7/lib:/appl/gcc/11.3.0-binutils-2.38/lib64:/appl/gcc/11.3.0-binutils-2.38/lib:/lsf/10.1/linux3.10-glibc2.17-x86_64/lib
2023-01-14 21:03:06.467883: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /appl/cuda/12.0.0/lib64:/appl/cudnn/v8.3.2.44-prod-cuda-11.5/lib:/appl/python/3.10.7/lib:/appl/gcc/11.3.0-binutils-2.38/lib64:/appl/gcc/11.3.0-binutils-2.38/lib:/lsf/10.1/linux3.10-glibc2.17-x86_64/lib
2023-01-14 21:03:06.501448: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /appl/cuda/12.0.0/lib64:/appl/cudnn/v8.3.2.44-prod-cuda-11.5/lib:/appl/python/3.10.7/lib:/appl/gcc/11.3.0-binutils-2.38/lib64:/appl/gcc/11.3.0-binutils-2.38/lib:/lsf/10.1/linux3.10-glibc2.17-x86_64/lib
2023-01-14 21:03:06.501935: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2023-01-14 21:03:06.503200: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Epochs:  100
Optimizer:  <keras.optimizers.optimizer_experimental.adam.Adam object at 0x7f7bb6f56920>
Metrics:  ['accuracy', <keras.metrics.metrics.MeanSquaredError object at 0x7f7bb5247250>]
Loss function name:  square_abs_min_loss
Csv file used:  black_background_500x500.csv
Verbose:  2
Unique name:  _layer_norm_
 ################ MODEL ############### 
 
inputs = keras.Input(shape=(input_size, input_size, 1))
x = layers.Conv2D(filters=32, kernel_size=3, activation="relu")(inputs)
x = layers.Conv2D(filters=32, kernel_size=3, activation="relu")(inputs)
x = layers.MaxPooling2D(pool_size=4)(x)
x = layers.Conv2D(filters=32, kernel_size=3, activation="relu")(x)
x = layers.Conv2D(filters=32, kernel_size=3, activation="relu")(inputs)
x = layers.MaxPooling2D(pool_size=4)(x)
x = layers.Conv2D(filters=32, kernel_size=3, activation="relu")(x)
x = layers.Conv2D(filters=32, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=4)(x)
x = layers.Conv2D(filters=32, kernel_size=3, activation="relu")(x)
x = layers.MaxPooling2D(pool_size=4)(x)
x = layers.Flatten()(x)
x = layers.Dense(128, activation="relu")(x)
x = layers.LayerNormalization(axis=1)(x)
# x = layers.Dropout(0.5)(x)
x = layers.Dense(16, activation="relu")(x)
x = layers.LayerNormalization(axis=1)(x)
# x = layers.Dropout(0.25)(x)
outputs = layers.Dense(3)(x)

Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 500, 500, 1)]     0         
                                                                 
 conv2d_3 (Conv2D)           (None, 498, 498, 32)      320       
                                                                 
 max_pooling2d_1 (MaxPooling  (None, 124, 124, 32)     0         
 2D)                                                             
                                                                 
 conv2d_4 (Conv2D)           (None, 122, 122, 32)      9248      
                                                                 
 conv2d_5 (Conv2D)           (None, 120, 120, 32)      9248      
                                                                 
 max_pooling2d_2 (MaxPooling  (None, 30, 30, 32)       0         
 2D)                                                             
                                                                 
 conv2d_6 (Conv2D)           (None, 28, 28, 32)        9248      
                                                                 
 max_pooling2d_3 (MaxPooling  (None, 7, 7, 32)         0         
 2D)                                                             
                                                                 
 flatten (Flatten)           (None, 1568)              0         
                                                                 
 dense (Dense)               (None, 128)               200832    
                                                                 
 layer_normalization (LayerN  (None, 128)              256       
 ormalization)                                                   
                                                                 
 dense_1 (Dense)             (None, 16)                2064      
                                                                 
 layer_normalization_1 (Laye  (None, 16)               32        
 rNormalization)                                                 
                                                                 
 dense_2 (Dense)             (None, 3)                 51        
                                                                 
=================================================================
Total params: 231,299
Trainable params: 231,299
Non-trainable params: 0
_________________________________________________________________
/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/utils/image_utils.py:409: UserWarning: grayscale is deprecated. Please use color_mode = "grayscale"
  warnings.warn(
Epoch 1/100
273/273 - 519s - loss: 0.0749 - accuracy: 0.3126 - mean_squared_error: 0.5777 - val_loss: 0.0789 - val_accuracy: 0.3558 - val_mean_squared_error: 0.4410 - 519s/epoch - 2s/step
Epoch 2/100
273/273 - 534s - loss: 0.0681 - accuracy: 0.3198 - mean_squared_error: 0.4457 - val_loss: 0.0764 - val_accuracy: 0.3599 - val_mean_squared_error: 0.7585 - 534s/epoch - 2s/step
Epoch 3/100
273/273 - 511s - loss: 0.0635 - accuracy: 0.2935 - mean_squared_error: 0.6557 - val_loss: 0.0638 - val_accuracy: 0.2692 - val_mean_squared_error: 0.8077 - 511s/epoch - 2s/step
Epoch 4/100
273/273 - 511s - loss: 0.0670 - accuracy: 0.3139 - mean_squared_error: 0.5574 - val_loss: 0.0754 - val_accuracy: 0.4385 - val_mean_squared_error: 0.5432 - 511s/epoch - 2s/step
Epoch 5/100
273/273 - 509s - loss: 0.0641 - accuracy: 0.3016 - mean_squared_error: 0.4797 - val_loss: 0.0646 - val_accuracy: 0.3831 - val_mean_squared_error: 0.5449 - 509s/epoch - 2s/step
Epoch 6/100
273/273 - 511s - loss: 0.0688 - accuracy: 0.3071 - mean_squared_error: 0.4709 - val_loss: 0.0702 - val_accuracy: 0.3357 - val_mean_squared_error: 0.5926 - 511s/epoch - 2s/step
Epoch 7/100
273/273 - 509s - loss: 0.0639 - accuracy: 0.2966 - mean_squared_error: 0.4371 - val_loss: 0.0590 - val_accuracy: 0.1855 - val_mean_squared_error: 0.4565 - 509s/epoch - 2s/step
Epoch 8/100
273/273 - 516s - loss: 0.0638 - accuracy: 0.2732 - mean_squared_error: 0.3511 - val_loss: 0.0748 - val_accuracy: 0.2681 - val_mean_squared_error: 0.3821 - 516s/epoch - 2s/step
Epoch 9/100
273/273 - 516s - loss: 0.0633 - accuracy: 0.3063 - mean_squared_error: 0.4267 - val_loss: 0.0633 - val_accuracy: 0.2601 - val_mean_squared_error: 0.4526 - 516s/epoch - 2s/step
Epoch 10/100
273/273 - 513s - loss: 0.0643 - accuracy: 0.3261 - mean_squared_error: 0.3901 - val_loss: 0.0677 - val_accuracy: 0.3780 - val_mean_squared_error: 0.3192 - 513s/epoch - 2s/step
Epoch 11/100
273/273 - 510s - loss: 0.0662 - accuracy: 0.3300 - mean_squared_error: 0.2446 - val_loss: 0.0671 - val_accuracy: 0.3417 - val_mean_squared_error: 0.1693 - 510s/epoch - 2s/step
Epoch 12/100
273/273 - 510s - loss: 0.0651 - accuracy: 0.3716 - mean_squared_error: 0.2917 - val_loss: 0.0645 - val_accuracy: 0.5292 - val_mean_squared_error: 0.2207 - 510s/epoch - 2s/step
Epoch 13/100
273/273 - 517s - loss: 0.0647 - accuracy: 0.3470 - mean_squared_error: 0.2834 - val_loss: 0.0719 - val_accuracy: 0.3730 - val_mean_squared_error: 0.1899 - 517s/epoch - 2s/step
Epoch 14/100
273/273 - 516s - loss: 0.0672 - accuracy: 0.3497 - mean_squared_error: 0.1609 - val_loss: 0.0774 - val_accuracy: 0.2581 - val_mean_squared_error: 0.1421 - 516s/epoch - 2s/step
Epoch 15/100
273/273 - 516s - loss: 0.0664 - accuracy: 0.3506 - mean_squared_error: 0.4092 - val_loss: 0.0680 - val_accuracy: 0.3508 - val_mean_squared_error: 0.5113 - 516s/epoch - 2s/step
Epoch 16/100
273/273 - 517s - loss: 0.0657 - accuracy: 0.3352 - mean_squared_error: 0.3485 - val_loss: 0.0736 - val_accuracy: 0.3619 - val_mean_squared_error: 0.2577 - 517s/epoch - 2s/step
Epoch 17/100
273/273 - 518s - loss: 0.0678 - accuracy: 0.3203 - mean_squared_error: 0.2626 - val_loss: 0.0721 - val_accuracy: 0.2812 - val_mean_squared_error: 0.2124 - 518s/epoch - 2s/step
Epoch 18/100
273/273 - 518s - loss: 0.0686 - accuracy: 0.3252 - mean_squared_error: 0.4655 - val_loss: 0.0719 - val_accuracy: 0.3417 - val_mean_squared_error: 0.3462 - 518s/epoch - 2s/step
Epoch 19/100
273/273 - 516s - loss: 0.0632 - accuracy: 0.2966 - mean_squared_error: 0.3256 - val_loss: 0.0712 - val_accuracy: 0.3871 - val_mean_squared_error: 0.2300 - 516s/epoch - 2s/step
Epoch 20/100
273/273 - 515s - loss: 0.0652 - accuracy: 0.3107 - mean_squared_error: 0.2718 - val_loss: 0.0783 - val_accuracy: 0.3760 - val_mean_squared_error: 0.1901 - 515s/epoch - 2s/step
Epoch 21/100
273/273 - 516s - loss: 0.0642 - accuracy: 0.3172 - mean_squared_error: 0.3080 - val_loss: 0.0624 - val_accuracy: 0.4224 - val_mean_squared_error: 0.3319 - 516s/epoch - 2s/step
Epoch 22/100
273/273 - 516s - loss: 0.0637 - accuracy: 0.3589 - mean_squared_error: 0.4762 - val_loss: 0.0792 - val_accuracy: 0.2681 - val_mean_squared_error: 0.4538 - 516s/epoch - 2s/step
Epoch 23/100
273/273 - 516s - loss: 0.0673 - accuracy: 0.3499 - mean_squared_error: 0.3603 - val_loss: 0.0710 - val_accuracy: 0.4093 - val_mean_squared_error: 0.3334 - 516s/epoch - 2s/step
Epoch 24/100
273/273 - 515s - loss: 0.0623 - accuracy: 0.3615 - mean_squared_error: 0.2750 - val_loss: 0.0757 - val_accuracy: 0.2933 - val_mean_squared_error: 0.2935 - 515s/epoch - 2s/step
Epoch 25/100
273/273 - 516s - loss: 0.0634 - accuracy: 0.3385 - mean_squared_error: 0.2571 - val_loss: 0.0607 - val_accuracy: 0.3750 - val_mean_squared_error: 0.2713 - 516s/epoch - 2s/step
Epoch 26/100
273/273 - 516s - loss: 0.0656 - accuracy: 0.3561 - mean_squared_error: 0.3672 - val_loss: 0.0596 - val_accuracy: 0.4325 - val_mean_squared_error: 0.4408 - 516s/epoch - 2s/step
Epoch 27/100
273/273 - 516s - loss: 0.0651 - accuracy: 0.2926 - mean_squared_error: 0.4616 - val_loss: 0.0742 - val_accuracy: 0.3558 - val_mean_squared_error: 0.5442 - 516s/epoch - 2s/step
Epoch 28/100
273/273 - 516s - loss: 0.0650 - accuracy: 0.3027 - mean_squared_error: 0.4809 - val_loss: 0.0659 - val_accuracy: 0.3599 - val_mean_squared_error: 0.4653 - 516s/epoch - 2s/step
Epoch 29/100
273/273 - 517s - loss: 0.0639 - accuracy: 0.3435 - mean_squared_error: 0.6309 - val_loss: 0.0731 - val_accuracy: 0.3710 - val_mean_squared_error: 0.5808 - 517s/epoch - 2s/step
Epoch 30/100
273/273 - 516s - loss: 0.0657 - accuracy: 0.3237 - mean_squared_error: 0.3446 - val_loss: 0.0768 - val_accuracy: 0.3992 - val_mean_squared_error: 0.3005 - 516s/epoch - 2s/step
Epoch 31/100
273/273 - 516s - loss: 0.0618 - accuracy: 0.3217 - mean_squared_error: 0.6778 - val_loss: 0.0638 - val_accuracy: 0.3508 - val_mean_squared_error: 0.7195 - 516s/epoch - 2s/step
Epoch 32/100
273/273 - 516s - loss: 0.0638 - accuracy: 0.3134 - mean_squared_error: 0.4726 - val_loss: 0.0682 - val_accuracy: 0.3095 - val_mean_squared_error: 0.3997 - 516s/epoch - 2s/step
Epoch 33/100
273/273 - 516s - loss: 0.0671 - accuracy: 0.3391 - mean_squared_error: 0.4964 - val_loss: 0.0644 - val_accuracy: 0.4536 - val_mean_squared_error: 0.4787 - 516s/epoch - 2s/step
Epoch 34/100
273/273 - 516s - loss: 0.0653 - accuracy: 0.3109 - mean_squared_error: 0.2393 - val_loss: 0.0759 - val_accuracy: 0.2994 - val_mean_squared_error: 0.2081 - 516s/epoch - 2s/step
Epoch 35/100
273/273 - 514s - loss: 0.0637 - accuracy: 0.3337 - mean_squared_error: 0.1769 - val_loss: 0.0757 - val_accuracy: 0.3760 - val_mean_squared_error: 0.1567 - 514s/epoch - 2s/step
Epoch 36/100
273/273 - 509s - loss: 0.0650 - accuracy: 0.3261 - mean_squared_error: 0.2382 - val_loss: 0.0683 - val_accuracy: 0.3075 - val_mean_squared_error: 0.2098 - 509s/epoch - 2s/step
Epoch 37/100
273/273 - 508s - loss: 0.0640 - accuracy: 0.3141 - mean_squared_error: 0.4743 - val_loss: 0.0679 - val_accuracy: 0.2964 - val_mean_squared_error: 0.4587 - 508s/epoch - 2s/step
Epoch 38/100
273/273 - 508s - loss: 0.0666 - accuracy: 0.3376 - mean_squared_error: 0.3762 - val_loss: 0.0667 - val_accuracy: 0.4052 - val_mean_squared_error: 0.3350 - 508s/epoch - 2s/step
Epoch 39/100
273/273 - 509s - loss: 0.0664 - accuracy: 0.3196 - mean_squared_error: 0.5077 - val_loss: 0.0740 - val_accuracy: 0.4002 - val_mean_squared_error: 0.4253 - 509s/epoch - 2s/step
Epoch 40/100
273/273 - 511s - loss: 0.0615 - accuracy: 0.2774 - mean_squared_error: 0.4115 - val_loss: 0.0746 - val_accuracy: 0.4183 - val_mean_squared_error: 0.3354 - 511s/epoch - 2s/step
Epoch 41/100
273/273 - 510s - loss: 0.0659 - accuracy: 0.3179 - mean_squared_error: 0.4448 - val_loss: 0.0756 - val_accuracy: 0.3760 - val_mean_squared_error: 0.5883 - 510s/epoch - 2s/step
Epoch 42/100
273/273 - 520s - loss: 0.0677 - accuracy: 0.3096 - mean_squared_error: 0.6343 - val_loss: 0.0646 - val_accuracy: 0.4214 - val_mean_squared_error: 0.7044 - 520s/epoch - 2s/step
Epoch 43/100
273/273 - 529s - loss: 0.0631 - accuracy: 0.3259 - mean_squared_error: 0.6430 - val_loss: 0.0744 - val_accuracy: 0.2812 - val_mean_squared_error: 0.5582 - 529s/epoch - 2s/step
Epoch 44/100
273/273 - 531s - loss: 0.0626 - accuracy: 0.3150 - mean_squared_error: 0.2969 - val_loss: 0.0648 - val_accuracy: 0.2984 - val_mean_squared_error: 0.3030 - 531s/epoch - 2s/step
Epoch 45/100
273/273 - 530s - loss: 0.0669 - accuracy: 0.2888 - mean_squared_error: 0.3005 - val_loss: 0.0652 - val_accuracy: 0.2671 - val_mean_squared_error: 0.2972 - 530s/epoch - 2s/step
Epoch 46/100
273/273 - 531s - loss: 0.0649 - accuracy: 0.3261 - mean_squared_error: 0.2969 - val_loss: 0.0679 - val_accuracy: 0.4073 - val_mean_squared_error: 0.2693 - 531s/epoch - 2s/step
Epoch 47/100
273/273 - 531s - loss: 0.0677 - accuracy: 0.3025 - mean_squared_error: 0.5399 - val_loss: 0.0616 - val_accuracy: 0.2117 - val_mean_squared_error: 0.4390 - 531s/epoch - 2s/step
Epoch 48/100
273/273 - 530s - loss: 0.0655 - accuracy: 0.2908 - mean_squared_error: 0.5317 - val_loss: 0.0769 - val_accuracy: 0.3347 - val_mean_squared_error: 0.5201 - 530s/epoch - 2s/step
Epoch 49/100
273/273 - 529s - loss: 0.0657 - accuracy: 0.3515 - mean_squared_error: 0.2935 - val_loss: 0.0649 - val_accuracy: 0.3790 - val_mean_squared_error: 0.2086 - 529s/epoch - 2s/step
Epoch 50/100
273/273 - 529s - loss: 0.0663 - accuracy: 0.3314 - mean_squared_error: 0.2440 - val_loss: 0.0723 - val_accuracy: 0.2681 - val_mean_squared_error: 0.2269 - 529s/epoch - 2s/step
Epoch 51/100
273/273 - 529s - loss: 0.0641 - accuracy: 0.3280 - mean_squared_error: 0.4848 - val_loss: 0.0709 - val_accuracy: 0.4163 - val_mean_squared_error: 0.6135 - 529s/epoch - 2s/step
Epoch 52/100
273/273 - 530s - loss: 0.0630 - accuracy: 0.3522 - mean_squared_error: 0.6978 - val_loss: 0.0704 - val_accuracy: 0.2046 - val_mean_squared_error: 0.5886 - 530s/epoch - 2s/step
Epoch 53/100
273/273 - 529s - loss: 0.0633 - accuracy: 0.3519 - mean_squared_error: 0.5213 - val_loss: 0.0619 - val_accuracy: 0.3085 - val_mean_squared_error: 0.5035 - 529s/epoch - 2s/step
Epoch 54/100
273/273 - 530s - loss: 0.0662 - accuracy: 0.3498 - mean_squared_error: 0.4315 - val_loss: 0.0684 - val_accuracy: 0.2883 - val_mean_squared_error: 0.3319 - 530s/epoch - 2s/step
Epoch 55/100
273/273 - 530s - loss: 0.0648 - accuracy: 0.3101 - mean_squared_error: 0.3717 - val_loss: 0.0748 - val_accuracy: 0.4435 - val_mean_squared_error: 0.4169 - 530s/epoch - 2s/step
Epoch 56/100
273/273 - 530s - loss: 0.0633 - accuracy: 0.3383 - mean_squared_error: 0.3840 - val_loss: 0.0711 - val_accuracy: 0.3800 - val_mean_squared_error: 0.2789 - 530s/epoch - 2s/step
Epoch 57/100
273/273 - 530s - loss: 0.0631 - accuracy: 0.3049 - mean_squared_error: 0.5776 - val_loss: 0.0667 - val_accuracy: 0.4476 - val_mean_squared_error: 0.5189 - 530s/epoch - 2s/step
Epoch 58/100
273/273 - 531s - loss: 0.0678 - accuracy: 0.3392 - mean_squared_error: 0.5807 - val_loss: 0.0666 - val_accuracy: 0.3276 - val_mean_squared_error: 0.6398 - 531s/epoch - 2s/step
Epoch 59/100
273/273 - 531s - loss: 0.0669 - accuracy: 0.3403 - mean_squared_error: 0.3730 - val_loss: 0.0770 - val_accuracy: 0.3054 - val_mean_squared_error: 0.3268 - 531s/epoch - 2s/step
Epoch 60/100
273/273 - 531s - loss: 0.0665 - accuracy: 0.3237 - mean_squared_error: 0.1756 - val_loss: 0.0657 - val_accuracy: 0.3216 - val_mean_squared_error: 0.1956 - 531s/epoch - 2s/step
Epoch 61/100
273/273 - 531s - loss: 0.0654 - accuracy: 0.2961 - mean_squared_error: 0.3334 - val_loss: 0.0685 - val_accuracy: 0.3357 - val_mean_squared_error: 0.4171 - 531s/epoch - 2s/step
Epoch 62/100
273/273 - 531s - loss: 0.0648 - accuracy: 0.3222 - mean_squared_error: 0.2771 - val_loss: 0.0633 - val_accuracy: 0.3548 - val_mean_squared_error: 0.2701 - 531s/epoch - 2s/step
Epoch 63/100
273/273 - 529s - loss: 0.0632 - accuracy: 0.3282 - mean_squared_error: 0.3046 - val_loss: 0.0561 - val_accuracy: 0.2913 - val_mean_squared_error: 0.3644 - 529s/epoch - 2s/step
Epoch 64/100
273/273 - 530s - loss: 0.0656 - accuracy: 0.2995 - mean_squared_error: 0.4126 - val_loss: 0.0784 - val_accuracy: 0.3196 - val_mean_squared_error: 0.5208 - 530s/epoch - 2s/step
Epoch 65/100
273/273 - 530s - loss: 0.0632 - accuracy: 0.3100 - mean_squared_error: 0.5430 - val_loss: 0.0682 - val_accuracy: 0.3861 - val_mean_squared_error: 0.5259 - 530s/epoch - 2s/step
Epoch 66/100
273/273 - 530s - loss: 0.0632 - accuracy: 0.2969 - mean_squared_error: 0.5352 - val_loss: 0.0686 - val_accuracy: 0.1764 - val_mean_squared_error: 0.6113 - 530s/epoch - 2s/step
Epoch 67/100
273/273 - 530s - loss: 0.0631 - accuracy: 0.3154 - mean_squared_error: 0.6034 - val_loss: 0.0722 - val_accuracy: 0.2339 - val_mean_squared_error: 0.6248 - 530s/epoch - 2s/step
Epoch 68/100
273/273 - 531s - loss: 0.0644 - accuracy: 0.3288 - mean_squared_error: 0.5342 - val_loss: 0.0743 - val_accuracy: 0.2621 - val_mean_squared_error: 0.4844 - 531s/epoch - 2s/step
Epoch 69/100
273/273 - 530s - loss: 0.0652 - accuracy: 0.3584 - mean_squared_error: 0.6746 - val_loss: 0.0820 - val_accuracy: 0.3125 - val_mean_squared_error: 0.5888 - 530s/epoch - 2s/step
Epoch 70/100
273/273 - 531s - loss: 0.0643 - accuracy: 0.3013 - mean_squared_error: 0.5710 - val_loss: 0.0674 - val_accuracy: 0.3478 - val_mean_squared_error: 0.6509 - 531s/epoch - 2s/step
Epoch 71/100
273/273 - 530s - loss: 0.0652 - accuracy: 0.2909 - mean_squared_error: 0.5490 - val_loss: 0.0656 - val_accuracy: 0.4113 - val_mean_squared_error: 0.5182 - 530s/epoch - 2s/step
Epoch 72/100
273/273 - 529s - loss: 0.0627 - accuracy: 0.3363 - mean_squared_error: 0.3964 - val_loss: 0.0622 - val_accuracy: 0.2490 - val_mean_squared_error: 0.3637 - 529s/epoch - 2s/step
Epoch 73/100
273/273 - 529s - loss: 0.0692 - accuracy: 0.3100 - mean_squared_error: 0.4517 - val_loss: 0.0657 - val_accuracy: 0.3558 - val_mean_squared_error: 0.5297 - 529s/epoch - 2s/step
Epoch 74/100
273/273 - 529s - loss: 0.0670 - accuracy: 0.2811 - mean_squared_error: 0.6418 - val_loss: 0.0779 - val_accuracy: 0.4587 - val_mean_squared_error: 0.7357 - 529s/epoch - 2s/step
Epoch 75/100
273/273 - 530s - loss: 0.0676 - accuracy: 0.3507 - mean_squared_error: 0.7553 - val_loss: 0.0770 - val_accuracy: 0.2802 - val_mean_squared_error: 0.8145 - 530s/epoch - 2s/step
Epoch 76/100
273/273 - 529s - loss: 0.0697 - accuracy: 0.3168 - mean_squared_error: 0.7381 - val_loss: 0.0620 - val_accuracy: 0.3972 - val_mean_squared_error: 0.8328 - 529s/epoch - 2s/step
Epoch 77/100
273/273 - 530s - loss: 0.0689 - accuracy: 0.3139 - mean_squared_error: 0.7091 - val_loss: 0.0752 - val_accuracy: 0.2419 - val_mean_squared_error: 0.6540 - 530s/epoch - 2s/step
Epoch 78/100
273/273 - 529s - loss: 0.0665 - accuracy: 0.3420 - mean_squared_error: 0.6711 - val_loss: 0.0684 - val_accuracy: 0.3337 - val_mean_squared_error: 0.7927 - 529s/epoch - 2s/step
Epoch 79/100
273/273 - 529s - loss: 0.0641 - accuracy: 0.2975 - mean_squared_error: 0.5826 - val_loss: 0.0610 - val_accuracy: 0.2389 - val_mean_squared_error: 0.6226 - 529s/epoch - 2s/step
Epoch 80/100
273/273 - 529s - loss: 0.0676 - accuracy: 0.3065 - mean_squared_error: 0.3999 - val_loss: 0.0643 - val_accuracy: 0.2762 - val_mean_squared_error: 0.4023 - 529s/epoch - 2s/step
Epoch 81/100
273/273 - 530s - loss: 0.0681 - accuracy: 0.3244 - mean_squared_error: 0.2991 - val_loss: 0.0711 - val_accuracy: 0.3579 - val_mean_squared_error: 0.3973 - 530s/epoch - 2s/step
Epoch 82/100
273/273 - 518s - loss: 0.0664 - accuracy: 0.3506 - mean_squared_error: 0.3548 - val_loss: 0.0652 - val_accuracy: 0.2863 - val_mean_squared_error: 0.2968 - 518s/epoch - 2s/step
Epoch 83/100
273/273 - 503s - loss: 0.0660 - accuracy: 0.3559 - mean_squared_error: 0.1416 - val_loss: 0.0701 - val_accuracy: 0.3135 - val_mean_squared_error: 0.1357 - 503s/epoch - 2s/step
Epoch 84/100
273/273 - 503s - loss: 0.0638 - accuracy: 0.3337 - mean_squared_error: 0.2312 - val_loss: 0.0714 - val_accuracy: 0.4032 - val_mean_squared_error: 0.2323 - 503s/epoch - 2s/step
Epoch 85/100
273/273 - 503s - loss: 0.0643 - accuracy: 0.3182 - mean_squared_error: 0.2743 - val_loss: 0.0737 - val_accuracy: 0.3206 - val_mean_squared_error: 0.3406 - 503s/epoch - 2s/step
Epoch 86/100
273/273 - 502s - loss: 0.0638 - accuracy: 0.2795 - mean_squared_error: 0.2691 - val_loss: 0.0603 - val_accuracy: 0.3377 - val_mean_squared_error: 0.2062 - 502s/epoch - 2s/step
Epoch 87/100
273/273 - 501s - loss: 0.0641 - accuracy: 0.2763 - mean_squared_error: 0.3736 - val_loss: 0.0718 - val_accuracy: 0.2833 - val_mean_squared_error: 0.3461 - 501s/epoch - 2s/step
Epoch 88/100
273/273 - 501s - loss: 0.0644 - accuracy: 0.3162 - mean_squared_error: 0.5957 - val_loss: 0.0617 - val_accuracy: 0.3679 - val_mean_squared_error: 0.7886 - 501s/epoch - 2s/step
Epoch 89/100
273/273 - 503s - loss: 0.0637 - accuracy: 0.3247 - mean_squared_error: 0.6307 - val_loss: 0.0707 - val_accuracy: 0.4405 - val_mean_squared_error: 0.4710 - 503s/epoch - 2s/step
Epoch 90/100
273/273 - 504s - loss: 0.0676 - accuracy: 0.3258 - mean_squared_error: 0.3691 - val_loss: 0.0691 - val_accuracy: 0.3125 - val_mean_squared_error: 0.3345 - 504s/epoch - 2s/step
Epoch 91/100
273/273 - 503s - loss: 0.0646 - accuracy: 0.3449 - mean_squared_error: 0.4492 - val_loss: 0.0708 - val_accuracy: 0.2440 - val_mean_squared_error: 0.5040 - 503s/epoch - 2s/step
Epoch 92/100
273/273 - 504s - loss: 0.0682 - accuracy: 0.3538 - mean_squared_error: 0.7039 - val_loss: 0.0676 - val_accuracy: 0.3750 - val_mean_squared_error: 0.5468 - 504s/epoch - 2s/step
Epoch 93/100
273/273 - 502s - loss: 0.0659 - accuracy: 0.3482 - mean_squared_error: 0.4426 - val_loss: 0.0664 - val_accuracy: 0.2419 - val_mean_squared_error: 0.5781 - 502s/epoch - 2s/step
Epoch 94/100
273/273 - 504s - loss: 0.0657 - accuracy: 0.3656 - mean_squared_error: 0.4764 - val_loss: 0.0655 - val_accuracy: 0.3921 - val_mean_squared_error: 0.4246 - 504s/epoch - 2s/step
Epoch 95/100
273/273 - 504s - loss: 0.0621 - accuracy: 0.3686 - mean_squared_error: 0.3967 - val_loss: 0.0752 - val_accuracy: 0.3780 - val_mean_squared_error: 0.3801 - 504s/epoch - 2s/step
Epoch 96/100
273/273 - 504s - loss: 0.0632 - accuracy: 0.3750 - mean_squared_error: 0.5885 - val_loss: 0.0697 - val_accuracy: 0.3387 - val_mean_squared_error: 0.6486 - 504s/epoch - 2s/step
Epoch 97/100
273/273 - 501s - loss: 0.0648 - accuracy: 0.3384 - mean_squared_error: 0.4704 - val_loss: 0.0740 - val_accuracy: 0.2843 - val_mean_squared_error: 0.4961 - 501s/epoch - 2s/step
Epoch 98/100
273/273 - 477s - loss: 0.0658 - accuracy: 0.3431 - mean_squared_error: 0.4085 - val_loss: 0.0755 - val_accuracy: 0.3417 - val_mean_squared_error: 0.3650 - 477s/epoch - 2s/step
Epoch 99/100
273/273 - 473s - loss: 0.0650 - accuracy: 0.3119 - mean_squared_error: 0.2179 - val_loss: 0.0757 - val_accuracy: 0.2762 - val_mean_squared_error: 0.1912 - 473s/epoch - 2s/step
Epoch 100/100
273/273 - 475s - loss: 0.0634 - accuracy: 0.3096 - mean_squared_error: 0.3463 - val_loss: 0.0695 - val_accuracy: 0.3669 - val_mean_squared_error: 0.3401 - 475s/epoch - 2s/step
 1/31 [..............................] - ETA: 20s - loss: 0.0677 - accuracy: 0.4062 - mean_squared_error: 0.3191 2/31 [>.............................] - ETA: 12s - loss: 0.0670 - accuracy: 0.4062 - mean_squared_error: 0.3207 3/31 [=>............................] - ETA: 11s - loss: 0.0679 - accuracy: 0.3958 - mean_squared_error: 0.3230 4/31 [==>...........................] - ETA: 11s - loss: 0.0676 - accuracy: 0.3828 - mean_squared_error: 0.3258 5/31 [===>..........................] - ETA: 10s - loss: 0.0676 - accuracy: 0.3750 - mean_squared_error: 0.3268 6/31 [====>.........................] - ETA: 10s - loss: 0.0675 - accuracy: 0.3750 - mean_squared_error: 0.3267 7/31 [=====>........................] - ETA: 10s - loss: 0.0673 - accuracy: 0.3705 - mean_squared_error: 0.3274 8/31 [======>.......................] - ETA: 9s - loss: 0.0672 - accuracy: 0.3711 - mean_squared_error: 0.3280  9/31 [=======>......................] - ETA: 9s - loss: 0.0674 - accuracy: 0.3715 - mean_squared_error: 0.328210/31 [========>.....................] - ETA: 8s - loss: 0.0674 - accuracy: 0.3688 - mean_squared_error: 0.328711/31 [=========>....................] - ETA: 8s - loss: 0.0676 - accuracy: 0.3665 - mean_squared_error: 0.329512/31 [==========>...................] - ETA: 7s - loss: 0.0678 - accuracy: 0.3646 - mean_squared_error: 0.330313/31 [===========>..................] - ETA: 7s - loss: 0.0681 - accuracy: 0.3630 - mean_squared_error: 0.330414/31 [============>.................] - ETA: 7s - loss: 0.0684 - accuracy: 0.3616 - mean_squared_error: 0.330615/31 [=============>................] - ETA: 6s - loss: 0.0687 - accuracy: 0.3604 - mean_squared_error: 0.331016/31 [==============>...............] - ETA: 6s - loss: 0.0688 - accuracy: 0.3594 - mean_squared_error: 0.331417/31 [===============>..............] - ETA: 5s - loss: 0.0690 - accuracy: 0.3585 - mean_squared_error: 0.331718/31 [================>.............] - ETA: 5s - loss: 0.0690 - accuracy: 0.3559 - mean_squared_error: 0.332119/31 [=================>............] - ETA: 5s - loss: 0.0690 - accuracy: 0.3536 - mean_squared_error: 0.332420/31 [==================>...........] - ETA: 4s - loss: 0.0689 - accuracy: 0.3516 - mean_squared_error: 0.332221/31 [===================>..........] - ETA: 4s - loss: 0.0689 - accuracy: 0.3497 - mean_squared_error: 0.332422/31 [====================>.........] - ETA: 3s - loss: 0.0688 - accuracy: 0.3466 - mean_squared_error: 0.333323/31 [=====================>........] - ETA: 3s - loss: 0.0689 - accuracy: 0.3438 - mean_squared_error: 0.334224/31 [======================>.......] - ETA: 2s - loss: 0.0688 - accuracy: 0.3398 - mean_squared_error: 0.335625/31 [=======================>......] - ETA: 2s - loss: 0.0687 - accuracy: 0.3375 - mean_squared_error: 0.336426/31 [========================>.....] - ETA: 2s - loss: 0.0687 - accuracy: 0.3353 - mean_squared_error: 0.337327/31 [=========================>....] - ETA: 1s - loss: 0.0686 - accuracy: 0.3345 - mean_squared_error: 0.337828/31 [==========================>...] - ETA: 1s - loss: 0.0685 - accuracy: 0.3337 - mean_squared_error: 0.338529/31 [===========================>..] - ETA: 0s - loss: 0.0685 - accuracy: 0.3330 - mean_squared_error: 0.339230/31 [============================>.] - ETA: 0s - loss: 0.0682 - accuracy: 0.3323 - mean_squared_error: 0.339631/31 [==============================] - ETA: 0s - loss: 0.0681 - accuracy: 0.3317 - mean_squared_error: 0.339931/31 [==============================] - 13s 421ms/step - loss: 0.0681 - accuracy: 0.3317 - mean_squared_error: 0.3399
test loss, test acc: [0.06806889921426773, 0.3316532373428345, 0.33992576599121094]
############### PREDICTIONS ###############
----------0----------
phi1 4923.0
PHI 3249.0
phi2 2115.0
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 149ms/step
predicted values [[  1.8819137 101.192856   11.330583 ]]
----------1----------
phi1 6840.0
PHI 7533.0
phi2 261.0
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 32ms/step
predicted values [[  1.8819141 101.192856   11.330578 ]]
----------2----------
phi1 1602.0
PHI 5742.0
phi2 4572.0
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 33ms/step
predicted values [[  1.8819141 101.192856   11.330578 ]]
----------3----------
phi1 1575.0
PHI 1395.0
phi2 4536.0
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 33ms/step
predicted values [[  1.8819131 101.192856   11.3305855]]
----------4----------
phi1 4275.0
PHI 2934.0
phi2 2682.0
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 33ms/step
predicted values [[  1.8819131 101.192856   11.330587 ]]
----------5----------
phi1 2996.9999999999995
PHI 3564.0
phi2 2565.0
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 32ms/step
predicted values [[  1.881913 101.192856  11.330588]]
----------6----------
phi1 5472.0
PHI 2538.0
phi2 891.0
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 31ms/step
predicted values [[  1.8819146 101.192856   11.330572 ]]
----------7----------
phi1 2394.0
PHI 612.0
phi2 6822.0
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 33ms/step
predicted values [[  1.8819138 101.192856   11.330582 ]]
----------8----------
phi1 3536.9999999999995
PHI 3681.0
phi2 684.0
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 30ms/step
predicted values [[  1.8819137 101.192856   11.330582 ]]
----------9----------
phi1 351.0
PHI 7866.000000000001
phi2 2322.0
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 31ms/step
predicted values [[  1.8819145 101.192856   11.330575 ]]
############### PREDICTIONS ###############

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 15187396: <s202741-train> in cluster <dcc> Done

Job <s202741-train> was submitted from host <n-62-20-1> by user <s202741> in cluster <dcc> at Sat Jan 14 18:42:22 2023
Job was executed on host(s) <4*n-62-20-11>, in queue <gpuv100>, as user <s202741> in cluster <dcc> at Sat Jan 14 21:02:58 2023
</zhome/ab/7/153983> was used as the home directory.
</zhome/ab/7/153983/project> was used as the working directory.
Started at Sat Jan 14 21:02:58 2023
Terminated at Sun Jan 15 11:26:09 2023
Results reported at Sun Jan 15 11:26:09 2023

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/bash
### General options
### -- specify queue --   NOTE: TitanX is significantly faster than K80
#BSUB -q gpuv100
#BSUB -gpu "num=1:mode=exclusive_process"
### -- set the job Name --
#BSUB -J s202741-train
### -- ask for number of cores (default: 1) --
#BSUB -n 4
#BSUB -R "span[hosts=1]"
### -- set walltime limit: hh:mm --  maximum 24 hours for GPU-queues right now
#BSUB -W 15:30
# request 5GB of memory
#BSUB -R "rusage[mem=5GB]"
### -- Specify the output and error file. %J is the job-id --
### -- -o and -e mean append, -oo and -eo mean overwrite --
#BSUB -o Logs/LayerNormalization%J.out
# -- end of LSF options --

# Necessary modules
cd project 
source venv/bin/activate

module swap cuda/12.0

python trainModelIter2.py 100 "keras.optimizers.Adam(learning_rate=0.03, amsgrad = True)" "[\"accuracy\", tf.keras.metrics.MeanSquaredError(name=\"mean_squared_error\", dtype=None)]" "square_abs_min_loss" "black_background_500x500.csv" 2 "_layer_norm_"

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   171321.75 sec.
    Max Memory :                                 2945 MB
    Average Memory :                             1719.57 MB
    Total Requested Memory :                     20480.00 MB
    Delta Memory :                               17535.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              4
    Max Threads :                                29
    Run time :                                   51792 sec.
    Turnaround time :                            60227 sec.

The output (if any) is above this job summary.

