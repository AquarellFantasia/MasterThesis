{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a27249cc",
   "metadata": {},
   "source": [
    "# Imports and data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad176564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-29 01:00:45.253348: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "############################# Imports ################################\n",
    "######################################################################\n",
    "import sys\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import CustomObjectScope\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.models import load_model \n",
    "from keras.utils import Sequence\n",
    "from keras.utils import load_img\n",
    "from keras.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c74d1b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jan 29 01:00:50 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 525.60.13    Driver Version: 525.60.13    CUDA Version: 12.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-PCIE...  On   | 00000000:37:00.0 Off |                    0 |\r\n",
      "| N/A   35C    P0    39W / 250W |  15102MiB / 16384MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla V100-PCIE...  On   | 00000000:AF:00.0 Off |                    0 |\r\n",
      "| N/A   28C    P0    25W / 250W |      0MiB / 16384MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      5511      C   ...4/Masters/venv/bin/python    15098MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################################################    \n",
    "########################### Debug info ###############################    \n",
    "######################################################################  \n",
    "!nvidia-smi\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb1c0c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################    \n",
    "####################### Load refference data #########################    \n",
    "######################################################################  \n",
    "df = pd.read_csv('black_background_500x500.csv')\n",
    "train_df = df[df['ImagePath'].str.contains(\"train\")]\n",
    "test_df = df[df['ImagePath'].str.contains(\"test\")]\n",
    "valid_df = df[df['ImagePath'].str.contains(\"valid\")]\n",
    "\n",
    "input_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f533699f",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "############################ data generator ##########################\n",
    "######################################################################\n",
    "class datagenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, \n",
    "            batch_size, \n",
    "            img_size,\n",
    "            data_paths_df,\n",
    "            input_channels,\n",
    "            output_channels):\n",
    "         \n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.data_paths_df = data_paths_df\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "        self.data_paths = data_paths_df.values[:,1]\n",
    "        self.params = data_paths_df.values[:,3:6]\n",
    "        assert len(self.data_paths) == len(self.params)\n",
    "        \n",
    "        self.n = len(self.data_paths)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'updates indexes after each epoch'\n",
    "        self.data_paths_df = self.data_paths_df.sample(frac = 1)\n",
    "        self.data_paths = self.data_paths_df.values[:,1]\n",
    "        self.params = self.data_paths_df.values[:,3:6]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_data_paths = self.data_paths[index : index + self.batch_size]\n",
    "        batch_params_paths = self.params[index : index + self.batch_size]\n",
    "\n",
    "        return self.__dataloader(self.img_size,\n",
    "                batch_data_paths, batch_params_paths,\n",
    "                self.input_channels, self.output_channels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size\n",
    "\n",
    "    #################### data loader ########################\n",
    "    def __dataloader(self, \n",
    "            img_size,\n",
    "            data_paths,\n",
    "            batch_params_paths,\n",
    "            input_channels,\n",
    "            output_channels):\n",
    "        x = np.zeros((len(data_paths), img_size[0], img_size[1], input_channels))\n",
    "        y = batch_params_paths        \n",
    "        \n",
    "        for i in range(len(data_paths)):\n",
    "            data = load_img(path = data_paths[i], color_mode = \"grayscale\")\n",
    "            data = tf.keras.utils.img_to_array(data, data_format=\"channels_last\", dtype=\"float32\")\n",
    "            data /= 255\n",
    "            x[i] = np.asarray(data)\n",
    "        return x.astype(\"float32\"), np.array(y).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913735f4",
   "metadata": {},
   "source": [
    "# Definitions of important functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "901d44f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################    \n",
    "########################## Loss functions ############################    \n",
    "###################################################################### \n",
    "import keras.backend as K\n",
    "  \n",
    "def abs_loss_function(y_true, y_pred):   \n",
    "    abs_diff = K.abs(y_true - y_pred)\n",
    "    ones = tf.ones_like(y_true)\n",
    "    abs_diff_reversed = K.abs(ones - abs_diff )   \n",
    "    minimum_from_two = tf.math.minimum(abs_diff, abs_diff_reversed) \n",
    "    return tf.math.reduce_mean(minimum_from_two, axis=-1)\n",
    "\n",
    "def square_abs_min_loss(y_true, y_pred):   \n",
    "    abs_diff = K.abs(y_true - y_pred)\n",
    "    ones = tf.ones_like(y_true)\n",
    "    abs_diff_reversed = K.abs(tf.ones_like(y_true) - abs_diff )   \n",
    "    minimum_from_two = tf.math.minimum(abs_diff, abs_diff_reversed) \n",
    "    min_sq = tf.math.sqrt(minimum_from_two)\n",
    "    return tf.math.reduce_mean(min_sq, axis=-1) \n",
    "\n",
    "def smart_square_abs_min_loss(y_true, y_pred):  \n",
    "    punished_y_pred = tf.where((y_pred<0)|(y_pred>1), 3.0 + K.abs(y_pred),y_pred)\n",
    "    abs_diff = K.abs(y_true - punished_y_pred)\n",
    "    ones = tf.ones_like(y_true)\n",
    "    abs_diff_reversed = K.abs(ones - abs_diff)   \n",
    "    minimum_from_two = tf.math.minimum(abs_diff, abs_diff_reversed)     \n",
    "    return tf.math.reduce_mean(minimum_from_two, axis=-1)\n",
    "    \n",
    "############################# For debugging ####################################\n",
    "#     print(\"_________________ 1 __________________\")\n",
    "#     print(abs_diff_reversed.numpy())\n",
    "#     print(\"_________________ 2 __________________\")\n",
    "#     print(abs_diff.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "621c458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################    \n",
    "############## Callback function to print evaluation #################    \n",
    "###################################################################### \n",
    "test_g = datagenerator(32, (input_size,input_size), test_df, 1, 3)\n",
    "evaluation_list = []\n",
    "accuracy_list = []\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch % 5 == 0:\n",
    "            print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "            m_e = self.model.evaluate(test_g, batch_size=32)\n",
    "            for i in range(60):\n",
    "                evaluation_list.append(m_e[0])\n",
    "                accuracy_list.append(m_e[2])\n",
    "            print(\"Loss on test data: \", m_e[0])\n",
    "            for nr in range(3):\n",
    "                t = test_df.values[nr][1]\n",
    "                data = load_img(path = t, grayscale = True)\n",
    "                data = tf.keras.utils.img_to_array(data, data_format=\"channels_last\", dtype=\"float32\")\n",
    "                data /= 255\n",
    "                data.shape = (1,) + data.shape\n",
    "                X = np.asarray(data)\n",
    "                print(\"----------{}----------\".format(nr))\n",
    "                euler = t.split(\"_\")\n",
    "                print(\"phi1\", float(euler[3]))\n",
    "                print(\"PHI\",   float(euler[4]))\n",
    "                print(\"phi2\",  float(euler[5][:-4]))\n",
    "                yhat = model.predict(data)\n",
    "                print(\"predicted values\", yhat*90)\n",
    "            print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "            model.save(\"TempModels/epoch{}.h5\".format(epoch), save_format = 'h5')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed4b21b",
   "metadata": {},
   "source": [
    "# Experiment section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cb55ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "############################# Experiments ############################\n",
    "######################################################################\n",
    "def conv_block(x, filters, kernel_size, regul):\n",
    "    if regul:\n",
    "        biasregul = regularizers.l2(regul)\n",
    "        kernelregul = regularizers.l2(regul)\n",
    "    else:\n",
    "        biasregul = kernelregul = None\n",
    "    x = ReflectionPadding2D(padding=((kernel_size-1),\n",
    "                                     (kernel_size-1)))(x)\n",
    "    x = layers.Conv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=\"valid\",\n",
    "            #activation=lambda x: activations.relu(x, alpha=0.1),\n",
    "            kernel_initializer='RandomNormal',\n",
    "            bias_initializer=initializers.Constant(0.1),\n",
    "            kernel_regularizer=kernelregul,\n",
    "            bias_regularizer=biasregul\n",
    "            )(x)\n",
    "    x = layers.PReLU(\n",
    "            shared_axes=[1,2],\n",
    "            alpha_initializer=tf.initializers.Constant(0.01),\n",
    "            )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    #x = layers.Activation(\"relu\")(x)\n",
    "    #x = layers.Dropout(rate=0.5)(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e309dfa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 500, 500, 1)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 498, 498, 32)      320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 496, 496, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 124, 124, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 122, 122, 32)      9248      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 120, 120, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 30, 30, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 26, 26, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1152)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               147584    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                2064      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 196,259\n",
      "Trainable params: 196,259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "######################################################################    \n",
    "######################## Loading the model ###########################    \n",
    "###################################################################### \n",
    "inputs = keras.Input(shape=(input_size, input_size, 1))\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=4)(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=4)(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=4)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(3)(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce477929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.2801 - smart_square_abs_min_loss: 0.2801 - accuracy: 0.2932+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 266ms/step - loss: 0.2579 - smart_square_abs_min_loss: 0.2579 - accuracy: 0.4012\n",
      "Loss on test data:  0.2578640580177307\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/zhome/ab/7/153983/project/venv/lib/python3.10/site-packages/keras/utils/image_utils.py:409: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 226ms/step\n",
      "predicted values [[ 4.7328153  2.8319077 13.617306 ]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[ 3.2477434  1.4213505 11.37334  ]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[ 5.42036   3.300544 13.797027]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 84s 304ms/step - loss: 0.2801 - smart_square_abs_min_loss: 0.2801 - accuracy: 0.2932 - val_loss: 0.2569 - val_smart_square_abs_min_loss: 0.2569 - val_accuracy: 0.2923\n",
      "Epoch 2/300\n",
      "273/273 [==============================] - 75s 274ms/step - loss: 0.3010 - smart_square_abs_min_loss: 0.3010 - accuracy: 0.2475 - val_loss: 0.4693 - val_smart_square_abs_min_loss: 0.4693 - val_accuracy: 0.3478\n",
      "Epoch 3/300\n",
      "273/273 [==============================] - 72s 264ms/step - loss: 0.2572 - smart_square_abs_min_loss: 0.2572 - accuracy: 0.3067 - val_loss: 0.2576 - val_smart_square_abs_min_loss: 0.2576 - val_accuracy: 0.3619\n",
      "Epoch 4/300\n",
      "273/273 [==============================] - 74s 270ms/step - loss: 0.2282 - smart_square_abs_min_loss: 0.2282 - accuracy: 0.4084 - val_loss: 0.3249 - val_smart_square_abs_min_loss: 0.3249 - val_accuracy: 0.3206\n",
      "Epoch 5/300\n",
      "273/273 [==============================] - 78s 285ms/step - loss: 0.2445 - smart_square_abs_min_loss: 0.2445 - accuracy: 0.3438 - val_loss: 0.2994 - val_smart_square_abs_min_loss: 0.2994 - val_accuracy: 0.3337\n",
      "Epoch 6/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.2353 - smart_square_abs_min_loss: 0.2353 - accuracy: 0.4013+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 274ms/step - loss: 0.2889 - smart_square_abs_min_loss: 0.2889 - accuracy: 0.2278\n",
      "Loss on test data:  0.28886479139328003\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[56.70788  33.555153  9.082936]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[49.320244 12.055392 11.054396]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[ 5.0963955 30.494715  43.652145 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 90s 331ms/step - loss: 0.2353 - smart_square_abs_min_loss: 0.2353 - accuracy: 0.4013 - val_loss: 0.3049 - val_smart_square_abs_min_loss: 0.3049 - val_accuracy: 0.4950\n",
      "Epoch 7/300\n",
      "273/273 [==============================] - 72s 262ms/step - loss: 0.2271 - smart_square_abs_min_loss: 0.2271 - accuracy: 0.4423 - val_loss: 0.2984 - val_smart_square_abs_min_loss: 0.2984 - val_accuracy: 0.3347\n",
      "Epoch 8/300\n",
      "273/273 [==============================] - 70s 254ms/step - loss: 0.2128 - smart_square_abs_min_loss: 0.2128 - accuracy: 0.3777 - val_loss: 0.2272 - val_smart_square_abs_min_loss: 0.2272 - val_accuracy: 0.3256\n",
      "Epoch 9/300\n",
      "273/273 [==============================] - 75s 276ms/step - loss: 0.1973 - smart_square_abs_min_loss: 0.1973 - accuracy: 0.4524 - val_loss: 0.2494 - val_smart_square_abs_min_loss: 0.2494 - val_accuracy: 0.3226\n",
      "Epoch 10/300\n",
      "273/273 [==============================] - 80s 294ms/step - loss: 0.1842 - smart_square_abs_min_loss: 0.1842 - accuracy: 0.4733 - val_loss: 0.2774 - val_smart_square_abs_min_loss: 0.2774 - val_accuracy: 0.2661\n",
      "Epoch 11/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.2002 - smart_square_abs_min_loss: 0.2002 - accuracy: 0.4410+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 271ms/step - loss: 0.2502 - smart_square_abs_min_loss: 0.2502 - accuracy: 0.4133\n",
      "Loss on test data:  0.2501865029335022\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[72.967964  6.401289 20.533768]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[51.01298    7.4122014 29.261374 ]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[ 7.8575454 46.356403  59.40895  ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 80s 294ms/step - loss: 0.2002 - smart_square_abs_min_loss: 0.2002 - accuracy: 0.4410 - val_loss: 0.2396 - val_smart_square_abs_min_loss: 0.2396 - val_accuracy: 0.3881\n",
      "Epoch 12/300\n",
      "273/273 [==============================] - 70s 258ms/step - loss: 0.2043 - smart_square_abs_min_loss: 0.2043 - accuracy: 0.4793 - val_loss: 0.2453 - val_smart_square_abs_min_loss: 0.2453 - val_accuracy: 0.3720\n",
      "Epoch 13/300\n",
      "273/273 [==============================] - 74s 269ms/step - loss: 0.1882 - smart_square_abs_min_loss: 0.1882 - accuracy: 0.4953 - val_loss: 0.2313 - val_smart_square_abs_min_loss: 0.2313 - val_accuracy: 0.4667\n",
      "Epoch 14/300\n",
      "273/273 [==============================] - 73s 267ms/step - loss: 0.1867 - smart_square_abs_min_loss: 0.1867 - accuracy: 0.5001 - val_loss: 0.2397 - val_smart_square_abs_min_loss: 0.2397 - val_accuracy: 0.3478\n",
      "Epoch 15/300\n",
      "273/273 [==============================] - 71s 260ms/step - loss: 0.1799 - smart_square_abs_min_loss: 0.1799 - accuracy: 0.4932 - val_loss: 0.2376 - val_smart_square_abs_min_loss: 0.2376 - val_accuracy: 0.3619\n",
      "Epoch 16/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.1629 - smart_square_abs_min_loss: 0.1629 - accuracy: 0.5248+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 240ms/step - loss: 0.2113 - smart_square_abs_min_loss: 0.2113 - accuracy: 0.3750\n",
      "Loss on test data:  0.2113141417503357\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[49.693775 41.37691  18.316397]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[23.581663  5.880193 69.533005]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "predicted values [[31.262114 61.40036  17.343473]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 75s 276ms/step - loss: 0.1629 - smart_square_abs_min_loss: 0.1629 - accuracy: 0.5248 - val_loss: 0.2703 - val_smart_square_abs_min_loss: 0.2703 - val_accuracy: 0.3417\n",
      "Epoch 17/300\n",
      "273/273 [==============================] - 81s 298ms/step - loss: 0.1586 - smart_square_abs_min_loss: 0.1586 - accuracy: 0.5584 - val_loss: 0.2227 - val_smart_square_abs_min_loss: 0.2227 - val_accuracy: 0.4385\n",
      "Epoch 18/300\n",
      "273/273 [==============================] - 85s 313ms/step - loss: 0.1515 - smart_square_abs_min_loss: 0.1515 - accuracy: 0.5588 - val_loss: 0.1994 - val_smart_square_abs_min_loss: 0.1994 - val_accuracy: 0.3589\n",
      "Epoch 19/300\n",
      "273/273 [==============================] - 79s 289ms/step - loss: 0.1606 - smart_square_abs_min_loss: 0.1606 - accuracy: 0.5341 - val_loss: 0.3461 - val_smart_square_abs_min_loss: 0.3461 - val_accuracy: 0.4194\n",
      "Epoch 20/300\n",
      "273/273 [==============================] - 82s 301ms/step - loss: 0.1526 - smart_square_abs_min_loss: 0.1526 - accuracy: 0.5651 - val_loss: 0.2027 - val_smart_square_abs_min_loss: 0.2027 - val_accuracy: 0.5464\n",
      "Epoch 21/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.1450 - smart_square_abs_min_loss: 0.1450 - accuracy: 0.5967+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 254ms/step - loss: 0.1921 - smart_square_abs_min_loss: 0.1921 - accuracy: 0.3730\n",
      "Loss on test data:  0.19210627675056458\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[88.837845 47.622837 60.56981 ]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[29.470768 39.79611  45.99025 ]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[42.287796 50.36097  31.139322]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 91s 332ms/step - loss: 0.1450 - smart_square_abs_min_loss: 0.1450 - accuracy: 0.5967 - val_loss: 0.2151 - val_smart_square_abs_min_loss: 0.2151 - val_accuracy: 0.4466\n",
      "Epoch 22/300\n",
      "273/273 [==============================] - 84s 309ms/step - loss: 0.1552 - smart_square_abs_min_loss: 0.1552 - accuracy: 0.5695 - val_loss: 0.1856 - val_smart_square_abs_min_loss: 0.1856 - val_accuracy: 0.4294\n",
      "Epoch 23/300\n",
      "273/273 [==============================] - 79s 291ms/step - loss: 0.1465 - smart_square_abs_min_loss: 0.1465 - accuracy: 0.6083 - val_loss: 0.1578 - val_smart_square_abs_min_loss: 0.1578 - val_accuracy: 0.5444\n",
      "Epoch 24/300\n",
      "273/273 [==============================] - 76s 277ms/step - loss: 0.1497 - smart_square_abs_min_loss: 0.1497 - accuracy: 0.5686 - val_loss: 0.1950 - val_smart_square_abs_min_loss: 0.1950 - val_accuracy: 0.4597\n",
      "Epoch 25/300\n",
      "273/273 [==============================] - 81s 297ms/step - loss: 0.1413 - smart_square_abs_min_loss: 0.1413 - accuracy: 0.5828 - val_loss: 0.1689 - val_smart_square_abs_min_loss: 0.1689 - val_accuracy: 0.4778\n",
      "Epoch 26/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.1408 - smart_square_abs_min_loss: 0.1408 - accuracy: 0.6033+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 274ms/step - loss: 0.1775 - smart_square_abs_min_loss: 0.1775 - accuracy: 0.5151\n",
      "Loss on test data:  0.1775234043598175\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[75.3716   52.09355  28.983644]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "predicted values [[37.68202 36.7694  22.12283]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[11.974503 51.479004 48.11192 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 91s 334ms/step - loss: 0.1408 - smart_square_abs_min_loss: 0.1408 - accuracy: 0.6033 - val_loss: 0.2279 - val_smart_square_abs_min_loss: 0.2279 - val_accuracy: 0.5484\n",
      "Epoch 27/300\n",
      "273/273 [==============================] - 78s 287ms/step - loss: 0.1331 - smart_square_abs_min_loss: 0.1331 - accuracy: 0.6190 - val_loss: 0.2258 - val_smart_square_abs_min_loss: 0.2258 - val_accuracy: 0.6482\n",
      "Epoch 28/300\n",
      "273/273 [==============================] - 79s 288ms/step - loss: 0.1249 - smart_square_abs_min_loss: 0.1249 - accuracy: 0.6276 - val_loss: 0.1596 - val_smart_square_abs_min_loss: 0.1596 - val_accuracy: 0.5696\n",
      "Epoch 29/300\n",
      "273/273 [==============================] - 79s 290ms/step - loss: 0.1280 - smart_square_abs_min_loss: 0.1280 - accuracy: 0.6268 - val_loss: 0.1690 - val_smart_square_abs_min_loss: 0.1690 - val_accuracy: 0.5433\n",
      "Epoch 30/300\n",
      "273/273 [==============================] - 76s 280ms/step - loss: 0.1250 - smart_square_abs_min_loss: 0.1250 - accuracy: 0.6261 - val_loss: 0.1720 - val_smart_square_abs_min_loss: 0.1720 - val_accuracy: 0.6613\n",
      "Epoch 31/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.1303 - smart_square_abs_min_loss: 0.1303 - accuracy: 0.5990+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 272ms/step - loss: 0.1643 - smart_square_abs_min_loss: 0.1643 - accuracy: 0.5534\n",
      "Loss on test data:  0.1643451750278473\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[77.12239 50.8602  31.95104]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[39.063988 43.41136  20.35645 ]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[27.656761 63.348064 49.97701 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 94s 342ms/step - loss: 0.1303 - smart_square_abs_min_loss: 0.1303 - accuracy: 0.5990 - val_loss: 0.1696 - val_smart_square_abs_min_loss: 0.1696 - val_accuracy: 0.4365\n",
      "Epoch 32/300\n",
      "273/273 [==============================] - 77s 281ms/step - loss: 0.1224 - smart_square_abs_min_loss: 0.1224 - accuracy: 0.6489 - val_loss: 0.1692 - val_smart_square_abs_min_loss: 0.1692 - val_accuracy: 0.4577\n",
      "Epoch 33/300\n",
      "273/273 [==============================] - 81s 295ms/step - loss: 0.1365 - smart_square_abs_min_loss: 0.1365 - accuracy: 0.6208 - val_loss: 0.2334 - val_smart_square_abs_min_loss: 0.2334 - val_accuracy: 0.5625\n",
      "Epoch 34/300\n",
      "273/273 [==============================] - 84s 309ms/step - loss: 0.1244 - smart_square_abs_min_loss: 0.1244 - accuracy: 0.6134 - val_loss: 0.1917 - val_smart_square_abs_min_loss: 0.1917 - val_accuracy: 0.5030\n",
      "Epoch 35/300\n",
      "273/273 [==============================] - 78s 284ms/step - loss: 0.1171 - smart_square_abs_min_loss: 0.1171 - accuracy: 0.6748 - val_loss: 0.1562 - val_smart_square_abs_min_loss: 0.1562 - val_accuracy: 0.4899\n",
      "Epoch 36/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.1143 - smart_square_abs_min_loss: 0.1143 - accuracy: 0.6660+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 256ms/step - loss: 0.1794 - smart_square_abs_min_loss: 0.1794 - accuracy: 0.5121\n",
      "Loss on test data:  0.17943094670772552\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[59.195625 38.641136 23.601294]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[31.844322 34.460793 16.035114]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "predicted values [[26.039314 55.187904 44.983585]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 89s 324ms/step - loss: 0.1143 - smart_square_abs_min_loss: 0.1143 - accuracy: 0.6660 - val_loss: 0.1344 - val_smart_square_abs_min_loss: 0.1344 - val_accuracy: 0.6058\n",
      "Epoch 37/300\n",
      "273/273 [==============================] - 76s 277ms/step - loss: 0.1222 - smart_square_abs_min_loss: 0.1222 - accuracy: 0.6424 - val_loss: 0.1357 - val_smart_square_abs_min_loss: 0.1357 - val_accuracy: 0.6139\n",
      "Epoch 38/300\n",
      "273/273 [==============================] - 82s 301ms/step - loss: 0.1070 - smart_square_abs_min_loss: 0.1070 - accuracy: 0.6272 - val_loss: 0.1464 - val_smart_square_abs_min_loss: 0.1464 - val_accuracy: 0.5131\n",
      "Epoch 39/300\n",
      "273/273 [==============================] - 79s 291ms/step - loss: 0.1257 - smart_square_abs_min_loss: 0.1257 - accuracy: 0.6391 - val_loss: 0.1496 - val_smart_square_abs_min_loss: 0.1496 - val_accuracy: 0.5766\n",
      "Epoch 40/300\n",
      "273/273 [==============================] - 80s 293ms/step - loss: 0.1284 - smart_square_abs_min_loss: 0.1284 - accuracy: 0.6237 - val_loss: 0.1838 - val_smart_square_abs_min_loss: 0.1838 - val_accuracy: 0.3760\n",
      "Epoch 41/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.1238 - smart_square_abs_min_loss: 0.1238 - accuracy: 0.6377+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 245ms/step - loss: 0.1594 - smart_square_abs_min_loss: 0.1594 - accuracy: 0.5867\n",
      "Loss on test data:  0.1593550741672516\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[57.051266 43.107334 21.935553]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "predicted values [[17.958384 36.080086  9.740531]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "predicted values [[17.469538 60.936893 46.06784 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 87s 320ms/step - loss: 0.1238 - smart_square_abs_min_loss: 0.1238 - accuracy: 0.6377 - val_loss: 0.1685 - val_smart_square_abs_min_loss: 0.1685 - val_accuracy: 0.6200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/300\n",
      "273/273 [==============================] - 79s 290ms/step - loss: 0.1059 - smart_square_abs_min_loss: 0.1059 - accuracy: 0.6830 - val_loss: 0.1477 - val_smart_square_abs_min_loss: 0.1477 - val_accuracy: 0.4970\n",
      "Epoch 43/300\n",
      "273/273 [==============================] - 70s 257ms/step - loss: 0.1159 - smart_square_abs_min_loss: 0.1159 - accuracy: 0.6376 - val_loss: 0.1449 - val_smart_square_abs_min_loss: 0.1449 - val_accuracy: 0.5998\n",
      "Epoch 44/300\n",
      "273/273 [==============================] - 79s 291ms/step - loss: 0.1070 - smart_square_abs_min_loss: 0.1070 - accuracy: 0.6621 - val_loss: 0.1400 - val_smart_square_abs_min_loss: 0.1400 - val_accuracy: 0.4708\n",
      "Epoch 45/300\n",
      "273/273 [==============================] - 77s 282ms/step - loss: 0.1257 - smart_square_abs_min_loss: 0.1257 - accuracy: 0.6385 - val_loss: 0.1643 - val_smart_square_abs_min_loss: 0.1643 - val_accuracy: 0.5192\n",
      "Epoch 46/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0976 - smart_square_abs_min_loss: 0.0976 - accuracy: 0.6986+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 265ms/step - loss: 0.1376 - smart_square_abs_min_loss: 0.1376 - accuracy: 0.4506\n",
      "Loss on test data:  0.13756750524044037\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "predicted values [[60.313118 41.976704 23.97448 ]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "predicted values [[30.352255 39.171295 15.926053]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[12.778972 61.20737  51.73883 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 90s 328ms/step - loss: 0.0976 - smart_square_abs_min_loss: 0.0976 - accuracy: 0.6986 - val_loss: 0.1892 - val_smart_square_abs_min_loss: 0.1892 - val_accuracy: 0.5524\n",
      "Epoch 47/300\n",
      "273/273 [==============================] - 81s 296ms/step - loss: 0.0999 - smart_square_abs_min_loss: 0.0999 - accuracy: 0.6943 - val_loss: 0.1417 - val_smart_square_abs_min_loss: 0.1417 - val_accuracy: 0.6079\n",
      "Epoch 48/300\n",
      "273/273 [==============================] - 79s 289ms/step - loss: 0.1124 - smart_square_abs_min_loss: 0.1124 - accuracy: 0.6439 - val_loss: 0.2014 - val_smart_square_abs_min_loss: 0.2014 - val_accuracy: 0.6381\n",
      "Epoch 49/300\n",
      "273/273 [==============================] - 85s 310ms/step - loss: 0.0997 - smart_square_abs_min_loss: 0.0997 - accuracy: 0.6981 - val_loss: 0.1365 - val_smart_square_abs_min_loss: 0.1365 - val_accuracy: 0.6966\n",
      "Epoch 50/300\n",
      "273/273 [==============================] - 83s 302ms/step - loss: 0.1173 - smart_square_abs_min_loss: 0.1173 - accuracy: 0.6496 - val_loss: 0.1782 - val_smart_square_abs_min_loss: 0.1782 - val_accuracy: 0.5212\n",
      "Epoch 51/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0937 - smart_square_abs_min_loss: 0.0937 - accuracy: 0.6923+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 263ms/step - loss: 0.1280 - smart_square_abs_min_loss: 0.1280 - accuracy: 0.6109\n",
      "Loss on test data:  0.12796345353126526\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[64.77377  36.851025 27.086811]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[34.039307  36.773422   7.8269563]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "predicted values [[17.564661 53.925453 45.41236 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 88s 324ms/step - loss: 0.0937 - smart_square_abs_min_loss: 0.0937 - accuracy: 0.6923 - val_loss: 0.1699 - val_smart_square_abs_min_loss: 0.1699 - val_accuracy: 0.4395\n",
      "Epoch 52/300\n",
      "273/273 [==============================] - 82s 301ms/step - loss: 0.0964 - smart_square_abs_min_loss: 0.0964 - accuracy: 0.7004 - val_loss: 0.1331 - val_smart_square_abs_min_loss: 0.1331 - val_accuracy: 0.4909\n",
      "Epoch 53/300\n",
      "273/273 [==============================] - 75s 274ms/step - loss: 0.1042 - smart_square_abs_min_loss: 0.1042 - accuracy: 0.6774 - val_loss: 0.1639 - val_smart_square_abs_min_loss: 0.1639 - val_accuracy: 0.6421\n",
      "Epoch 54/300\n",
      "273/273 [==============================] - 83s 302ms/step - loss: 0.1224 - smart_square_abs_min_loss: 0.1224 - accuracy: 0.6212 - val_loss: 0.1122 - val_smart_square_abs_min_loss: 0.1122 - val_accuracy: 0.6502\n",
      "Epoch 55/300\n",
      "273/273 [==============================] - 78s 286ms/step - loss: 0.1062 - smart_square_abs_min_loss: 0.1062 - accuracy: 0.6898 - val_loss: 0.1156 - val_smart_square_abs_min_loss: 0.1156 - val_accuracy: 0.7379\n",
      "Epoch 56/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0927 - smart_square_abs_min_loss: 0.0927 - accuracy: 0.7224+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 280ms/step - loss: 0.1183 - smart_square_abs_min_loss: 0.1183 - accuracy: 0.5262\n",
      "Loss on test data:  0.11829688400030136\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[61.942142 41.394787 18.568653]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[11.641359  33.274853   4.1863933]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[15.553111 51.658257 45.732662]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 89s 324ms/step - loss: 0.0927 - smart_square_abs_min_loss: 0.0927 - accuracy: 0.7224 - val_loss: 0.1360 - val_smart_square_abs_min_loss: 0.1360 - val_accuracy: 0.5363\n",
      "Epoch 57/300\n",
      "273/273 [==============================] - 84s 309ms/step - loss: 0.1058 - smart_square_abs_min_loss: 0.1058 - accuracy: 0.7008 - val_loss: 0.1482 - val_smart_square_abs_min_loss: 0.1482 - val_accuracy: 0.6603\n",
      "Epoch 58/300\n",
      "273/273 [==============================] - 85s 313ms/step - loss: 0.1050 - smart_square_abs_min_loss: 0.1050 - accuracy: 0.6904 - val_loss: 0.1314 - val_smart_square_abs_min_loss: 0.1314 - val_accuracy: 0.5575\n",
      "Epoch 59/300\n",
      "273/273 [==============================] - 78s 286ms/step - loss: 0.1055 - smart_square_abs_min_loss: 0.1055 - accuracy: 0.6931 - val_loss: 0.1065 - val_smart_square_abs_min_loss: 0.1065 - val_accuracy: 0.5675\n",
      "Epoch 60/300\n",
      "273/273 [==============================] - 83s 303ms/step - loss: 0.1097 - smart_square_abs_min_loss: 0.1097 - accuracy: 0.6644 - val_loss: 0.1058 - val_smart_square_abs_min_loss: 0.1058 - val_accuracy: 0.6220\n",
      "Epoch 61/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0999 - smart_square_abs_min_loss: 0.0999 - accuracy: 0.6829+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 261ms/step - loss: 0.1246 - smart_square_abs_min_loss: 0.1246 - accuracy: 0.6643\n",
      "Loss on test data:  0.12461226433515549\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[62.516113 31.128304 29.826763]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[26.320475 43.558426 12.551481]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[13.22433  55.191803 49.709976]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 93s 340ms/step - loss: 0.0999 - smart_square_abs_min_loss: 0.0999 - accuracy: 0.6829 - val_loss: 0.1559 - val_smart_square_abs_min_loss: 0.1559 - val_accuracy: 0.6109\n",
      "Epoch 62/300\n",
      "273/273 [==============================] - 79s 287ms/step - loss: 0.0857 - smart_square_abs_min_loss: 0.0857 - accuracy: 0.7150 - val_loss: 0.1140 - val_smart_square_abs_min_loss: 0.1140 - val_accuracy: 0.5968\n",
      "Epoch 63/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273/273 [==============================] - 86s 314ms/step - loss: 0.1107 - smart_square_abs_min_loss: 0.1107 - accuracy: 0.6560 - val_loss: 0.1104 - val_smart_square_abs_min_loss: 0.1104 - val_accuracy: 0.6613\n",
      "Epoch 64/300\n",
      "273/273 [==============================] - 79s 288ms/step - loss: 0.0930 - smart_square_abs_min_loss: 0.0930 - accuracy: 0.6809 - val_loss: 0.1435 - val_smart_square_abs_min_loss: 0.1435 - val_accuracy: 0.5121\n",
      "Epoch 65/300\n",
      "273/273 [==============================] - 78s 287ms/step - loss: 0.1035 - smart_square_abs_min_loss: 0.1035 - accuracy: 0.7103 - val_loss: 0.1290 - val_smart_square_abs_min_loss: 0.1290 - val_accuracy: 0.6522\n",
      "Epoch 66/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0922 - smart_square_abs_min_loss: 0.0922 - accuracy: 0.7174+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 258ms/step - loss: 0.1441 - smart_square_abs_min_loss: 0.1441 - accuracy: 0.7389\n",
      "Loss on test data:  0.14406144618988037\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[61.480507 32.04367  21.15044 ]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[19.014423 45.2938    5.784134]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[16.104359 56.79866  43.19025 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 89s 325ms/step - loss: 0.0922 - smart_square_abs_min_loss: 0.0922 - accuracy: 0.7174 - val_loss: 0.1201 - val_smart_square_abs_min_loss: 0.1201 - val_accuracy: 0.7540\n",
      "Epoch 67/300\n",
      "273/273 [==============================] - 86s 314ms/step - loss: 0.1081 - smart_square_abs_min_loss: 0.1081 - accuracy: 0.6680 - val_loss: 0.1038 - val_smart_square_abs_min_loss: 0.1038 - val_accuracy: 0.6603\n",
      "Epoch 68/300\n",
      "273/273 [==============================] - 80s 291ms/step - loss: 0.0933 - smart_square_abs_min_loss: 0.0933 - accuracy: 0.7099 - val_loss: 0.1157 - val_smart_square_abs_min_loss: 0.1157 - val_accuracy: 0.6714\n",
      "Epoch 69/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0936 - smart_square_abs_min_loss: 0.0936 - accuracy: 0.7173 - val_loss: 0.1420 - val_smart_square_abs_min_loss: 0.1420 - val_accuracy: 0.4950\n",
      "Epoch 70/300\n",
      "273/273 [==============================] - 86s 314ms/step - loss: 0.0980 - smart_square_abs_min_loss: 0.0980 - accuracy: 0.6769 - val_loss: 0.1233 - val_smart_square_abs_min_loss: 0.1233 - val_accuracy: 0.4960\n",
      "Epoch 71/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.1016 - smart_square_abs_min_loss: 0.1016 - accuracy: 0.6730+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 252ms/step - loss: 0.1109 - smart_square_abs_min_loss: 0.1109 - accuracy: 0.5212\n",
      "Loss on test data:  0.11088117212057114\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[56.0455   35.181885 23.100328]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[26.498692  38.283752  -1.6785861]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "predicted values [[11.866483 60.360878 43.39235 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 93s 341ms/step - loss: 0.1016 - smart_square_abs_min_loss: 0.1016 - accuracy: 0.6730 - val_loss: 0.1284 - val_smart_square_abs_min_loss: 0.1284 - val_accuracy: 0.5595\n",
      "Epoch 72/300\n",
      "273/273 [==============================] - 80s 293ms/step - loss: 0.0851 - smart_square_abs_min_loss: 0.0851 - accuracy: 0.7294 - val_loss: 0.1399 - val_smart_square_abs_min_loss: 0.1399 - val_accuracy: 0.7389\n",
      "Epoch 73/300\n",
      "273/273 [==============================] - 79s 289ms/step - loss: 0.0891 - smart_square_abs_min_loss: 0.0891 - accuracy: 0.7126 - val_loss: 0.0984 - val_smart_square_abs_min_loss: 0.0984 - val_accuracy: 0.5474\n",
      "Epoch 74/300\n",
      "273/273 [==============================] - 80s 293ms/step - loss: 0.0954 - smart_square_abs_min_loss: 0.0954 - accuracy: 0.6896 - val_loss: 0.1214 - val_smart_square_abs_min_loss: 0.1214 - val_accuracy: 0.5907\n",
      "Epoch 75/300\n",
      "273/273 [==============================] - 79s 289ms/step - loss: 0.0923 - smart_square_abs_min_loss: 0.0923 - accuracy: 0.6769 - val_loss: 0.1268 - val_smart_square_abs_min_loss: 0.1268 - val_accuracy: 0.6179\n",
      "Epoch 76/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0839 - smart_square_abs_min_loss: 0.0839 - accuracy: 0.7334+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 261ms/step - loss: 0.1604 - smart_square_abs_min_loss: 0.1604 - accuracy: 0.6613\n",
      "Loss on test data:  0.16038788855075836\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[63.625732 43.910877 28.60872 ]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[25.674906  30.999352   3.5662987]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[12.167509 60.70465  52.771557]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 94s 344ms/step - loss: 0.0839 - smart_square_abs_min_loss: 0.0839 - accuracy: 0.7334 - val_loss: 0.1415 - val_smart_square_abs_min_loss: 0.1415 - val_accuracy: 0.6310\n",
      "Epoch 77/300\n",
      "273/273 [==============================] - 78s 284ms/step - loss: 0.0967 - smart_square_abs_min_loss: 0.0967 - accuracy: 0.6932 - val_loss: 0.1765 - val_smart_square_abs_min_loss: 0.1765 - val_accuracy: 0.5554\n",
      "Epoch 78/300\n",
      "273/273 [==============================] - 85s 310ms/step - loss: 0.1012 - smart_square_abs_min_loss: 0.1012 - accuracy: 0.7042 - val_loss: 0.1308 - val_smart_square_abs_min_loss: 0.1308 - val_accuracy: 0.6583\n",
      "Epoch 79/300\n",
      "273/273 [==============================] - 80s 293ms/step - loss: 0.0890 - smart_square_abs_min_loss: 0.0890 - accuracy: 0.7098 - val_loss: 0.0999 - val_smart_square_abs_min_loss: 0.0999 - val_accuracy: 0.6653\n",
      "Epoch 80/300\n",
      "273/273 [==============================] - 78s 287ms/step - loss: 0.0888 - smart_square_abs_min_loss: 0.0888 - accuracy: 0.7123 - val_loss: 0.0893 - val_smart_square_abs_min_loss: 0.0893 - val_accuracy: 0.7450\n",
      "Epoch 81/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0810 - smart_square_abs_min_loss: 0.0810 - accuracy: 0.7420+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 278ms/step - loss: 0.1143 - smart_square_abs_min_loss: 0.1143 - accuracy: 0.6845\n",
      "Loss on test data:  0.11433404684066772\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[63.235043 32.940018 26.869469]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[26.450094 29.193739 12.581255]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[16.882317 59.852207 52.46984 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 88s 323ms/step - loss: 0.0810 - smart_square_abs_min_loss: 0.0810 - accuracy: 0.7420 - val_loss: 0.1192 - val_smart_square_abs_min_loss: 0.1192 - val_accuracy: 0.7540\n",
      "Epoch 82/300\n",
      "273/273 [==============================] - 78s 284ms/step - loss: 0.0886 - smart_square_abs_min_loss: 0.0886 - accuracy: 0.6851 - val_loss: 0.1516 - val_smart_square_abs_min_loss: 0.1516 - val_accuracy: 0.5736\n",
      "Epoch 83/300\n",
      "273/273 [==============================] - 84s 309ms/step - loss: 0.0922 - smart_square_abs_min_loss: 0.0922 - accuracy: 0.7355 - val_loss: 0.1024 - val_smart_square_abs_min_loss: 0.1024 - val_accuracy: 0.5121\n",
      "Epoch 84/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273/273 [==============================] - 83s 305ms/step - loss: 0.1054 - smart_square_abs_min_loss: 0.1054 - accuracy: 0.6821 - val_loss: 0.0985 - val_smart_square_abs_min_loss: 0.0985 - val_accuracy: 0.7843\n",
      "Epoch 85/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0877 - smart_square_abs_min_loss: 0.0877 - accuracy: 0.7389 - val_loss: 0.0920 - val_smart_square_abs_min_loss: 0.0920 - val_accuracy: 0.6825\n",
      "Epoch 86/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0850 - smart_square_abs_min_loss: 0.0850 - accuracy: 0.7247+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 285ms/step - loss: 0.1144 - smart_square_abs_min_loss: 0.1144 - accuracy: 0.5968\n",
      "Loss on test data:  0.11437555402517319\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[57.76423  35.45217  32.249584]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[13.31535  24.910303 15.957618]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[12.3326   59.938236 52.27193 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 89s 325ms/step - loss: 0.0850 - smart_square_abs_min_loss: 0.0850 - accuracy: 0.7247 - val_loss: 0.1412 - val_smart_square_abs_min_loss: 0.1412 - val_accuracy: 0.7006\n",
      "Epoch 87/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0859 - smart_square_abs_min_loss: 0.0859 - accuracy: 0.6916 - val_loss: 0.1071 - val_smart_square_abs_min_loss: 0.1071 - val_accuracy: 0.7419\n",
      "Epoch 88/300\n",
      "273/273 [==============================] - 84s 307ms/step - loss: 0.0945 - smart_square_abs_min_loss: 0.0945 - accuracy: 0.6912 - val_loss: 0.1290 - val_smart_square_abs_min_loss: 0.1290 - val_accuracy: 0.7238\n",
      "Epoch 89/300\n",
      "273/273 [==============================] - 84s 309ms/step - loss: 0.0852 - smart_square_abs_min_loss: 0.0852 - accuracy: 0.7286 - val_loss: 0.0688 - val_smart_square_abs_min_loss: 0.0688 - val_accuracy: 0.6179\n",
      "Epoch 90/300\n",
      "273/273 [==============================] - 85s 312ms/step - loss: 0.0813 - smart_square_abs_min_loss: 0.0813 - accuracy: 0.7284 - val_loss: 0.0974 - val_smart_square_abs_min_loss: 0.0974 - val_accuracy: 0.7591\n",
      "Epoch 91/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0970 - smart_square_abs_min_loss: 0.0970 - accuracy: 0.6645+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 281ms/step - loss: 0.1343 - smart_square_abs_min_loss: 0.1343 - accuracy: 0.6290\n",
      "Loss on test data:  0.13426737487316132\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[56.572437 36.817394 33.589165]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[25.576258 33.228252 10.722061]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[ 7.47566  62.330902 52.57235 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 94s 343ms/step - loss: 0.0970 - smart_square_abs_min_loss: 0.0970 - accuracy: 0.6645 - val_loss: 0.1038 - val_smart_square_abs_min_loss: 0.1038 - val_accuracy: 0.6149\n",
      "Epoch 92/300\n",
      "273/273 [==============================] - 84s 309ms/step - loss: 0.0877 - smart_square_abs_min_loss: 0.0877 - accuracy: 0.6883 - val_loss: 0.0840 - val_smart_square_abs_min_loss: 0.0840 - val_accuracy: 0.6815\n",
      "Epoch 93/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0942 - smart_square_abs_min_loss: 0.0942 - accuracy: 0.6822 - val_loss: 0.1131 - val_smart_square_abs_min_loss: 0.1131 - val_accuracy: 0.8034\n",
      "Epoch 94/300\n",
      "273/273 [==============================] - 85s 310ms/step - loss: 0.0908 - smart_square_abs_min_loss: 0.0908 - accuracy: 0.6928 - val_loss: 0.0838 - val_smart_square_abs_min_loss: 0.0838 - val_accuracy: 0.5887\n",
      "Epoch 95/300\n",
      "273/273 [==============================] - 85s 310ms/step - loss: 0.0895 - smart_square_abs_min_loss: 0.0895 - accuracy: 0.7119 - val_loss: 0.1147 - val_smart_square_abs_min_loss: 0.1147 - val_accuracy: 0.6089\n",
      "Epoch 96/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0726 - smart_square_abs_min_loss: 0.0726 - accuracy: 0.7671+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 277ms/step - loss: 0.1085 - smart_square_abs_min_loss: 0.1085 - accuracy: 0.5111\n",
      "Loss on test data:  0.10846971720457077\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[53.999947 35.731453 25.784986]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "predicted values [[15.379268 34.944195  8.364706]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[13.53295  61.916885 52.564285]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 95s 347ms/step - loss: 0.0726 - smart_square_abs_min_loss: 0.0726 - accuracy: 0.7671 - val_loss: 0.1104 - val_smart_square_abs_min_loss: 0.1104 - val_accuracy: 0.6129\n",
      "Epoch 97/300\n",
      "273/273 [==============================] - 84s 309ms/step - loss: 0.0835 - smart_square_abs_min_loss: 0.0835 - accuracy: 0.7372 - val_loss: 0.1213 - val_smart_square_abs_min_loss: 0.1213 - val_accuracy: 0.5917\n",
      "Epoch 98/300\n",
      "273/273 [==============================] - 84s 307ms/step - loss: 0.0859 - smart_square_abs_min_loss: 0.0859 - accuracy: 0.7353 - val_loss: 0.1233 - val_smart_square_abs_min_loss: 0.1233 - val_accuracy: 0.6885\n",
      "Epoch 99/300\n",
      "273/273 [==============================] - 86s 313ms/step - loss: 0.0836 - smart_square_abs_min_loss: 0.0836 - accuracy: 0.7308 - val_loss: 0.1074 - val_smart_square_abs_min_loss: 0.1074 - val_accuracy: 0.5252\n",
      "Epoch 100/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0755 - smart_square_abs_min_loss: 0.0755 - accuracy: 0.7402 - val_loss: 0.1007 - val_smart_square_abs_min_loss: 0.1007 - val_accuracy: 0.5181\n",
      "Epoch 101/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0922 - smart_square_abs_min_loss: 0.0922 - accuracy: 0.6992+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 270ms/step - loss: 0.1271 - smart_square_abs_min_loss: 0.1271 - accuracy: 0.7188\n",
      "Loss on test data:  0.1270534098148346\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[54.32731  38.040226 22.894438]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[14.121872  32.989605   3.2537053]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[ 8.931437 62.651085 51.251415]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 94s 343ms/step - loss: 0.0922 - smart_square_abs_min_loss: 0.0922 - accuracy: 0.6992 - val_loss: 0.1288 - val_smart_square_abs_min_loss: 0.1288 - val_accuracy: 0.6421\n",
      "Epoch 102/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0931 - smart_square_abs_min_loss: 0.0931 - accuracy: 0.6811 - val_loss: 0.1180 - val_smart_square_abs_min_loss: 0.1180 - val_accuracy: 0.6371\n",
      "Epoch 103/300\n",
      "273/273 [==============================] - 85s 310ms/step - loss: 0.0795 - smart_square_abs_min_loss: 0.0795 - accuracy: 0.7448 - val_loss: 0.1213 - val_smart_square_abs_min_loss: 0.1213 - val_accuracy: 0.6935\n",
      "Epoch 104/300\n",
      "273/273 [==============================] - 83s 304ms/step - loss: 0.0911 - smart_square_abs_min_loss: 0.0911 - accuracy: 0.7230 - val_loss: 0.1107 - val_smart_square_abs_min_loss: 0.1107 - val_accuracy: 0.5958\n",
      "Epoch 105/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273/273 [==============================] - 84s 309ms/step - loss: 0.0857 - smart_square_abs_min_loss: 0.0857 - accuracy: 0.7086 - val_loss: 0.0781 - val_smart_square_abs_min_loss: 0.0781 - val_accuracy: 0.6946\n",
      "Epoch 106/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.1024 - smart_square_abs_min_loss: 0.1024 - accuracy: 0.6560+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 271ms/step - loss: 0.0807 - smart_square_abs_min_loss: 0.0807 - accuracy: 0.6835\n",
      "Loss on test data:  0.08067329227924347\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[58.404182 32.67841  27.920341]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[10.698951  29.378975   3.5056298]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[15.734714 61.61633  52.550404]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 93s 342ms/step - loss: 0.1024 - smart_square_abs_min_loss: 0.1024 - accuracy: 0.6560 - val_loss: 0.1683 - val_smart_square_abs_min_loss: 0.1683 - val_accuracy: 0.5877\n",
      "Epoch 107/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0883 - smart_square_abs_min_loss: 0.0883 - accuracy: 0.7288 - val_loss: 0.1157 - val_smart_square_abs_min_loss: 0.1157 - val_accuracy: 0.6784\n",
      "Epoch 108/300\n",
      "273/273 [==============================] - 84s 309ms/step - loss: 0.0802 - smart_square_abs_min_loss: 0.0802 - accuracy: 0.7394 - val_loss: 0.1127 - val_smart_square_abs_min_loss: 0.1127 - val_accuracy: 0.7248\n",
      "Epoch 109/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0941 - smart_square_abs_min_loss: 0.0941 - accuracy: 0.7004 - val_loss: 0.0879 - val_smart_square_abs_min_loss: 0.0879 - val_accuracy: 0.5988\n",
      "Epoch 110/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0815 - smart_square_abs_min_loss: 0.0815 - accuracy: 0.7303 - val_loss: 0.0817 - val_smart_square_abs_min_loss: 0.0817 - val_accuracy: 0.7571\n",
      "Epoch 111/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0825 - smart_square_abs_min_loss: 0.0825 - accuracy: 0.7376+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 281ms/step - loss: 0.1197 - smart_square_abs_min_loss: 0.1197 - accuracy: 0.5867\n",
      "Loss on test data:  0.11965936422348022\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[55.687016 32.579437 24.773495]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[19.526705  29.873291   6.7013283]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[13.559896 64.776924 47.8818  ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 92s 338ms/step - loss: 0.0825 - smart_square_abs_min_loss: 0.0825 - accuracy: 0.7376 - val_loss: 0.0988 - val_smart_square_abs_min_loss: 0.0988 - val_accuracy: 0.6683\n",
      "Epoch 112/300\n",
      "273/273 [==============================] - 83s 302ms/step - loss: 0.0960 - smart_square_abs_min_loss: 0.0960 - accuracy: 0.7091 - val_loss: 0.0822 - val_smart_square_abs_min_loss: 0.0822 - val_accuracy: 0.6149\n",
      "Epoch 113/300\n",
      "273/273 [==============================] - 85s 313ms/step - loss: 0.0720 - smart_square_abs_min_loss: 0.0720 - accuracy: 0.7426 - val_loss: 0.0794 - val_smart_square_abs_min_loss: 0.0794 - val_accuracy: 0.7450\n",
      "Epoch 114/300\n",
      "273/273 [==============================] - 85s 309ms/step - loss: 0.0849 - smart_square_abs_min_loss: 0.0849 - accuracy: 0.7289 - val_loss: 0.1319 - val_smart_square_abs_min_loss: 0.1319 - val_accuracy: 0.5837\n",
      "Epoch 115/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0812 - smart_square_abs_min_loss: 0.0812 - accuracy: 0.7285 - val_loss: 0.1318 - val_smart_square_abs_min_loss: 0.1318 - val_accuracy: 0.6542\n",
      "Epoch 116/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0826 - smart_square_abs_min_loss: 0.0826 - accuracy: 0.7084+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 273ms/step - loss: 0.1119 - smart_square_abs_min_loss: 0.1119 - accuracy: 0.6583\n",
      "Loss on test data:  0.11188255995512009\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[56.083923 37.66715  28.888306]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[19.512108  37.949368   1.8609394]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[15.380606 60.211098 43.282593]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 94s 346ms/step - loss: 0.0826 - smart_square_abs_min_loss: 0.0826 - accuracy: 0.7084 - val_loss: 0.1215 - val_smart_square_abs_min_loss: 0.1215 - val_accuracy: 0.6048\n",
      "Epoch 117/300\n",
      "273/273 [==============================] - 84s 306ms/step - loss: 0.0794 - smart_square_abs_min_loss: 0.0794 - accuracy: 0.7242 - val_loss: 0.0889 - val_smart_square_abs_min_loss: 0.0889 - val_accuracy: 0.6512\n",
      "Epoch 118/300\n",
      "273/273 [==============================] - 84s 306ms/step - loss: 0.0812 - smart_square_abs_min_loss: 0.0812 - accuracy: 0.7577 - val_loss: 0.0855 - val_smart_square_abs_min_loss: 0.0855 - val_accuracy: 0.7308\n",
      "Epoch 119/300\n",
      "273/273 [==============================] - 85s 313ms/step - loss: 0.0833 - smart_square_abs_min_loss: 0.0833 - accuracy: 0.7137 - val_loss: 0.0826 - val_smart_square_abs_min_loss: 0.0826 - val_accuracy: 0.6865\n",
      "Epoch 120/300\n",
      "273/273 [==============================] - 85s 312ms/step - loss: 0.0898 - smart_square_abs_min_loss: 0.0898 - accuracy: 0.6947 - val_loss: 0.1373 - val_smart_square_abs_min_loss: 0.1373 - val_accuracy: 0.6300\n",
      "Epoch 121/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0899 - smart_square_abs_min_loss: 0.0899 - accuracy: 0.7097+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 280ms/step - loss: 0.1643 - smart_square_abs_min_loss: 0.1643 - accuracy: 0.6411\n",
      "Loss on test data:  0.16425494849681854\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[56.907646 34.508465 21.196892]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[18.96956   29.517727   0.2793581]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[13.676849 62.18649  48.7274  ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 93s 342ms/step - loss: 0.0899 - smart_square_abs_min_loss: 0.0899 - accuracy: 0.7097 - val_loss: 0.0887 - val_smart_square_abs_min_loss: 0.0887 - val_accuracy: 0.7067\n",
      "Epoch 122/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0869 - smart_square_abs_min_loss: 0.0869 - accuracy: 0.7308 - val_loss: 0.1091 - val_smart_square_abs_min_loss: 0.1091 - val_accuracy: 0.6653\n",
      "Epoch 123/300\n",
      "273/273 [==============================] - 83s 305ms/step - loss: 0.0770 - smart_square_abs_min_loss: 0.0770 - accuracy: 0.7569 - val_loss: 0.1002 - val_smart_square_abs_min_loss: 0.1002 - val_accuracy: 0.6512\n",
      "Epoch 124/300\n",
      "273/273 [==============================] - 84s 306ms/step - loss: 0.0932 - smart_square_abs_min_loss: 0.0932 - accuracy: 0.6954 - val_loss: 0.0987 - val_smart_square_abs_min_loss: 0.0987 - val_accuracy: 0.5998\n",
      "Epoch 125/300\n",
      "273/273 [==============================] - 84s 306ms/step - loss: 0.0702 - smart_square_abs_min_loss: 0.0702 - accuracy: 0.7895 - val_loss: 0.1069 - val_smart_square_abs_min_loss: 0.1069 - val_accuracy: 0.8065\n",
      "Epoch 126/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273/273 [==============================] - ETA: 0s - loss: 0.0807 - smart_square_abs_min_loss: 0.0807 - accuracy: 0.7160+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 276ms/step - loss: 0.0855 - smart_square_abs_min_loss: 0.0855 - accuracy: 0.6562\n",
      "Loss on test data:  0.08550123870372772\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted values [[56.358356 36.077778 24.385668]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[25.3167    30.545702   5.7604833]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "predicted values [[15.584931 61.41826  45.463566]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 92s 336ms/step - loss: 0.0807 - smart_square_abs_min_loss: 0.0807 - accuracy: 0.7160 - val_loss: 0.1063 - val_smart_square_abs_min_loss: 0.1063 - val_accuracy: 0.6361\n",
      "Epoch 127/300\n",
      "273/273 [==============================] - 85s 310ms/step - loss: 0.0921 - smart_square_abs_min_loss: 0.0921 - accuracy: 0.7062 - val_loss: 0.0918 - val_smart_square_abs_min_loss: 0.0918 - val_accuracy: 0.6210\n",
      "Epoch 128/300\n",
      "273/273 [==============================] - 79s 290ms/step - loss: 0.0911 - smart_square_abs_min_loss: 0.0911 - accuracy: 0.6799 - val_loss: 0.1145 - val_smart_square_abs_min_loss: 0.1145 - val_accuracy: 0.7470\n",
      "Epoch 129/300\n",
      "273/273 [==============================] - 84s 307ms/step - loss: 0.0948 - smart_square_abs_min_loss: 0.0948 - accuracy: 0.7016 - val_loss: 0.0784 - val_smart_square_abs_min_loss: 0.0784 - val_accuracy: 0.6240\n",
      "Epoch 130/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0865 - smart_square_abs_min_loss: 0.0865 - accuracy: 0.7174 - val_loss: 0.1088 - val_smart_square_abs_min_loss: 0.1088 - val_accuracy: 0.6018\n",
      "Epoch 131/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0806 - smart_square_abs_min_loss: 0.0806 - accuracy: 0.6965+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 283ms/step - loss: 0.1032 - smart_square_abs_min_loss: 0.1032 - accuracy: 0.6179\n",
      "Loss on test data:  0.10318688303232193\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[58.319572 35.21838  21.975832]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[26.219479  36.14829    2.5905008]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[15.8303175 61.37349   47.430683 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 93s 339ms/step - loss: 0.0806 - smart_square_abs_min_loss: 0.0806 - accuracy: 0.6965 - val_loss: 0.0987 - val_smart_square_abs_min_loss: 0.0987 - val_accuracy: 0.6290\n",
      "Epoch 132/300\n",
      "273/273 [==============================] - 84s 306ms/step - loss: 0.0831 - smart_square_abs_min_loss: 0.0831 - accuracy: 0.7256 - val_loss: 0.0864 - val_smart_square_abs_min_loss: 0.0864 - val_accuracy: 0.6875\n",
      "Epoch 133/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0780 - smart_square_abs_min_loss: 0.0780 - accuracy: 0.7656 - val_loss: 0.0796 - val_smart_square_abs_min_loss: 0.0796 - val_accuracy: 0.8075\n",
      "Epoch 134/300\n",
      "273/273 [==============================] - 85s 310ms/step - loss: 0.0848 - smart_square_abs_min_loss: 0.0848 - accuracy: 0.7078 - val_loss: 0.0823 - val_smart_square_abs_min_loss: 0.0823 - val_accuracy: 0.6996\n",
      "Epoch 135/300\n",
      "273/273 [==============================] - 86s 315ms/step - loss: 0.0863 - smart_square_abs_min_loss: 0.0863 - accuracy: 0.7309 - val_loss: 0.0904 - val_smart_square_abs_min_loss: 0.0904 - val_accuracy: 0.6562\n",
      "Epoch 136/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0876 - smart_square_abs_min_loss: 0.0876 - accuracy: 0.6857+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 281ms/step - loss: 0.1089 - smart_square_abs_min_loss: 0.1089 - accuracy: 0.7440\n",
      "Loss on test data:  0.10890412330627441\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[56.74916  35.49244  20.303228]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[22.03611   35.433308   2.2371392]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[16.402218 61.75502  50.138435]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 94s 343ms/step - loss: 0.0876 - smart_square_abs_min_loss: 0.0876 - accuracy: 0.6857 - val_loss: 0.1048 - val_smart_square_abs_min_loss: 0.1048 - val_accuracy: 0.7490\n",
      "Epoch 137/300\n",
      "273/273 [==============================] - 83s 302ms/step - loss: 0.0788 - smart_square_abs_min_loss: 0.0788 - accuracy: 0.7465 - val_loss: 0.0833 - val_smart_square_abs_min_loss: 0.0833 - val_accuracy: 0.6704\n",
      "Epoch 138/300\n",
      "273/273 [==============================] - 85s 309ms/step - loss: 0.0912 - smart_square_abs_min_loss: 0.0912 - accuracy: 0.7071 - val_loss: 0.0952 - val_smart_square_abs_min_loss: 0.0952 - val_accuracy: 0.6179\n",
      "Epoch 139/300\n",
      "273/273 [==============================] - 85s 313ms/step - loss: 0.0762 - smart_square_abs_min_loss: 0.0762 - accuracy: 0.7418 - val_loss: 0.1094 - val_smart_square_abs_min_loss: 0.1094 - val_accuracy: 0.6714\n",
      "Epoch 140/300\n",
      "273/273 [==============================] - 84s 307ms/step - loss: 0.0830 - smart_square_abs_min_loss: 0.0830 - accuracy: 0.7068 - val_loss: 0.0990 - val_smart_square_abs_min_loss: 0.0990 - val_accuracy: 0.6774\n",
      "Epoch 141/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0740 - smart_square_abs_min_loss: 0.0740 - accuracy: 0.7469+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 277ms/step - loss: 0.1197 - smart_square_abs_min_loss: 0.1197 - accuracy: 0.6512\n",
      "Loss on test data:  0.11974730342626572\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[58.29909  39.05127  22.317883]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[21.824951 33.042614  5.786098]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[14.853863 61.450893 52.193745]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 93s 340ms/step - loss: 0.0740 - smart_square_abs_min_loss: 0.0740 - accuracy: 0.7469 - val_loss: 0.0774 - val_smart_square_abs_min_loss: 0.0774 - val_accuracy: 0.7056\n",
      "Epoch 142/300\n",
      "273/273 [==============================] - 85s 311ms/step - loss: 0.0891 - smart_square_abs_min_loss: 0.0891 - accuracy: 0.6785 - val_loss: 0.0816 - val_smart_square_abs_min_loss: 0.0816 - val_accuracy: 0.7056\n",
      "Epoch 143/300\n",
      "273/273 [==============================] - 84s 306ms/step - loss: 0.0826 - smart_square_abs_min_loss: 0.0826 - accuracy: 0.7366 - val_loss: 0.0942 - val_smart_square_abs_min_loss: 0.0942 - val_accuracy: 0.6361\n",
      "Epoch 144/300\n",
      "273/273 [==============================] - 85s 312ms/step - loss: 0.0870 - smart_square_abs_min_loss: 0.0870 - accuracy: 0.6935 - val_loss: 0.1175 - val_smart_square_abs_min_loss: 0.1175 - val_accuracy: 0.5433\n",
      "Epoch 145/300\n",
      "273/273 [==============================] - 85s 311ms/step - loss: 0.0711 - smart_square_abs_min_loss: 0.0711 - accuracy: 0.7582 - val_loss: 0.1075 - val_smart_square_abs_min_loss: 0.1075 - val_accuracy: 0.6512\n",
      "Epoch 146/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0795 - smart_square_abs_min_loss: 0.0795 - accuracy: 0.7244+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 8s 268ms/step - loss: 0.0857 - smart_square_abs_min_loss: 0.0857 - accuracy: 0.6159\n",
      "Loss on test data:  0.08567019551992416\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[58.236217 37.51773  21.65714 ]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[21.55806  39.598396  5.156741]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[19.038902 61.85546  46.942688]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 92s 338ms/step - loss: 0.0795 - smart_square_abs_min_loss: 0.0795 - accuracy: 0.7244 - val_loss: 0.0961 - val_smart_square_abs_min_loss: 0.0961 - val_accuracy: 0.8024\n",
      "Epoch 147/300\n",
      "273/273 [==============================] - 84s 307ms/step - loss: 0.0711 - smart_square_abs_min_loss: 0.0711 - accuracy: 0.7891 - val_loss: 0.1020 - val_smart_square_abs_min_loss: 0.1020 - val_accuracy: 0.7510\n",
      "Epoch 148/300\n",
      "273/273 [==============================] - 84s 306ms/step - loss: 0.0822 - smart_square_abs_min_loss: 0.0822 - accuracy: 0.7313 - val_loss: 0.1233 - val_smart_square_abs_min_loss: 0.1233 - val_accuracy: 0.6300\n",
      "Epoch 149/300\n",
      "273/273 [==============================] - 84s 306ms/step - loss: 0.0794 - smart_square_abs_min_loss: 0.0794 - accuracy: 0.7576 - val_loss: 0.1154 - val_smart_square_abs_min_loss: 0.1154 - val_accuracy: 0.5524\n",
      "Epoch 150/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0713 - smart_square_abs_min_loss: 0.0713 - accuracy: 0.7327 - val_loss: 0.0971 - val_smart_square_abs_min_loss: 0.0971 - val_accuracy: 0.6956\n",
      "Epoch 151/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0859 - smart_square_abs_min_loss: 0.0859 - accuracy: 0.7295+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 272ms/step - loss: 0.0999 - smart_square_abs_min_loss: 0.0999 - accuracy: 0.5665\n",
      "Loss on test data:  0.09994540363550186\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[57.579792 34.65114  21.262745]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[17.148487 40.908745  4.313459]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[18.716955 61.329277 44.896618]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 94s 344ms/step - loss: 0.0859 - smart_square_abs_min_loss: 0.0859 - accuracy: 0.7295 - val_loss: 0.0825 - val_smart_square_abs_min_loss: 0.0825 - val_accuracy: 0.7732\n",
      "Epoch 152/300\n",
      "273/273 [==============================] - 84s 307ms/step - loss: 0.0860 - smart_square_abs_min_loss: 0.0860 - accuracy: 0.6866 - val_loss: 0.0727 - val_smart_square_abs_min_loss: 0.0727 - val_accuracy: 0.7218\n",
      "Epoch 153/300\n",
      "273/273 [==============================] - 83s 305ms/step - loss: 0.0654 - smart_square_abs_min_loss: 0.0654 - accuracy: 0.7752 - val_loss: 0.1065 - val_smart_square_abs_min_loss: 0.1065 - val_accuracy: 0.5675\n",
      "Epoch 154/300\n",
      "273/273 [==============================] - 84s 307ms/step - loss: 0.0688 - smart_square_abs_min_loss: 0.0688 - accuracy: 0.7737 - val_loss: 0.1135 - val_smart_square_abs_min_loss: 0.1135 - val_accuracy: 0.6079\n",
      "Epoch 155/300\n",
      "273/273 [==============================] - 85s 313ms/step - loss: 0.0781 - smart_square_abs_min_loss: 0.0781 - accuracy: 0.7474 - val_loss: 0.1258 - val_smart_square_abs_min_loss: 0.1258 - val_accuracy: 0.6714\n",
      "Epoch 156/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0806 - smart_square_abs_min_loss: 0.0806 - accuracy: 0.7245+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 268ms/step - loss: 0.0721 - smart_square_abs_min_loss: 0.0721 - accuracy: 0.6411\n",
      "Loss on test data:  0.07213596999645233\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[57.126904 36.165985 21.723206]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[20.541306  40.76323    2.0692606]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[18.26495  59.708466 49.98359 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 93s 339ms/step - loss: 0.0806 - smart_square_abs_min_loss: 0.0806 - accuracy: 0.7245 - val_loss: 0.1191 - val_smart_square_abs_min_loss: 0.1191 - val_accuracy: 0.5464\n",
      "Epoch 157/300\n",
      "273/273 [==============================] - 83s 304ms/step - loss: 0.0670 - smart_square_abs_min_loss: 0.0670 - accuracy: 0.7605 - val_loss: 0.1312 - val_smart_square_abs_min_loss: 0.1312 - val_accuracy: 0.5181\n",
      "Epoch 158/300\n",
      "273/273 [==============================] - 82s 302ms/step - loss: 0.0837 - smart_square_abs_min_loss: 0.0837 - accuracy: 0.7210 - val_loss: 0.0785 - val_smart_square_abs_min_loss: 0.0785 - val_accuracy: 0.7641\n",
      "Epoch 159/300\n",
      "273/273 [==============================] - 84s 307ms/step - loss: 0.0898 - smart_square_abs_min_loss: 0.0898 - accuracy: 0.6890 - val_loss: 0.0622 - val_smart_square_abs_min_loss: 0.0622 - val_accuracy: 0.7571\n",
      "Epoch 160/300\n",
      "273/273 [==============================] - 85s 309ms/step - loss: 0.0819 - smart_square_abs_min_loss: 0.0819 - accuracy: 0.7191 - val_loss: 0.0702 - val_smart_square_abs_min_loss: 0.0702 - val_accuracy: 0.7450\n",
      "Epoch 161/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0853 - smart_square_abs_min_loss: 0.0853 - accuracy: 0.7382+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 271ms/step - loss: 0.0876 - smart_square_abs_min_loss: 0.0876 - accuracy: 0.6431\n",
      "Loss on test data:  0.08758332580327988\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[60.0966   41.64781  25.417175]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[22.296272 36.52376   1.341749]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[17.61717  60.473213 49.91428 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 94s 345ms/step - loss: 0.0853 - smart_square_abs_min_loss: 0.0853 - accuracy: 0.7382 - val_loss: 0.1259 - val_smart_square_abs_min_loss: 0.1259 - val_accuracy: 0.6815\n",
      "Epoch 162/300\n",
      "273/273 [==============================] - 83s 303ms/step - loss: 0.0885 - smart_square_abs_min_loss: 0.0885 - accuracy: 0.7110 - val_loss: 0.1065 - val_smart_square_abs_min_loss: 0.1065 - val_accuracy: 0.6966\n",
      "Epoch 163/300\n",
      "273/273 [==============================] - 84s 306ms/step - loss: 0.0813 - smart_square_abs_min_loss: 0.0813 - accuracy: 0.7198 - val_loss: 0.0805 - val_smart_square_abs_min_loss: 0.0805 - val_accuracy: 0.7046\n",
      "Epoch 164/300\n",
      "273/273 [==============================] - 85s 312ms/step - loss: 0.0957 - smart_square_abs_min_loss: 0.0957 - accuracy: 0.6944 - val_loss: 0.0811 - val_smart_square_abs_min_loss: 0.0811 - val_accuracy: 0.6683\n",
      "Epoch 165/300\n",
      "273/273 [==============================] - 83s 304ms/step - loss: 0.0726 - smart_square_abs_min_loss: 0.0726 - accuracy: 0.7463 - val_loss: 0.0958 - val_smart_square_abs_min_loss: 0.0958 - val_accuracy: 0.7026\n",
      "Epoch 166/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0756 - smart_square_abs_min_loss: 0.0756 - accuracy: 0.7400+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 274ms/step - loss: 0.1312 - smart_square_abs_min_loss: 0.1312 - accuracy: 0.7399\n",
      "Loss on test data:  0.13123036921024323\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[58.531475 39.08694  19.530973]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "predicted values [[14.894985  29.241      0.1469247]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[17.460787 60.261993 47.29717 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 93s 340ms/step - loss: 0.0756 - smart_square_abs_min_loss: 0.0756 - accuracy: 0.7400 - val_loss: 0.1005 - val_smart_square_abs_min_loss: 0.1005 - val_accuracy: 0.6512\n",
      "Epoch 167/300\n",
      "273/273 [==============================] - 86s 314ms/step - loss: 0.0838 - smart_square_abs_min_loss: 0.0838 - accuracy: 0.7075 - val_loss: 0.0666 - val_smart_square_abs_min_loss: 0.0666 - val_accuracy: 0.8508\n",
      "Epoch 168/300\n",
      "273/273 [==============================] - 85s 312ms/step - loss: 0.0790 - smart_square_abs_min_loss: 0.0790 - accuracy: 0.7307 - val_loss: 0.1075 - val_smart_square_abs_min_loss: 0.1075 - val_accuracy: 0.6744\n",
      "Epoch 169/300\n",
      "273/273 [==============================] - 85s 310ms/step - loss: 0.0651 - smart_square_abs_min_loss: 0.0651 - accuracy: 0.7547 - val_loss: 0.1361 - val_smart_square_abs_min_loss: 0.1361 - val_accuracy: 0.6532\n",
      "Epoch 170/300\n",
      "273/273 [==============================] - 87s 319ms/step - loss: 0.0848 - smart_square_abs_min_loss: 0.0848 - accuracy: 0.6806 - val_loss: 0.1207 - val_smart_square_abs_min_loss: 0.1207 - val_accuracy: 0.5867\n",
      "Epoch 171/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0726 - smart_square_abs_min_loss: 0.0726 - accuracy: 0.7316+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 285ms/step - loss: 0.1120 - smart_square_abs_min_loss: 0.1120 - accuracy: 0.6028\n",
      "Loss on test data:  0.11200504004955292\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[56.767727 36.98662  18.44575 ]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[28.609627  37.113293  -1.3215297]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[17.00209  60.12972  46.424595]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 94s 345ms/step - loss: 0.0726 - smart_square_abs_min_loss: 0.0726 - accuracy: 0.7316 - val_loss: 0.0722 - val_smart_square_abs_min_loss: 0.0722 - val_accuracy: 0.7500\n",
      "Epoch 172/300\n",
      "273/273 [==============================] - 77s 282ms/step - loss: 0.0763 - smart_square_abs_min_loss: 0.0763 - accuracy: 0.7395 - val_loss: 0.1289 - val_smart_square_abs_min_loss: 0.1289 - val_accuracy: 0.6865\n",
      "Epoch 173/300\n",
      "273/273 [==============================] - 72s 264ms/step - loss: 0.0821 - smart_square_abs_min_loss: 0.0821 - accuracy: 0.7214 - val_loss: 0.1450 - val_smart_square_abs_min_loss: 0.1450 - val_accuracy: 0.6573\n",
      "Epoch 174/300\n",
      "273/273 [==============================] - 78s 285ms/step - loss: 0.0782 - smart_square_abs_min_loss: 0.0782 - accuracy: 0.7320 - val_loss: 0.1074 - val_smart_square_abs_min_loss: 0.1074 - val_accuracy: 0.6794\n",
      "Epoch 175/300\n",
      "273/273 [==============================] - 77s 282ms/step - loss: 0.0782 - smart_square_abs_min_loss: 0.0782 - accuracy: 0.7444 - val_loss: 0.1176 - val_smart_square_abs_min_loss: 0.1176 - val_accuracy: 0.6351\n",
      "Epoch 176/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0748 - smart_square_abs_min_loss: 0.0748 - accuracy: 0.7284+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 258ms/step - loss: 0.1264 - smart_square_abs_min_loss: 0.1264 - accuracy: 0.5817\n",
      "Loss on test data:  0.12640789151191711\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[57.199654 38.300114 20.658585]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[21.057892 37.550774  4.344793]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[17.212353 60.979248 49.667553]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 89s 325ms/step - loss: 0.0748 - smart_square_abs_min_loss: 0.0748 - accuracy: 0.7284 - val_loss: 0.0771 - val_smart_square_abs_min_loss: 0.0771 - val_accuracy: 0.7389\n",
      "Epoch 177/300\n",
      "273/273 [==============================] - 86s 314ms/step - loss: 0.0721 - smart_square_abs_min_loss: 0.0721 - accuracy: 0.7602 - val_loss: 0.0825 - val_smart_square_abs_min_loss: 0.0825 - val_accuracy: 0.7530\n",
      "Epoch 178/300\n",
      "273/273 [==============================] - 86s 314ms/step - loss: 0.0688 - smart_square_abs_min_loss: 0.0688 - accuracy: 0.7475 - val_loss: 0.1009 - val_smart_square_abs_min_loss: 0.1009 - val_accuracy: 0.5444\n",
      "Epoch 179/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0870 - smart_square_abs_min_loss: 0.0870 - accuracy: 0.6894 - val_loss: 0.1082 - val_smart_square_abs_min_loss: 0.1082 - val_accuracy: 0.5403\n",
      "Epoch 180/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0790 - smart_square_abs_min_loss: 0.0790 - accuracy: 0.7168 - val_loss: 0.0913 - val_smart_square_abs_min_loss: 0.0913 - val_accuracy: 0.6925\n",
      "Epoch 181/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0716 - smart_square_abs_min_loss: 0.0716 - accuracy: 0.7639+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 282ms/step - loss: 0.0833 - smart_square_abs_min_loss: 0.0833 - accuracy: 0.7974\n",
      "Loss on test data:  0.08328066766262054\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "predicted values [[56.919533 37.42588  26.405104]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[21.535648  37.518845   3.1619182]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[19.474146 63.29249  50.766533]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 94s 346ms/step - loss: 0.0716 - smart_square_abs_min_loss: 0.0716 - accuracy: 0.7639 - val_loss: 0.0865 - val_smart_square_abs_min_loss: 0.0865 - val_accuracy: 0.8407\n",
      "Epoch 182/300\n",
      "273/273 [==============================] - 78s 284ms/step - loss: 0.0658 - smart_square_abs_min_loss: 0.0658 - accuracy: 0.7721 - val_loss: 0.0996 - val_smart_square_abs_min_loss: 0.0996 - val_accuracy: 0.6522\n",
      "Epoch 183/300\n",
      "273/273 [==============================] - 76s 280ms/step - loss: 0.0850 - smart_square_abs_min_loss: 0.0850 - accuracy: 0.7201 - val_loss: 0.0890 - val_smart_square_abs_min_loss: 0.0890 - val_accuracy: 0.6774\n",
      "Epoch 184/300\n",
      "273/273 [==============================] - 85s 310ms/step - loss: 0.0871 - smart_square_abs_min_loss: 0.0871 - accuracy: 0.7015 - val_loss: 0.1220 - val_smart_square_abs_min_loss: 0.1220 - val_accuracy: 0.6250\n",
      "Epoch 185/300\n",
      "273/273 [==============================] - 82s 299ms/step - loss: 0.0766 - smart_square_abs_min_loss: 0.0766 - accuracy: 0.7238 - val_loss: 0.0739 - val_smart_square_abs_min_loss: 0.0739 - val_accuracy: 0.6129\n",
      "Epoch 186/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0900 - smart_square_abs_min_loss: 0.0900 - accuracy: 0.6968+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 274ms/step - loss: 0.1570 - smart_square_abs_min_loss: 0.1570 - accuracy: 0.6784\n",
      "Loss on test data:  0.15697833895683289\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[57.27084  34.329327 16.792992]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[22.699654  40.383488   3.2278214]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[18.07507  61.27293  51.560913]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 94s 345ms/step - loss: 0.0900 - smart_square_abs_min_loss: 0.0900 - accuracy: 0.6968 - val_loss: 0.0870 - val_smart_square_abs_min_loss: 0.0870 - val_accuracy: 0.5847\n",
      "Epoch 187/300\n",
      "273/273 [==============================] - 85s 310ms/step - loss: 0.0720 - smart_square_abs_min_loss: 0.0720 - accuracy: 0.7705 - val_loss: 0.1169 - val_smart_square_abs_min_loss: 0.1169 - val_accuracy: 0.7127\n",
      "Epoch 188/300\n",
      "273/273 [==============================] - 84s 308ms/step - loss: 0.0734 - smart_square_abs_min_loss: 0.0734 - accuracy: 0.7345 - val_loss: 0.1112 - val_smart_square_abs_min_loss: 0.1112 - val_accuracy: 0.6250\n",
      "Epoch 189/300\n",
      "273/273 [==============================] - 86s 313ms/step - loss: 0.0787 - smart_square_abs_min_loss: 0.0787 - accuracy: 0.7316 - val_loss: 0.0948 - val_smart_square_abs_min_loss: 0.0948 - val_accuracy: 0.6250\n",
      "Epoch 190/300\n",
      "273/273 [==============================] - 85s 312ms/step - loss: 0.0910 - smart_square_abs_min_loss: 0.0910 - accuracy: 0.6993 - val_loss: 0.0760 - val_smart_square_abs_min_loss: 0.0760 - val_accuracy: 0.6714\n",
      "Epoch 191/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0808 - smart_square_abs_min_loss: 0.0808 - accuracy: 0.6833+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 285ms/step - loss: 0.0661 - smart_square_abs_min_loss: 0.0661 - accuracy: 0.7248\n",
      "Loss on test data:  0.06611368805170059\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "predicted values [[59.2988   38.332355 24.988451]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[26.46193   42.375095   3.9382963]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[17.051662 62.137756 51.523975]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 95s 350ms/step - loss: 0.0808 - smart_square_abs_min_loss: 0.0808 - accuracy: 0.6833 - val_loss: 0.0769 - val_smart_square_abs_min_loss: 0.0769 - val_accuracy: 0.7651\n",
      "Epoch 192/300\n",
      "273/273 [==============================] - 71s 259ms/step - loss: 0.0746 - smart_square_abs_min_loss: 0.0746 - accuracy: 0.7596 - val_loss: 0.0982 - val_smart_square_abs_min_loss: 0.0982 - val_accuracy: 0.7137\n",
      "Epoch 193/300\n",
      "273/273 [==============================] - 73s 266ms/step - loss: 0.0748 - smart_square_abs_min_loss: 0.0748 - accuracy: 0.7258 - val_loss: 0.0950 - val_smart_square_abs_min_loss: 0.0950 - val_accuracy: 0.6905\n",
      "Epoch 194/300\n",
      "273/273 [==============================] - 78s 285ms/step - loss: 0.0755 - smart_square_abs_min_loss: 0.0755 - accuracy: 0.7416 - val_loss: 0.1150 - val_smart_square_abs_min_loss: 0.1150 - val_accuracy: 0.5847\n",
      "Epoch 195/300\n",
      "273/273 [==============================] - 78s 285ms/step - loss: 0.0671 - smart_square_abs_min_loss: 0.0671 - accuracy: 0.7566 - val_loss: 0.0696 - val_smart_square_abs_min_loss: 0.0696 - val_accuracy: 0.7046\n",
      "Epoch 196/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0735 - smart_square_abs_min_loss: 0.0735 - accuracy: 0.7090+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 282ms/step - loss: 0.1277 - smart_square_abs_min_loss: 0.1277 - accuracy: 0.6694\n",
      "Loss on test data:  0.12771089375019073\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[58.32846  34.79657  18.510378]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[23.608578  42.141834  -1.4804848]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[17.877209 61.83076  50.72042 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 89s 326ms/step - loss: 0.0735 - smart_square_abs_min_loss: 0.0735 - accuracy: 0.7090 - val_loss: 0.0830 - val_smart_square_abs_min_loss: 0.0830 - val_accuracy: 0.6532\n",
      "Epoch 197/300\n",
      "273/273 [==============================] - 72s 264ms/step - loss: 0.0860 - smart_square_abs_min_loss: 0.0860 - accuracy: 0.6937 - val_loss: 0.0843 - val_smart_square_abs_min_loss: 0.0843 - val_accuracy: 0.5302\n",
      "Epoch 198/300\n",
      "273/273 [==============================] - 72s 265ms/step - loss: 0.0857 - smart_square_abs_min_loss: 0.0857 - accuracy: 0.7089 - val_loss: 0.0777 - val_smart_square_abs_min_loss: 0.0777 - val_accuracy: 0.7984\n",
      "Epoch 199/300\n",
      "273/273 [==============================] - 78s 284ms/step - loss: 0.0826 - smart_square_abs_min_loss: 0.0826 - accuracy: 0.7129 - val_loss: 0.0799 - val_smart_square_abs_min_loss: 0.0799 - val_accuracy: 0.7409\n",
      "Epoch 200/300\n",
      "273/273 [==============================] - 80s 291ms/step - loss: 0.0782 - smart_square_abs_min_loss: 0.0782 - accuracy: 0.7099 - val_loss: 0.1208 - val_smart_square_abs_min_loss: 0.1208 - val_accuracy: 0.5575\n",
      "Epoch 201/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0893 - smart_square_abs_min_loss: 0.0893 - accuracy: 0.7157+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 257ms/step - loss: 0.0915 - smart_square_abs_min_loss: 0.0915 - accuracy: 0.7480\n",
      "Loss on test data:  0.09146210551261902\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted values [[52.933964 36.49723  17.117426]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[14.708339  31.735779   1.9906349]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[19.282755 62.020992 50.23377 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 81s 295ms/step - loss: 0.0893 - smart_square_abs_min_loss: 0.0893 - accuracy: 0.7157 - val_loss: 0.1244 - val_smart_square_abs_min_loss: 0.1244 - val_accuracy: 0.6794\n",
      "Epoch 202/300\n",
      "273/273 [==============================] - 71s 259ms/step - loss: 0.0733 - smart_square_abs_min_loss: 0.0733 - accuracy: 0.7499 - val_loss: 0.0950 - val_smart_square_abs_min_loss: 0.0950 - val_accuracy: 0.7188\n",
      "Epoch 203/300\n",
      "273/273 [==============================] - 78s 285ms/step - loss: 0.0849 - smart_square_abs_min_loss: 0.0849 - accuracy: 0.7198 - val_loss: 0.0925 - val_smart_square_abs_min_loss: 0.0925 - val_accuracy: 0.5907\n",
      "Epoch 204/300\n",
      "273/273 [==============================] - 79s 289ms/step - loss: 0.0868 - smart_square_abs_min_loss: 0.0868 - accuracy: 0.7106 - val_loss: 0.0626 - val_smart_square_abs_min_loss: 0.0626 - val_accuracy: 0.6411\n",
      "Epoch 205/300\n",
      "273/273 [==============================] - 85s 310ms/step - loss: 0.0746 - smart_square_abs_min_loss: 0.0746 - accuracy: 0.7467 - val_loss: 0.0789 - val_smart_square_abs_min_loss: 0.0789 - val_accuracy: 0.6784\n",
      "Epoch 206/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0706 - smart_square_abs_min_loss: 0.0706 - accuracy: 0.7539+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 273ms/step - loss: 0.0949 - smart_square_abs_min_loss: 0.0949 - accuracy: 0.6421\n",
      "Loss on test data:  0.0948500782251358\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "predicted values [[56.671127 36.06594  20.143543]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[22.767143  48.406708   2.1019633]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[16.342443 63.5818   51.58341 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 93s 340ms/step - loss: 0.0706 - smart_square_abs_min_loss: 0.0706 - accuracy: 0.7539 - val_loss: 0.1002 - val_smart_square_abs_min_loss: 0.1002 - val_accuracy: 0.6956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 207/300\n",
      "273/273 [==============================] - 85s 310ms/step - loss: 0.0864 - smart_square_abs_min_loss: 0.0864 - accuracy: 0.6746 - val_loss: 0.0739 - val_smart_square_abs_min_loss: 0.0739 - val_accuracy: 0.7954\n",
      "Epoch 208/300\n",
      "273/273 [==============================] - 84s 309ms/step - loss: 0.0784 - smart_square_abs_min_loss: 0.0784 - accuracy: 0.7429 - val_loss: 0.1092 - val_smart_square_abs_min_loss: 0.1092 - val_accuracy: 0.6815\n",
      "Epoch 209/300\n",
      "273/273 [==============================] - 85s 312ms/step - loss: 0.0819 - smart_square_abs_min_loss: 0.0819 - accuracy: 0.7123 - val_loss: 0.1163 - val_smart_square_abs_min_loss: 0.1163 - val_accuracy: 0.6673\n",
      "Epoch 210/300\n",
      "273/273 [==============================] - 86s 314ms/step - loss: 0.0763 - smart_square_abs_min_loss: 0.0763 - accuracy: 0.7427 - val_loss: 0.0822 - val_smart_square_abs_min_loss: 0.0822 - val_accuracy: 0.7046\n",
      "Epoch 211/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0766 - smart_square_abs_min_loss: 0.0766 - accuracy: 0.7315+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 278ms/step - loss: 0.0985 - smart_square_abs_min_loss: 0.0985 - accuracy: 0.6925\n",
      "Loss on test data:  0.09850206971168518\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted values [[59.718258 37.031773 21.803192]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[19.750788 35.64344   0.696573]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[16.071108 62.667774 51.908226]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 94s 345ms/step - loss: 0.0766 - smart_square_abs_min_loss: 0.0766 - accuracy: 0.7315 - val_loss: 0.0918 - val_smart_square_abs_min_loss: 0.0918 - val_accuracy: 0.6663\n",
      "Epoch 212/300\n",
      "273/273 [==============================] - 77s 281ms/step - loss: 0.0915 - smart_square_abs_min_loss: 0.0915 - accuracy: 0.7048 - val_loss: 0.0806 - val_smart_square_abs_min_loss: 0.0806 - val_accuracy: 0.6875\n",
      "Epoch 213/300\n",
      "273/273 [==============================] - 78s 287ms/step - loss: 0.0714 - smart_square_abs_min_loss: 0.0714 - accuracy: 0.7426 - val_loss: 0.0875 - val_smart_square_abs_min_loss: 0.0875 - val_accuracy: 0.7389\n",
      "Epoch 214/300\n",
      "273/273 [==============================] - 79s 290ms/step - loss: 0.0836 - smart_square_abs_min_loss: 0.0836 - accuracy: 0.7131 - val_loss: 0.1179 - val_smart_square_abs_min_loss: 0.1179 - val_accuracy: 0.6774\n",
      "Epoch 215/300\n",
      "273/273 [==============================] - 86s 317ms/step - loss: 0.0756 - smart_square_abs_min_loss: 0.0756 - accuracy: 0.7403 - val_loss: 0.1106 - val_smart_square_abs_min_loss: 0.1106 - val_accuracy: 0.6562\n",
      "Epoch 216/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0792 - smart_square_abs_min_loss: 0.0792 - accuracy: 0.7286+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 280ms/step - loss: 0.1043 - smart_square_abs_min_loss: 0.1043 - accuracy: 0.7560\n",
      "Loss on test data:  0.10427689552307129\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[57.18144  36.037643 25.30788 ]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[17.832369  31.039005   0.5989098]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[16.467083 61.76623  51.382492]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 95s 347ms/step - loss: 0.0792 - smart_square_abs_min_loss: 0.0792 - accuracy: 0.7286 - val_loss: 0.0909 - val_smart_square_abs_min_loss: 0.0909 - val_accuracy: 0.6593\n",
      "Epoch 217/300\n",
      "273/273 [==============================] - 73s 266ms/step - loss: 0.0630 - smart_square_abs_min_loss: 0.0630 - accuracy: 0.7537 - val_loss: 0.1035 - val_smart_square_abs_min_loss: 0.1035 - val_accuracy: 0.5625\n",
      "Epoch 218/300\n",
      "273/273 [==============================] - 85s 311ms/step - loss: 0.0780 - smart_square_abs_min_loss: 0.0780 - accuracy: 0.7286 - val_loss: 0.0734 - val_smart_square_abs_min_loss: 0.0734 - val_accuracy: 0.6099\n",
      "Epoch 219/300\n",
      "273/273 [==============================] - 77s 280ms/step - loss: 0.0760 - smart_square_abs_min_loss: 0.0760 - accuracy: 0.7072 - val_loss: 0.1029 - val_smart_square_abs_min_loss: 0.1029 - val_accuracy: 0.6562\n",
      "Epoch 220/300\n",
      "273/273 [==============================] - 79s 288ms/step - loss: 0.0654 - smart_square_abs_min_loss: 0.0654 - accuracy: 0.7755 - val_loss: 0.1055 - val_smart_square_abs_min_loss: 0.1055 - val_accuracy: 0.5968\n",
      "Epoch 221/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0670 - smart_square_abs_min_loss: 0.0670 - accuracy: 0.7753+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 255ms/step - loss: 0.1059 - smart_square_abs_min_loss: 0.1059 - accuracy: 0.7238\n",
      "Loss on test data:  0.10593201965093613\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted values [[57.17866  35.29716  21.939283]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[16.637068 36.75261  -0.747875]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[18.74486  62.755253 51.986736]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 80s 293ms/step - loss: 0.0670 - smart_square_abs_min_loss: 0.0670 - accuracy: 0.7753 - val_loss: 0.1030 - val_smart_square_abs_min_loss: 0.1030 - val_accuracy: 0.6895\n",
      "Epoch 222/300\n",
      "273/273 [==============================] - 79s 291ms/step - loss: 0.0754 - smart_square_abs_min_loss: 0.0754 - accuracy: 0.7392 - val_loss: 0.0972 - val_smart_square_abs_min_loss: 0.0972 - val_accuracy: 0.7409\n",
      "Epoch 223/300\n",
      "273/273 [==============================] - 79s 290ms/step - loss: 0.0729 - smart_square_abs_min_loss: 0.0729 - accuracy: 0.7408 - val_loss: 0.0818 - val_smart_square_abs_min_loss: 0.0818 - val_accuracy: 0.7661\n",
      "Epoch 224/300\n",
      "273/273 [==============================] - 72s 262ms/step - loss: 0.0741 - smart_square_abs_min_loss: 0.0741 - accuracy: 0.7529 - val_loss: 0.0693 - val_smart_square_abs_min_loss: 0.0693 - val_accuracy: 0.7460\n",
      "Epoch 225/300\n",
      "273/273 [==============================] - 85s 310ms/step - loss: 0.0797 - smart_square_abs_min_loss: 0.0797 - accuracy: 0.7078 - val_loss: 0.0898 - val_smart_square_abs_min_loss: 0.0898 - val_accuracy: 0.6956\n",
      "Epoch 226/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0807 - smart_square_abs_min_loss: 0.0807 - accuracy: 0.7421+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 7s 231ms/step - loss: 0.1348 - smart_square_abs_min_loss: 0.1348 - accuracy: 0.5806\n",
      "Loss on test data:  0.13482238352298737\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "predicted values [[57.12487  36.93872  22.853703]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[17.49131   40.013508  -0.4357443]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[18.83705  61.647636 50.461975]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 92s 339ms/step - loss: 0.0807 - smart_square_abs_min_loss: 0.0807 - accuracy: 0.7421 - val_loss: 0.1328 - val_smart_square_abs_min_loss: 0.1328 - val_accuracy: 0.4748\n",
      "Epoch 227/300\n",
      "273/273 [==============================] - 77s 283ms/step - loss: 0.0795 - smart_square_abs_min_loss: 0.0795 - accuracy: 0.7299 - val_loss: 0.0997 - val_smart_square_abs_min_loss: 0.0997 - val_accuracy: 0.6804\n",
      "Epoch 228/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273/273 [==============================] - 85s 311ms/step - loss: 0.0845 - smart_square_abs_min_loss: 0.0845 - accuracy: 0.7168 - val_loss: 0.1209 - val_smart_square_abs_min_loss: 0.1209 - val_accuracy: 0.6734\n",
      "Epoch 229/300\n",
      "273/273 [==============================] - 78s 287ms/step - loss: 0.0814 - smart_square_abs_min_loss: 0.0814 - accuracy: 0.7347 - val_loss: 0.0971 - val_smart_square_abs_min_loss: 0.0971 - val_accuracy: 0.7228\n",
      "Epoch 230/300\n",
      "273/273 [==============================] - 71s 260ms/step - loss: 0.0758 - smart_square_abs_min_loss: 0.0758 - accuracy: 0.7428 - val_loss: 0.0572 - val_smart_square_abs_min_loss: 0.0572 - val_accuracy: 0.7228\n",
      "Epoch 231/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0888 - smart_square_abs_min_loss: 0.0888 - accuracy: 0.7020+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 9s 281ms/step - loss: 0.0879 - smart_square_abs_min_loss: 0.0879 - accuracy: 0.7016\n",
      "Loss on test data:  0.08788804709911346\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "predicted values [[59.511158 36.943798 21.907402]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[15.9617405  35.20371    -0.03530324]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[18.574024 61.2846   50.35201 ]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 88s 322ms/step - loss: 0.0888 - smart_square_abs_min_loss: 0.0888 - accuracy: 0.7020 - val_loss: 0.0596 - val_smart_square_abs_min_loss: 0.0596 - val_accuracy: 0.7278\n",
      "Epoch 232/300\n",
      "273/273 [==============================] - 77s 282ms/step - loss: 0.0793 - smart_square_abs_min_loss: 0.0793 - accuracy: 0.7438 - val_loss: 0.1313 - val_smart_square_abs_min_loss: 0.1313 - val_accuracy: 0.5625\n",
      "Epoch 233/300\n",
      "273/273 [==============================] - 78s 287ms/step - loss: 0.0808 - smart_square_abs_min_loss: 0.0808 - accuracy: 0.7318 - val_loss: 0.1038 - val_smart_square_abs_min_loss: 0.1038 - val_accuracy: 0.5393\n",
      "Epoch 234/300\n",
      "273/273 [==============================] - 72s 264ms/step - loss: 0.0767 - smart_square_abs_min_loss: 0.0767 - accuracy: 0.7489 - val_loss: 0.0866 - val_smart_square_abs_min_loss: 0.0866 - val_accuracy: 0.6522\n",
      "Epoch 235/300\n",
      "273/273 [==============================] - 71s 260ms/step - loss: 0.0719 - smart_square_abs_min_loss: 0.0719 - accuracy: 0.7388 - val_loss: 0.1203 - val_smart_square_abs_min_loss: 0.1203 - val_accuracy: 0.7520\n",
      "Epoch 236/300\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.0741 - smart_square_abs_min_loss: 0.0741 - accuracy: 0.7620+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "31/31 [==============================] - 8s 241ms/step - loss: 0.0970 - smart_square_abs_min_loss: 0.0970 - accuracy: 0.5847\n",
      "Loss on test data:  0.0970216616988182\n",
      "----------0----------\n",
      "phi1 54.7\n",
      "PHI 36.1\n",
      "phi2 23.5\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "predicted values [[60.00133  36.033638 24.281693]]\n",
      "----------1----------\n",
      "phi1 76.0\n",
      "PHI 83.7\n",
      "phi2 2.9\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "predicted values [[18.89293    44.285896    0.62103736]]\n",
      "----------2----------\n",
      "phi1 17.8\n",
      "PHI 63.8\n",
      "phi2 50.8\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "predicted values [[17.64181  61.484352 50.447727]]\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "273/273 [==============================] - 86s 314ms/step - loss: 0.0741 - smart_square_abs_min_loss: 0.0741 - accuracy: 0.7620 - val_loss: 0.0711 - val_smart_square_abs_min_loss: 0.0711 - val_accuracy: 0.7137\n",
      "Epoch 237/300\n",
      "168/273 [=================>............] - ETA: 27s - loss: 0.0892 - smart_square_abs_min_loss: 0.0892 - accuracy: 0.6998"
     ]
    }
   ],
   "source": [
    "######################################################################    \n",
    "##################### Compile and run the model ######################    \n",
    "###################################################################### \n",
    "model.compile(optimizer = RMSprop(learning_rate=0.0005),\n",
    "              loss = smart_square_abs_min_loss, \n",
    "              metrics = [smart_square_abs_min_loss, \"accuracy\"])  # Add run_eagerly=True to enable the numpy debugging\n",
    "\n",
    "tg = datagenerator(32, (input_size,input_size), train_df, 1, 3)\n",
    "vg = datagenerator(32, (input_size,input_size), valid_df, 1, 3)\n",
    "history = model.fit(x=tg,\n",
    "                    batch_size=32,\n",
    "                    epochs=300,\n",
    "                    validation_data=vg,\n",
    "                    callbacks=[LossHistory()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629ab4d4",
   "metadata": {},
   "source": [
    "# Working with results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80de1989",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################    \n",
    "################# Predict few values for visibility ##################    \n",
    "######################################################################\n",
    "def prdict_and_print(nr):\n",
    "    t = test_df.values[nr][1]\n",
    "    data = load_img(path = t, grayscale = True)\n",
    "    data = tf.keras.utils.img_to_array(data, data_format=\"channels_last\", dtype=\"float32\")\n",
    "    data /= 255\n",
    "    data.shape = (1,) + data.shape\n",
    "    X = np.asarray(data)\n",
    "    print(\"----------{}----------\".format(nr))\n",
    "    euler = t.split(\"_\")\n",
    "    print(\"phi1\", float(euler[3]))\n",
    "    print(\"PHI\",   float(euler[4]))\n",
    "    print(\"phi2\",  float(euler[5][:-4]))\n",
    "    yhat = model.predict(data)\n",
    "    print(\"predicted values\", yhat*90)\n",
    "    \n",
    "print(\"############### PREDICTIONS ###############\")\n",
    "for i in range(10):\n",
    "    prdict_and_print(i)\n",
    "print(\"############### PREDICTIONS ###############\")\n",
    "\n",
    "######################################################################    \n",
    "########################## Evaluate the mode #########################    \n",
    "######################################################################\n",
    "model_e = model.evaluate(test_g, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de24180",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################    \n",
    "############################ Saving model ############################    \n",
    "######################################################################\n",
    "model_name = \"Best_model_so_far_abs_loss_function_RMSprop\"\n",
    "model.save(\"Models/{}.h5\".format(model_name), save_format = 'h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16593473",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################    \n",
    "################## Plotting accuracy and loss graph ##################    \n",
    "###################################################################### \n",
    "def plot_accuracy_loss(history, name):\n",
    "    \"\"\"\n",
    "        Plot the accuracy and the loss during the training of the nn.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(12,5))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(221)\n",
    "    plt.plot(history.history['accuracy'],'bo--', label = \"acc\")\n",
    "    plt.plot(history.history['val_accuracy'],'ro--', label = \"val_accuracy\")\n",
    "    plt.title(\"train_acc vs val_acc\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot loss function\n",
    "    plt.subplot(222)\n",
    "    plt.plot(history.history['loss'],'bo--', label = \"loss\")\n",
    "    plt.plot(history.history['val_loss'],'ro--', label = \"val_loss\")\n",
    "    plt.title(\"train_loss vs val_loss\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "\n",
    "    plt.legend()\n",
    "    \n",
    "plot_accuracy_loss(history, \"1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353e7440",
   "metadata": {},
   "source": [
    "# Experiments with automating the load of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e80705",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################    \n",
    "##################### Loading a model from a file ####################    \n",
    "###################################################################### \n",
    "with CustomObjectScope({'abs_loss_function': square_abs_min_loss}):\n",
    "    model = keras.models.load_model('Models/3db071e0968f11ed81960894ef90a55a_model_adam_001.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348f3e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################    \n",
    "###################### Define models as functions ####################    \n",
    "###################################################################### \n",
    "def load_model_a():\n",
    "    inputs = keras.Input(shape=(input_size, input_size, 1))\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=4)(x)\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=4)(x)\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=4)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dense(16, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(3)(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_model_b():\n",
    "    inputs = keras.Input(shape=(input_size, input_size, 1))\n",
    "    x = layers.Conv2D(filters=16, kernel_size=11, activation=\"relu\")(inputs)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=7, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=5, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dense(16, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(3)(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "def load_model_c():\n",
    "    inputs = keras.Input(shape=(input_size, input_size, 1))\n",
    "    x = layers.Conv2D(filters=16, kernel_size=11, activation=\"relu\")(inputs)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=7, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=5, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.01))(x)\n",
    "    x = layers.Dense(16, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.01))(x) \n",
    "    outputs = layers.Dense(3)(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def plot_accuracy_loss(history):\n",
    "    \"\"\"\n",
    "        Plot the accuracy and the loss during the training of the nn.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(12,5))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(221)\n",
    "    plt.plot(history.history['accuracy'],'bo--', label = \"acc\")\n",
    "    plt.plot(history.history['val_accuracy'],'ro--', label = \"val_accuracy\")\n",
    "    plt.title(\"train_acc vs val_acc\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot loss function\n",
    "    plt.subplot(222)\n",
    "    plt.plot(history.history['loss'],'bo--', label = \"loss\")\n",
    "    plt.plot(history.history['val_loss'],'ro--', label = \"val_loss\")\n",
    "    plt.title(\"train_loss vs val_loss\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "def load_and_train_model(model, epochs = 100, loss_func = abs_loss_function):\n",
    "    tg = datagenerator(32, (input_size,input_size), train_df, 1, 3)\n",
    "    vg = datagenerator(32, (input_size,input_size), valid_df, 1, 3)\n",
    "    model.compile(optimizer = RMSprop(learning_rate=0.001),\n",
    "                  loss = loss_func, \n",
    "                  metrics = [\"accuracy\", loss_func])  # Add run_eagerly=True to enable the numpy debugging\n",
    "    \n",
    "    history = model.fit(x=tg,\n",
    "                        batch_size=32,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=vg)\n",
    "    \n",
    "    \n",
    "    plot_accuracy_loss(history)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d98e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################    \n",
    "################# Loading models and tunning them ####################    \n",
    "######################################################################\n",
    "model_a = load_model_a()\n",
    "model_a.summary()\n",
    "history_a = load_and_train_model(model_a, 100, abs_loss_function)\n",
    "model_b = load_model_b()\n",
    "model_b.summary()\n",
    "history_b = load_and_train_model(model_a, 100, abs_loss_function)\n",
    "model_c = load_model_c()\n",
    "model_c.summary()\n",
    "history_c = load_and_train_model(model_c, 100, abs_loss_function)\n",
    "plot_accuracy_loss(history_a)\n",
    "plot_accuracy_loss(history_b)\n",
    "plot_accuracy_loss(history_c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
